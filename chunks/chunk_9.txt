(word I pronoun Ising (common nom) -wh speaker) 
(word we pronoun Iplur (common nom) -wh speaker+other) 
(word you pronoun 2pers (common ?) -wh 1istener) 
(word he pronoun 3sing (common nom) -wh male) 
(word she pronoun 3s ing (common nom) -wh female) 
(word it pronoun 3s ing (common ?) -wh anything) 
(word they pronoun 3plur (common nom) -wh anything) 

(word me pronoun Ising (common obj) -wh speaker) 
(word us pronoun Iplur (common obj) -wh speaker+other) 
(word him pronoun 3sing (common obj) -wh male) 
(word her pronoun 3sing (common obj) -wh female) 
(word them pronoun 3plur (common obj) -wh anything) 

(word my pronoun Ising gen -wh speaker) 
(word our pronoun Iplur gen -wh speaker+other) 
(word your pronoun 2pers gen -wh 1istener) 
(word his pronoun 3sing gen -wh male) 
(word her pronoun 3sing gen -wh female) 
(word its pronoun 3s ing gen -wh anything) 
(word their pronoun 3plur gen -wh anything) 
(word whose pronoun 3sing gen +wh anything) 

(word who pronoun ? (common ?) +wh person) 
(word whom pronoun ? (common obj) +wh person) 
(word what pronoun ? (common ?) +wh thing) 
(word which pronoun ? (common ?) +wh thing) 

(word who rel-pro ? person) 
(word which rel-pro ? thing) 
(word that rel-pro ? thing) 
(word whom rel-pro (common obj) person) 

Names 

The following names were convenient for one example or another: 

(word God name 3sing) (word Lynn name 3sing) 
(word Jan name 3sing) (word Mary name 3sing) 
(word John name 3sing) (word NY name 3sing) 
(word Kim name 3sing) (word LA name 3sing) 
(word Lee name 3sing) (word SF name 3sing) 


<a id='page-738'></a>

Adjectives 

Here are a few adjectives: 

(word big adj big) (word bad adj bad) 
(word old adj old) (word smart adj smart) 
(word green adj green) (word red adj red) 
(word tal l adj tall ) (word fun adj fun) 

Adverbs 

The adverbs covered here include interrogatives: 

(word quickly adv -wh quickly) 
(word slowly adv -wh slowly) 

(word where adv +wh loc) 
(word when adv +wh time) 
(word why adv +wh reason) 
(word how adv +wh manner) 

Articles 

The common articles are listed here: 

(word the art 3sing the) 
(word the art Splur group) 
(word a art Ssing a) 
(word an art Ssing a) 
(word every art Ssing every) 
(word each art Ssing each) 
(word all art Ssing all) 
(word some art ? some) 

(word this art Ssing this) 
(word that art Ssing that) 
(word these art Splur this) 
(word those art Splur that) 

(word what art ? wh) 
(word which art ? wh) 


<a id='page-739'></a>

Cardinal and Ordinal Numbers 

We can take advantage of format's capabilities to fill up the lexicon. To go beyond 
20, we would need a subgrammar of numbers. 

This puts in numbers up to twenty, as if by 

(word five cardinal 5 3plur) 

(word fifth ordinal 5) 

(dotimes (i 21) 
(add-word (read-from-string (format nil "~r" i)) 
'cardinal i (if (= i 1) 'Ssing 'Splur)) 
(add-word (read-from-string (format nil "~:r" i)) Ordinal i)) 

Prepositions 

Here is a fairly complete list of prepositions: 

(word above prep) (word about prep) (word around prep) 
(word across prep) (word after prep) (word against prep) 
(word along prep) (word at prep) (word away prep) 
(word before prep) (word behind prep) (word below prep) 

(word beyond prep) (word by prep) (word down prep) 
(word for prep) (word from prep) (word in prep) 
(word of prep) (word off prep) (word on prep) 
(word out prep) (word over prep) (word past prep) 

(word since prep) (word through prep)(word throughout prep) 

(word till prep) (word to prep) (word under prep) 

(word until prep) (word up prep) (word with prep) 

(word without prep) 

21.12 Supporting the Lexicon 
This section describes the implementation of the macros word, verb, noun, and 
abbrev. Abbreviations are stored in a hash table. The macro abbrev and the functions 
get-abbrev and clear-abbrevs define the interface. We will see how to expand 
abbreviations later. 


<a id='page-740'></a>

(defvar *abbrevs* (make-hash-table)) 

(defmacro abbrev (symbol definition) 
"Make symbol be an abbreviation for definition." 

'(setf (gethash '.symbol *abbrevs*) '.definition)) 
(defun clear-abbrevs () (clrhash *abbrevs*)) 
(defun get-abbrev (symbol) (gethash symbol *abbrevs*)) 

Words are also stored in a hash table. Currently, words are symbols, but it might 
bea better idea to use strings for words, since then we could maintain capitalization 
information. The macro word or the function add-word adds a word to the lexicon. 
When used as an index into the hash table, each word returns a list of entries, where 
the first element of each entry is the word's category, and the other elements depend 
on the category. 

(defvar *words* (make-hash-table :size 500)) 

(defmacro word (word cat &rest info) 
"Put word, with category and subcat info, into lexicon." 
'(add-word '.word '.cat ..(mapcar #'kwote info))) 

(defun add-word (word cat &rest info) 
"Put word, with category and other info, into lexicon." 
(push (cons cat (mapcar #'expand-abbrevs-and-variables info)) 

(gethash word *words*)) 
word) 

(defun kwote (x) (list 'quote x)) 

The function expand-abbrevs-and-variables expands abbreviations and substitutes 
variable structures for symbols beginning with ?. This makes it easier to make 
a copy of the structure, which will be needed later. 

(defun expand-abbrevs-and-variables (exp) 
"Replace all variables in exp with vars, and expand abbrevs." 
(let ((bindings nil)) 

(labels 
((expand (exp) 

(cond 
((lookup exp bindings)) 
((eq exp '?) (?)) 
((variable-p exp) 

(let ((var (?))) 
(push (cons exp var) bindings) 
var)) 

((consp exp) 
(reuse-cons (expand (first exp)) 


<a id='page-741'></a>
(expand (rest exp)) 
exp)) 
(t (multiple-value-bind (expansion found?) 
(get-abbrev exp) 

(if found? 
(expand-abbrevs-and-variables expansion) 
exp)))))) 

(expand exp)))) 

Now we can store words in the lexicon, but we need some way of getting them out. 
The function word/. takes a word (which must be instantiated to a symbol) and a 
category and optional additional information and finds the entries in the lexicon for 
that word that unify with the category and additional information. For each match, 
it calls the supplied continuation. This means that word/. is a replacement for a long 
list of word facts. There are three differences: word/n hashes, so it will be faster; it is 
incremental (you can add a word at a time without needing to recompile); and it can 
not be used when the word is unbound. (It is not difficult to change it to handle an 
unbound word using maphash, but there are better ways of addressing that problem.) 

(defun word/n (word cat cont &rest info) 
"Retrieve a word from the lexicon." 
(unless (unbound-var-p (deref word)) 

(let ((old-trail (fil 1-pointer nrail*))) 
(dolist (old-entry (gethash word *words*)) 
(let ((entry (deref-copy old-entry))) 

(when (and (consp entry) 
(unify! cat (first entry)) 
(unify! info (rest entry))) 

(funcall cont))) 
(undo-bindings! old-trail))))) 

Note that word/n does not follow our convention of putting the continuation last. 
Therefore, we will need the following additional functions: 

(defun word/2 (w cat cont) (word/n w cat cont)) 
(defun word/3 (w cat a cont) (word/n w cat cont a)) 
(defun word/4 (w cat a b cont) (word/n w cat cont a b)) 
(defun word/5 (w cat a b c cont) (word/n w cat cont a b c)) 
(defun word/6 (w cat a b c d cont) (word/n w cat cont a bed)) 

We could create the whole lexicon with the macro word, but it is convenient to create 
specific macros for some classes. The macro noun is used to generate two entries, one 
for the singular and one for the plural. The arguments are the base noun, optionally 
followed by the plural (which defaults to the base plus "s"), the semantics (which 


<a id='page-742'></a>

defaults to the base), and a list of complements. Mass nouns, like "furniture," have 
only one entry, and are marked by an asterisk where the plural would otherwise be. 

(defmacro noun (base &rest args) 
"Add a noun and its plural to the lexicon." 
*(add-noun-form '.base ,(mapcar #'kwote args))) 

(defun add-noun-form (base &optional (plural (symbol base 's)) 
(sem base) &rest slots) 

(if (eq plural '*) 
(add-word base 'noun *? slots sem) 
(progn 

(add-word base 'noun '3sing slots sem) 
(add-word plural 'noun '3plur slots sem)))) 

Verbs are more complex. Each verb has seven entries: the base or nonfinite, the 
present tense singular and plural, the past tense, the past-participle, the present-
participle, and the passive. The macro verb automatically generates all seven entries. 
Verbs that do not have all of them can be handled by individual calls to word. We 
automatically handle the spelling for the simple cases of adding "s," "ing," and "ed," 
and perhaps stripping a trailing vowel. More irregular spellings have to be specified 
explicitly. Here are three examples of the use of verb: 

(verb (do did done doing does) (perform v/trans)) 
(verb (eat ate eaten) (eat v/trans)) 

(verb (trust) (trust v/trans ((agt 1 (NP ?)) (obj 2 (PP in ?))))) 

And here is the macro definition: 

(defmacro verb ((base &rest forms) &body senses) 
"Enter a verb into the lexicon." 

'(add-verb '.senses '.base .(mapcar #'kwote (mklist forms)))) 
(defun add-verb (senses base &optional 
(past (symbol (strip-vowel base) 'ed)) 
(past-part past) 
(pres-part (symbol (strip-vowel base) 'ing)) 
(plural (symbol base 's))) 

"Enter a verb into the lexicon." 
(add-word base 'verb 'nonfinite senses) 
(add-word base 'verb '(finite ~3sing present) senses) 
(add-word past 'verb '(finite ? past) senses) 
(add-word past-part 'verb '-en senses) 
(add-word pres-part 'verb '-ing senses) 
(add-word plural 'verb '(finite 3sing present) senses) 
(add-word past-part 'verb 'passive 


<a id='page-743'></a>
(mapcar #'passivize-sense 
(expand-abbrevs-and-vari ables senses)))) 

This uses a few auxiliary functions. First, stri p-vowel removes a vowel if it is the 
last character of the given argument. The idea is that for a verb like "fire," stripping 
the vowel yields "fir," from which we can get "fired" and "firing" automatically. 

(defun strip-vowel (word) 
"Strip off a trailing vowel from a string." 
(let* ((str (string word)) 

(end (- (length str) 1))) 

(if (vowel-p (char str end)) 
(subseq str 0 end) 
str))) 

(defun vowel-p (char) (find char "aeiou" :test #'char-equal)) 

We also provide a function to generate automatically the passive sense with the 
proper complement list(s). The idea is that the subject slot of the active verb becomes 
an optional slot marked by the preposition "by," and any slot that is marked with 
number 2 can be promoted to become the subject: 

(defun passivize-sense (sense) 
The first element of sense is the semantics; rest are slots 
(cons (first sense) (mapcan #*passivize-subcat (rest sense)))) 

(defun passivize-subcat (slots) 

"Return a list of passivizations of this subcat frame." 
Whenever the 1 slot is of the form (?any 1 (NP ?)), 
demote the 1 to a (3), and promote any 2 to a 1. 

(when (and (eql (slot-number (first slots)) 1) 
(starts-with (third (first slots)) 'NP)) 
(let ((old-1 .(,(first (first slots)) (3) (PP by ?)))) 

(loop for slot in slots 
when (eql (slot-number slot) 2) 
collect '((.(first slot) 1 .(third slot)) 

,@(remove slot (rest slots)) 
.old-1))))) 

(defun slot-number (slot) (first-or-self (second slot))) 

Finally, we provide a special function just to define the copula, "be." 


<a id='page-744'></a>

(defun copula (senses entries) 
"Copula entries are both aux and main verb." 
They also are used in passive verb phrases and aux-inv-S 

(dolist (entry entries) 
(add-word (first entry) 'aux (second entry) (third entry)) 
(add-word (first entry) 'verb (second entry) senses) 
(add-word (first entry) 'aux (second entry) 'passive) 
(add-word (first entry) 'be))) 

The remaining functions are used for testing, debugging, and extending the grammar. 
First, we need functions to clear everything so that we can start over. These functions 
can be placed at the top of the lexicon and grammar files, respectively: 

(defun clear-lexicon () 
(clrhash *words*) 
(clear-abbrevs)) 

(defun clear-grammar () 
(clear-examples) 
(clear-db)) 

Testing could be done with run-exampl es, but it is convenient to provide another 
interface, the macro try (and its corresponding function, try-dcg). Both macro and 
function can be invoked three ways. With no argument, all the examples stored by 
: ex are run. When the name of a category is given, all the examples for that category 
alone are run. Finally, the user can supply both the name of a category and a list of 
words to test whether those words can be parsed as that category. This option is only 
available for categories that are listed in the definition: 

(defmacro try (&optional cat &rest words) 
"Tries to parse WORDS as a constituent of category CAT. 
With no words, runs all the :ex examples for category. 
With no cat. runs all the examples." 
'(try-dcg '.cat '.words)) 

(defun try-dcg (&optional cat words) 
"Tries to parse WORDS as a constituent of category CAT. 
With no words, runs all the :ex examples for category. 
With no cat. runs all the examples." 
(if (null words) 

(run-examples cat) 

(let ((args '((gap nil) (gap nil) ?sem .words ()))) 
(mapc #'test-unknown-word words) 
(top-level-prove 

(ecase cat 
(np '((np ? ? ?wh ?x .args))) 


<a id='page-745'></a>
(vp '((vp ?infl ?x ?sl ?v ,@args))) 
(pp '((pp ?prep ?role ?wh ?x ,@args))) 
(xp *((xp ?slot ?constituent ?wh ?x .args))) 
(s *((s ? ?sem .words ()))) 
(rel-clause '((rel-clause ? ?x ?sem .words ()))) 
(clause '((clause ?infl ?x ?int-subj ?v ?gl ?g2 

?sem .words ())))))))) 

(defun test-unknown-word (word) 
"Print a warning message if this is an unknown word." 
(unless (or (gethash word *words*) (numberp word)) 

(warn ""&Unknown word: ~a" word))) 

21.13 Other Primitives 
To support the -.test predicates made in various grammar rules we need definitions 
of the Prolog predicates i f, member, =, numberp, and atom. They are repeated here: 

(<- (if ?test ?then) (if ?then ?else (fail))) 
(<- (if ?test ?then ?else) (call ?test) ! (call ?then)) 
(<- (if ?test ?then ?else) (call ?else)) 

(<- (member ?item (?item . ?rest))) 

(<- (member ?item (?x . ?rest)) (member ?item ?rest)) 

(<- (= ?x ?x)) 

(defun numberp/1 (x cont) 
(when (numberp (deref x)) 
(funcall cont))) 

(defun atom/1 (x cont) 
(when (atom (deref x)) 
(funcall cont))) 

(defun cal 1/1 (goal cont) 
"Try to prove goal by calling it." 
(deref goal) 
(apply (make-predicate (first goal) 

(length (args goal))) 
(append (args goal) (list cont)))) 


<a id='page-746'></a>

21.14 Examples 
Here are some examples of what the parser can handle. I have edited the output 
by changing variable names like ? 168 to more readable names like ?J. The first 
two examples show that nested clauses are supported and that we can extract a 
constituent from a nested clause: 

> (try S John promised Kim to persuade Lee to sleep) 

?SEM = (AND (THE ?J (NAME JOHN ?J)) (AGT ?P ?J) 
(PAST ?P) (PROMISE ?P) 
(GOAL ?P ?K) (THE ?K (NAME KIM ?K)) 
(CON ?P ?PER) (PERSUADE ?PER) (GOAL ?PER ?L) 
(THE ?L (NAME LEE ?L)) (CON ?PER ?S) (SLEEP ?S)); 

> (try S Who did John promise Kim to persuade to sleep) 

?SEM = (AND (WH ?W (PERSON ?W)) (PAST ?P) 
(THE ?J (NAME JOHN ?J)) (AGT ?P ?J) 
(PROMISE ?P) (GOAL ?P ?K) 
(THE ?K (NAME KIM ?K)) (CON ?P ?PER) 
(PERSUADE ?PER) (GOAL ?PER ?W) 
(CON ?PER ?S) (SLEEP ?S)); 

In the next example, the "when" can be interpreted as asking about the time of any of 
the three events: the promising, the persuading, or the sleeping. The grammar finds 
all three. 

> (try S When did John promise Kim to persuade Lee to sleep) 

?SEM = (AND (WH ?W (TIME ?S ?W)) (PAST ?P) 
(THE ?J (NAME JOHN ?J)) (AGT ?P ?J) 
(PROMISE ?P) (GOAL ?P ?K) 
(THE ?K (NAME KIM ?K)) (CON ?P ?PER) 
(PERSUADE ?PER) (GOAL ?PER ?L) 
(THE ?L (NAME LEE ?L)) (CON ?PER ?S) 
(SLEEP ?S)); 

?SEM = (AND (WH ?W (TIME ?PER ?W)) (PAST ?P) 
(THE ?J (NAME JOHN ?J)) (AGT ?P ?J) 
(PROMISE ?P) (GOAL ?P ?K) 
(THE ?K (NAME KIM ?K)) (CON ?P ?PER) 
(PERSUADE ?PER) (GOAL ?PER ?L) 
(THE ?L (NAME LEE ?L)) (CON ?PER ?S) 
(SLEEP ?S)); 


<a id='page-747'></a>
?SEM = (AND (WH ?W (TIME ?P ?W)) (PAST ?P) 
(THE ?J (NAME JOHN ?J)) (AGT ?P ?J) 
(PROMISE ?P) (GOAL ?P ?K) 
(THE ?K (NAME KIM ?K)) (CON ?P ?PER) 
(PERSUADE ?PER) (GOAL ?PER ?L) 
(THE ?L (NAME LEE ?L)) (CON ?PER ?S) 
(SLEEP ?S)). 

The next example shows auxiliary verbs and negation. It is ambiguous between 
an interpretation where Kim is searching for Lee and one where Kim is looking at 
something unspecified, on Lee's behalf. 

> (try S Kim would not have been looking for Lee) 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?S ?K) 
(EXPECTED ?S) (NOT ?S) (PAST-PARTICIPLE ?S) 
(PROGRESSIVE ?S) (SEARCH ?S) (PAT ?S ?L) 
(PAT ?S ?L) (THE ?L (NAME LEE ?L))); 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?2 ?K) 
(EXPECTED ?2) (NOT ?2) (PAST-PARTICIPLE ?LOOK) 
(PROGRESSIVE ?LOOK) (LOOK ?LOOK) (FOR ?LOOK ?L) 
(THE ?L (NAME LEE ?L))); 

The next two examples are unambiguous: 

> (try s It should not surprise you that Kim does not like Lee) 

?SEM = (AND (MANDATORY ?2) (NOT ?2) (SURPRISE ?2) (EXP ?2 ?YOU) 
(PRO ?YOU (LISTENER ?YOU)) (CON ?2 ?LIKE) 
(THE ?K (NAME KIM ?K)) (AGT ?LIKE ?K) 
(PRESENT ?LIKE) (NOT ?LIKE) (LIKE-1 ?LIKE) 
(OBJ ?LIKE ?L) (THE ?L (NAME LEE ?L))); 

> (try s Kim did not want Lee to know that the man knew her) 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?W ?K) (PAST ?W) 
(NOT ?W) (DESIRE ?W) (GOAL ?W ?L) 
(THE ?L (NAME LEE ?L)) (CON ?W ?KN) 
(KNOW-THAT ?KN) (CON ?KN ?KN2) 
(THE ?M (MAN ?M)) (AGT ?KN2 ?M) (PAST ?KN2) 
(KNOW-OF ?KN2) (OBJ ?KN2 ?HER) 
(PRO ?HER (FEMALE ?HER))). 

The final example appears to be unambiguous, but the parser finds four separate 
parses. The first is the obvious interpretation where the looking up is done quickly, 
and the second has quickly modifying the surprise. The last two interpretations are 
the same as the first two; they are artifacts of the search process. A disambiguation 
procedure should be equipped to weed out such duplicates. 


<a id='page-748'></a>

> (try s That Kim looked her up quickly surprised me) 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?LU1 ?K) (PAST ?LU1) 
(LOOK-UP ?LU1) (PAT ?LU1 ?H) (PRO ?H (FEMALE ?H)) 
(QUICKLY ?LU1) (CON ?S ?LU1) (PAST ?S) (SURPRISE ?S) 
(EXP ?S ?ME1) (PRO ?ME1 (SPEAKER ?ME1))); 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?LU2 ?K) (PAST ?LU2) 
(LOOK-UP ?LU2) (PAT ?LU2 ?H) (PRO ?H (FEMALE ?H)) 
(CON ?S ?LU2) (QUICKLY ?S) (PAST ?S) (SURPRISE ?S) 
(EXP ?S ?ME2) (PRO ?ME2 (SPEAKER ?ME2))); 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?LU3 ?K) (PAST ?LU3) 
(LOOK-UP ?LU3) (PAT ?LU3 ?H) (PRO ?H (FEMALE ?H)) 
(QUICKLY ?LU3) (CON ?S ?LU3) (PAST ?S) (SURPRISE ?S) 
(EXP ?S ?ME3) (PRO ?ME3 (SPEAKER ?ME3))); 

?SEM = (AND (THE ?K (NAME KIM ?K)) (AGT ?LU4 ?K) (PAST ?LU4) 
(LOOK-UP ?LU4) (PAT ?LU4 ?H) (PRO ?H (FEMALE ?H)) 
(CON ?S ?LU4) (QUICKLY ?S) (PAST ?S) (SURPRISE ?S) 
(EXP ?S ?ME4) (PRO ?ME4 (SPEAKER ?ME4))): 

21.15 History and References 
Chapter 20 provides some basic references on natural language. Here we will concentrate 
on references that provide: 

1. A comprehensive grammar of English. 
2. A complete implementation. 
There are a few good textbooks that partially address both issues. Both Winograd 
(1983) and Allen (1987) do a good job of presenting the major grammatical features of 
English and discuss implementation techniques, but they do not provide actual code. 

There are also a few textbooks that concentrate on the second issue. Ramsey and 
Barrett (1987) and Walker et al. (1990) provide chapter-length implementations at 
about the same level of detail as this chapter. Both are recommended. Pereira and 
Shieber 1987 and Gazdar and Mellish 1989 are book-length treatments, but because 
they cover a variety of parsing techniques rather than concentrating on one in depth, 
they are actually less comprehensive. 

Several linguists have made serious attempts at addressing the first issue. The 
largest is the aptly namedA Comprehensive Grammar of Contemporary English by Quirk, 
Greenbaum, Leech and Svartik (1985). More manageable (although hardly concise) 
is their abridged edition, A Concise Grammar of Contemporary English. Both editions 
contain a gold mine of examples and facts about the English langauge, but the authors 


<a id='page-749'></a>
do not attempt to write rigorous rules. Harris (1982) and Huddleston (1984) offer 
less complete grammars with greater linguistic rigor. 

Naomi Sager (1981) presents the most complete computerized grammar ever 
published. The grammar is separated into a simple, neat, context-free component 
and a rather baroque augmentation that manipulates features. 

21.16 Exercises 
&#9635; Exercise 21.1 [m] Change the grammar to account better for mass nouns. The current 
grammar treats mass nouns by making them vague between singular and plural, 
which is incorrect. They should be treated separately, since there are determiners 
such as "much" that work only with mass nouns, and other determiners such as 
"these" that work only with plural count nouns. 

&#9635; Exercise 21.2 [m] Change the grammar to make a distinction between attributive 
and predicative adjectives. Most adjectives fall into both classes, but some can be used 
only attributively, as in "an utter fool" but not" * the fool is utter." Other adjectives can 
only be used predicatively, as in "the woman was loath to admit it" but not "*a loath 
(to admit it) woman." 

&#9635; Exercise 21.3 Pi] Implement complement lists for adjectives, so that "loath" would 
take an obligatory infinitive complement, and "proud" would take an optional (PP 
of) complement. In connection to the previous exercise, note that it is rare if not 
impossible for attributive adjectives to take complements: "he is proud," "he is proud 
of his country" and "a proud citizen" are all acceptable, but "*a proud of his country 
citizen" is not. 

&#9635; Exercise 21.4 [m] Add rules to advp to allow for adverbs to modify other adverbs, 
as in "extremely likely" or "very strongly." 

&#9635; Exercise 21.5 [h] Allow adverbs to modify adjectives, as in "very good" or "really 
delicious." The syntax will be easy, but it is harder to get a reasonable semantics. 
While you're at it, make sure that you can handle adjectives with so-called nonintersective 
semantics. Some adjectives can be handled by intersective semantics: a red 
circle is something that is red and is a circle. But for other adjectives, this model 
does not work: a former senator is not something that is former and is a senator - 
former senator is not a senator at all. Similarly, a toy elephant is not an elephant. 


<a id='page-750'></a>

The semantics should be represented by something closer to ((toy elephant) ?x) 
rather than (and (toy ?x) (elephant ?x)). 
&#9635; Exercise 21.6 [m] Write a function that notices punctuation instead of ignoring it. 
It should work something like this: 
> (string->words "Who asked Lee. Kim and John?") 
(WHO ASKED LEE I.I KIM AND JOHN l?l ) 

&#9635; Exercise 21.7 [m] Change the grammar to allow optional punctuation marks at the 
end of sentences and before relative clauses. 

&#9635; Exercise 21.8 [m] Change the grammar to allow conjunction with more than two 
elements, using commas. Can these rules be generated automatically by conj rule? 

&#9635; Exercise 21.9 [h] Make a distinction between restrictive and nonrestrictive relative 
clauses. In "The truck that has 4-wheel drive costs $5000," the italicized relative clause 
is restrictive. It serves to identify the truck and thus would be part of the quantifier's 
restriction. The complete sentence might be interpreted as: 
(and (the ?x (and (truck ?x) (4-wheel-drive ?x))) 
(costs ?x $5000)) 
Contrast this to "The truck, which has 4-wheel drive, costs $5000." Here the relative 
clause is nonrestrictive and thus belongs outside the quantifier's restriction: 
(and (the ?x (truck ?x)) 
(4-wheel-drive ?x)(cost s ?x $5000)) 


## Chapter 22
<a id='page-753'></a>

Scheme: An Uncommon Lisp 

The best laid schemes o' mice an' men 

-Robert Burns (1759-1796) 

r I 1 his chapter presents the Scheme dialect of Lisp and an interpreter for it. While it is not 

I likely that you would use this interpreter for any serious programming, understanding 

JL how the interpreter works can give you a better appreciation of how Lisp works, and 
thus make you a better programmer. A Scheme interpreter is used instead of a Common Lisp 
one because Scheme is simpler, and also because Scheme is an important language that is worth 
knowing about. 

Scheme is the only dialect of Lisp besides Common Lisp that is currently flourishing. Where 
Common Lisp tries to standardize all the important features that are in current use by Lisp 
programmers. Scheme tries to give a minimal set of very powerful features that can be used to 
implement the others. It is interesting that among all the programming languages in the world. 
Scheme is one of the smallest, while Common Lisp is one of the largest. The Scheme manual 
is only 45 pages (only 38 if you omit the example, bibliography, and index), while Common Lisp 
the Language, 2d edition, is 1029 pages. Here is a partial list of the ways Scheme is simpler than 
Common Lisp: 


<a id='page-754'></a>

1. Scheme has fewer buUt-in functions and special forms. 
2. Scheme has no special variables, only lexical variables. 
3. Scheme uses the same name space for functions and variables (and everything 
else). 
4. Scheme evaluates the function part of a function call in exactly the same way 
as the arguments. 
5. Scheme functions can not have optional and keyword parameters. However, 
they can have the equivalent of a &rest parameter. 
6. Scheme has no block, return, go, or throw; a single function (cal 1 /cc) replaces 
all of these (and does much more). 
7. Scheme has no packages. Lexical variables can be used to implement packagelike 
structures. 
8. Scheme, as a standard, has no macros, although most implementations provide 
macros as an extension. 
9. Scheme has no special forms for looping; instead it asks the user to use recursion 
and promises to implement the recursion efficiently. 
The five main special forms in Scheme are quote and if, which are just as in 
Common Lisp; begin and setl, which are just different spellings for progn and 
setq; and 1 ambda, which is as in Common Lisp, except that it doesn't require a 
#' before it. In addition. Scheme allows variables, constants (numbers, strings, and 
characters), and function calls. The function call is different because the function 
itself is evaluated in the same way as the arguments. In Common Lisp, (fx) means 
to look up the function binding of f and apply that to the value of x. In Scheme, (fx) 
means to evaluate f (in this case by looking up the value of the variable f), evaluate 
X (by looking up the value of the variable in exactly the same way) and then apply 
the function to the argument. Any expression can be in the function position, and 
it is evaluated just like the arguments. Another difference is that Scheme uses #t 
and #f for true and false, instead of t and nil. The empty list is denoted by (), and 
it is distinct from the false value, #f. There are also minor lexical differences in the 
conventions for complex numbers and numbers in different bases, but these can be 
ignored for all the programs in this book. Also, in Scheme a single macro, def i ne, 
serves to define both variables and functions. 


<a id='page-755'></a>

Scheme Common Lisp 

var var 

constant constant 

(quotes) or *x (quotes) or 'x 

(beginx..) (progn X..) 

(set! varx) (setq varx) 

(ifpab) (ifpab) 

(lambda parms x...) #'( 1 ambda parmsx...) 

{fn arg.) (fnarg...) or (funcall fnarg...) 

#t t 

#f nil 

() nil 

(define varexp) (defparameter varexp) 

(define ifnparm...) body) (defun fniparm...) body) 

&#9635; Exercise 22.1 [s] What does the following expression evaluate to in Scheme? How 
many errors does it have as a Common Lisp expression? 

((if (= (+ 2 2) 4) 
(lambda (x y) (+ (* . y) 12)) 
cons) 

5 

6) 

A great many functions, such as car, cdr, cons, append, +, *, and list are 
the same (or nearly the same) in both dialects. However, Scheme has some spelling 
conventions that are different from Common Lisp. Most Scheme mutators, like 
set!, end in'!'. Common Lisp has no consistent convention for this; some mutators 
start with . (nreverse, nsubst, nintersection) while others have idiosyncratic 
names (del ete versus remove). Scheme would use consistent names - reverse! and 
remove! - if these functions were defined at all (they are not defined in the standard). 
Most Scheme predicates end in '?', not 'p'. This makes predicates more obvious 
and eliminates the complicated conventions for adding a hyphen before the p.^ The 
only problem with this convention is in spoken language: is equal ? pronounced 
"equal-question-mark" or "equal-q" or perhaps equal, with rising intonation? This 
would make Scheme a tone language, like Chinese. 

^One writes numberp because there is no hyphen in number but random-state-. because 
there is a hyphen in random-state. However, defstruct concatenates -p in all its predicates, 
regardless of the presence of a hyphen in the structure's name. 


<a id='page-756'></a>

In Scheme, it is an error to apply car or cdr to the empty list. Despite the fact that 
Scheme has cons, it calls the result a pai r rather than a cons cell, so the predicate is 
pair?, not consp. 

Scheme recognizes not all lambda expressions will be "functions" according to 
the mathematical definition of function, and so it uses the term "procedure" instead. 
Here is a partial list of correspondences between the two dialects: 

Scheme Procedure Common Lisp Ftmction 

char-ready? listen 
char? characterp 
eq? eq 
equal? equal 
eqv? eql 
even? evenp 
for-each mapc 
integer? integerp 
list->string coerce 
list->vector coerce 
list-ref nth 
list-tail nthcdr 
map mapcar 
negative? minusp 
pair? consp 
procedure? functionp 
set! setq 
set-car! replaca 
vector-set! setf 
string-set! setf 

22.1 A Scheme Interpreter 
As we have seen, an interpreter takes a program (or expression) as input and returns 
the value computed by that program. The Lisp function eval is thus an interpreter, 
and that is essentially the function we are trying to write in this section. We have 
to be careful, however, in that it is possible to confuse the notions of interpreter and 
compiler. A compiler takes a program as input and produces as output a translation 
of that program into some other language - usually a language that can be directly 
(or more easily) executed on some machine. So it is also possible to write eval by 
compiling the argument and then interpreting the resulting machine-level program. 
Most modern Lisp systems support both possibilities, although some only interpret 


<a id='page-757'></a>
code directly, and others compile all code before executing it. To make the distinction 
clear, we will not write a function called eval. Instead, we will write versions of two 
functions: interp, a Scheme interpreter, and, in the next chapter, comp, a Scheme 
compiler. 

An interpreter that handles the Scheme primitives is easy to write. In the interpreter 
interp, the main conditional has eight cases, corresponding to the five 
special forms, symbols, other atoms, and procedure applications (otherwise known 
as function calls). For the moment we will stick with t and .i 1 instead of #t and 
#f. After developing a simple interpreter, we will add support for macros, then 
develop a tail-recursive interpreter, and finally a continuation-passing interpreter. 
(These terms will be defined when the time comes.). The glossary for i nterp is in 
figure 22.1. 

scheme 
interp 
def-scheme-macro 

*scheme-procs* 

set-var! 
get-var 
set-global-var! 

get-global-var 
extend-env 
init-scheme-interp 
init-scheme-proc 
scheme-macro 
scheme-macro-expand 
maybe-add 
print-proc 

proc 

interp-begin 
interp-call 
map-interp 
call/cc 

lastl 
length=1 

Top-Level Fimctions 

A Scheme read-interp-print loop. 
Interpret (evaluate) an expression in an environment. 
Define a Scheme macro. 

Special Variables 

Some procedures to store in the global environment. 

Auxiliary Functions 

Set a variable to a value. 
Get the value of a variable in an environment. 
Set a global variable to a value. 

Get the value of a variable fron the global environment. 
Add some variables and values to an environment. 
Initialize some global variables. 
Define a primitive Scheme procedure. 
Retrieve the Scheme macro for a symbol. 
Macro-expand a Scheme expression. 
Add an element to the front of a non-singleton list. 
Print a procedure. 

Data Type (tail-recursive version only) 

A Scheme procedure. 

Functions (continuation version only) 

Interpret a begi . expression. 
Interpret a function application. 
Map i nterp over a list. 
call with current continuation. 

Previously Defined Functions 

Select the last element of a list. 
Is this a list of length1? 

Figure 22.1: Glossary for the Scheme Interpreter 


<a id='page-758'></a>

The simple interpreter has eight cases to worry about: (1) If the expression is a 
symbol, look up its value in the environment. (2) If it is an atom that is not a symbol 
(such as a number), just return it. Otherwise, the expression must be a list. (3) If it 
starts with quote, return the quoted expression. (4) If it starts with beg i ., interpret 
each subexpression, and return the last one. (5) If it starts with set 1, interpret the 
value and then set the variable to that value. (6) If it starts with i f, then interpret 
the conditional, and depending on if it is true or not, interpret the then-part or the 
else-part. (7) If it starts with 1 ambda, build a new procedure - a closure over the ctu*rent 
environment. (8) Otherwise, it must be a procedure application. Interpret the 
procedure and all the arguments, and apply the procedure value to the argument 
values. 

(defun interp (x &optiona1 env) 

"Interpret (evaluate) the expression . in the environment env." 

(cond 

((symbolp x) (get-var . env)) 

((atom x) x) 

((case (first x) 

(QUOTE (second x)) 
(BEGIN (lastl (mapcar #*(lambda (y) (interp y env)) 
(rest x)))) 
(SET! (set-var! (second x) (interp (third x) env) env)) 
(IF (if (interp (second x) env) 
(interp (third x) env) 
(interp (fourth x) env))) 

(LAMBDA (let ((parms (second x)) 
(code (maybe-add 'begin (rest2 x)))) 
#*(lambda (&rest args) 
(interp code (extend-env parms args env))))) 
(t ;; a procedure application 
(apply (interp (first x) env) 
(mapcar #'(lambda (v) (interp . env)) 
(rest x)))))))) 

An environment is represented as an association list of variable/value pairs, except 
for the global environment, which is represented by values on the gl obal - val 
property of symbols. It would be simpler to represent the global environment 
in the same way as local environments, but it is more efficient to use property 
lists than one big global a-list. Furthermore, the global environment is distinct 
in that every symbol is implicitly defined in the global environment, while local 
environments only contain variables that are explicitly mentioned (in a 1 ambda expression). 



<a id='page-759'></a>
As an example, suppose we interpret the function call (f 1 2 3), and that the 
functions f has been defined by the Scheme expression: 

(set! f (lambda (a b c) (+ a (g b c)))) 

Then we will interpret (f 1 2 3) by interpreting the body of f with the environment: 

((a 1) (b 2) (c 3)) 

Scheme procedures are implemented as Common Lisp functions, and in fact all the 
Scheme data types are implemented by the corresponding Common Lisp types. I 
include the function i .i t -s eherne - i . te rp to initialize a few global values and repeat 
the definitions of last1 and length=1: 

(defun set-var! (var val env) 
"Set a variable to a value, in the given or global environment." 
(if (assoc var env) 

(setf (second (assoc var env)) val) 
(set-global-var! var val)) 
val) 

(defun get-var (var env) 
"Get the value of a variable, from the given or global environment, 

(if (assoc var env) 
(second (assoc var env)) 
(get-global-var var))) 

(defun set-global-var! (var val) 
(setf (get var 'global-val) val)) 

(defun get-global-var (var) 
(let* ((default "unbound") 
(val (get var 'global-val default))) 

(if (eq val default) 
(error "Unbound scheme variable: '"a" var) 
val))) 

(defun extend-env (vars vals env) 
"Add some variables and values to an environment." 
(nconc (mapcar #'list vars vals) env)) 

(defparameter *scheme-procs* 

.(+-'/=<><=>= cons car cdr not append list read member 
(null? null) (eq? eq) (equal? equal) (eqv? eql) 
(write prinl) (display princ) (newline terpri))) 


<a id='page-760'></a>

(defun init-scheme-interp () 
"Initialize the scheme interpreter with some global variables." 
Define Scheme procedures as CL functions: 
(mapc #*init-scheme-proc *scheme-procs*) 

Define the Boolean 'constants*. Unfortunately, this won't 
;; stop someone from saying: (setl t nil) 
(set-global-var! t t) 
(set-global-vari nil nil)) 

(defun init-scheme-proc (f) 
"Define a Scheme procedure as a corresponding CL function." 
(if (listp f) 

(set-global-var! (first f) (symbol-function (second f))) 
(set-global-var! f (symbol-function f)))) 

(defun maybe-add (op exps &optional if-nil) 
"For example, (maybe-add 'and exps t) returns 
t if exps is nil, exps if there is only one, 
and (and expl exp2...) if there are several exps." 
(cond ((null exps) if-nil) 

((length=1 exps) (first exps)) 
(t (cons op exps)))) 

(defun length=1 (x) 
"Is X a list of length 1?" 
(and (consp x) (null (cdr x)))) 

(defun lastl (list) 
"Return the last element (not last cons cell) of list" 
(first (last list))) 

To test the interpreter, we add a simple read-eval-print loop: 

(defun scheme () 
"A Scheme read-eval-print loop (using interp)" 
(init-scheme-interp) 
(loop (format t ""&==> ") 

(print (interp (read) nil)))) 

And now we're ready to try out the interpreter. Note the Common Lisp prompt is 
">," while the Scheme prompt is "==>." 

> (scheme) 
==> (+ 2 2) 
4 

==> ((if (= 1 2) * +) 3 4) 
7 


<a id='page-761'></a>

= => ((if (= 1 1) * +) 3 4) 
12 

==> (setl fact (lambda (n) 
(if (= . 0) 1 
(* . (fact (- . 1)))))) 
#<DTP-LEXICAL-CLOSURE 36722615> 

==> (fact 5) 
120 

==> (setl table (lambda (f start end) 
(if (<= start end) 

(begin 
(write (list start (f start))) 
(newline) 
(table f (+ start 1) end))))) 

#<DTP-LEXICAL-CLOSURE 41072172> 

==> (table fact 1 10) 
(1 1) 
(2 2) 
(3 6) 
(4 24) 
(5 120) 
(6 720) 
(7 5040) 
(8 40320) 
(9 362880) 

(10 3628800) 

NIL 

==> (table (lambda (x) (* . . .)) 5 10) 
(5 125) 

(6 216) 
(7 343) 
(8 512) 
(9 729) 

(10 1000) 

NIL 

= => [ABORT] 


<a id='page-762'></a>

22.2 Syntactic Extension with Macros 
Scheme has a number of other special forms that were not listed above. Actually, 
Scheme uses the term "syntax" where we have been using "special form." The remaining 
syntax can be defined as "derived expressions" in terms of the five primitives. 
The Scheme standard does not recognize a concept of macros, but it is clear that a 
"derived expression" is like a macro, and we will implement them using macros. The 
following forms are used (nearly) identically in Scheme and Common Lisp: 

let let* and or do cond case 

One difference is that Scheme is less lenient as to what counts as a binding in let, 
let* and do. Every binding must be (var init); just (var) or var is not allowed. In do, 
a binding can be either (var init step) or (var init). Notice there is no do*. The other 
difference is in ca se and cond. Where Common Lisp uses the symbol t or otherwi se 
to mark the final case. Scheme uses el se. The final three syntactic extensions are 
unique to Scheme: 

(define var val) or (define (proc-name arg...) body...) 

(delay expression) 

(letrec {{varinit)...) body...) 

define is a combination of defun and defparameter. In its first form, it assigns a 
value to a variable. Since there are no special variables in Scheme, this is no different 
than using set!. (There is a difference when the def i ne is nested inside another 
definition, but that is not yet considered.) In the second form, it defines a function, 
del ay is used to delay evaluation, as described in section 9.3, [page 281](chapter9.md#page-281). letrec is 
similar to let. The difference is that all the init forms are evaluated in an environment 
that includes all the pars. Thus, letrec can be used to define local recursive functions, 
just as 1 abel s does in Common Lisp. 

The first step in implementing these syntactic extensions is to change i nterp to 
allow macros. Only one clause has to be added, but we'll repeat the whole definition: 

(defun interp (x &optional env) 

"Interpret (evaluate) the expression . in the environment env. 

This version handles macros." 

(cond 

((symbolp x) (get-var . env)) 

((atom x) x) 

((scheme-macro (first x)) ;*** 

(interp (scheme-macro-expand x) env)) ;*** 

((case (first x) 

(QUOTE (second x)) 


<a id='page-763'></a>
(BEGIN (last l (mapcar #'(lambda (y) (interp y env)) 
(rest X))) ) 
(SET! (set-var ! (second x) (interp (third x) env) env)) 
(IF (if (interp (second x) env) 
(interp (third x) env) 
(interp (fourth x) env))) 

(LAMBDA (let ((parms (second x)) 
(code (maybe-add 'begin (rest2 x)))) 
#'(lambda (&rest args) 
(interp code (extend-env parms args env))))) 
(t ;; a procedure application 
(apply (interp (first x) env) 
(mapcar #*(lambda (v) (interp . env)) 
(rest X)))))))) 

Now we provide a mechanism for defining macros. The macro definitions can be in 
any convenient language; the easiest choices are Scheme itself or Common Lisp. I 
have chosen the latter. This makes it clear that macros are not part of Scheme itself but 
rather are used to implement Scheme. If we wanted to offer the macro facility to the 
Scheme programmer, we would make the other choice. (But then we would be sure to 
add the backquote notation, which is so useful in writing macros.) def -s cheme - mac ro 
(which happens to be a macro itself) provides a way of adding new Scheme macros. 
It does that by storing a Common Lisp function on the scheme-macro property of 
a symbol. This^furiction, when given a list of ai-gumehts, returns the code that the 
macro call should expand into. The function scheme-macro tests if a symbol has a 
macro attached to it, and scheme-macro-expand does the actual macro-expansion: 

(defun scheme-macro (symbol) 
(and (symbolp symbol) (get symbol 'scheme-macro))) 

(defmacro def-scheme-macro (name parmlist &body body) 
"Define a Scheme macro." 
'(setf (get '.name 'scheme-macro) 

#'(lambda .parmlist ..body))) 

(defun scheme-macro-expand (x) 
"Macro-expand this Scheme expression." 
(if (and distp x) (scheme-macro (first x))) 

(scheme-macro-expand 
(apply (scheme-macro (first x)) (rest x))) 

X)) 


<a id='page-764'></a>

Here are the definitions of nine important macros in Scheme: 

(def-scheme-macro let (bindings &rest body) 
'((lambda ,(mapcar #'first bindings) . .body) 
..(mapcar #*second bindings))) 

(def-scheme-macro let* (bindings &rest body) 

(if (null bindings) 
'(begin ..body) 
'(let (.(first bindings)) 

(let* .(rest bindings) . .body)))) 

(def-scheme-macro and (&rest args) 

(cond ((null args) *T) 
((length=1 args) (first args)) 
(t '(if .(first args) 

(and . .(rest args)))))) 

(def-scheme-macro or (&rest args) 

(cond ((null args) 'nil) 
((length=1 args) (first args)) 
(t (let ((var (gensym))) 

'(let ((.var .(first args))) 
(if ,var .var (or . .(rest args)))))))) 
(def-scheme-macro cond (&rest clauses) 
(cond ((null clauses) nil) 
((length=1 (first clauses)) 
'(or .(first clauses) (cond ..(rest clauses)))) 
((starts-with (first clauses) 'else) 
'(begin ..(rest (first clauses)))) 

(t '(if .(first (first clauses)) 
(begin ..(rest (first clauses))) 
(cond ..(rest clauses)))))) 

(def-scheme-macro case (key &rest clauses) 
(let ((key-val (gensym "KEY"))) 
'(let ((.key-val .key)) 
(cond .(mapcar 
#*(lambda (clause) 

(if (starts-with clause 'else) 
clause 
'((member ,key-val '.(first clause)) 

..(rest clause)))) 
clauses))))) 

(def-scheme-macro define (name &rest body) 
(if (atom name) 
'(begin (setl .name . .body) '.name) 

'(define .(first name) 
(lambda .(rest name) . .body)))) 

<a id='page-765'></a>
(def-scheme-macro delay (computation) 
'(lambda () .computation)) 

(def-scheme-macro letrec (bindings &rest body) 

'(let .(mapcar #'(lambda (v) (list (first v) nil)) bindings) 
.(mapcar #*(lambda (v) '(set! ..v)) bindings) 
..body)) 

We can test out the macro faciUty: 

> (scheme-macro-expand '(and . q)) (IF . (AND Q)) 

> (scheme-macro-expand '(and q)) => Q 

> (scheme-macro-expand '(let ((x 1) (y 2)) (+ . y))) 
((LAMBDA (X Y) (+ . Y)) 1 2) 

> (scheme-macro-expand 
'(letrec 
((even? (lambda (.) (or (= . 0) (odd? (-. 1))))) 
(odd? (lambda (.) (even? (-. 1))))) 
(even? .))) 
(LET ((EVEN? NIL) 

(ODD? NIL)) 
(SET! EVEN? (LAMBDA (X) (OR (= X 0) (ODD? (-X 1))))) 
(SET! ODD? (LAMBDA (X) (EVEN? (- X 1)))) 
(EVEN? Z)) 

> (scheme) 
==> (define (reverse 1) 
(if (null? 1) nil 
(append (reverse (cdr 1)) (list (car 1))))) 
REVERSE 

==> (reverse '(a b c d)) 
(D C . A) 

==> (let* ((X 5) (y (+ x x))) 

(if (or (= x 0) (and (< O y) (< y 20))) 
(list X y) 
(+ y .))) 

(5 10) 

The macro def i ne is just like set !, except that it returns the symbol rather than the 
value assigned to the symbol. In addition, def i ne provides an optional syntax for 
defining functions - it serves the purposes of both defun and defvar. The syntax 

(define {fn. args). >7ody) is an abbreviation for (define (lambda args. body)). 


<a id='page-766'></a>

In addition. Scheme provides a notation where def i ne can be used inside a function 
definition in a way that makes it work like let rather than set!. 

The advantage of the macro-based approach to special forms is that we don't have 
to change the interpreter to add new special forms. The interpreter remains simple, 
even while the language grows. This also holds for the compiler, as we see in the next 
section. 

22.3 A Properly Tail-Recursive Interpreter 
Unfortunately, the interpreter presented above can not lay claim to the name Scheme, 
because a true Scheme must be properly tail-recursive. Our interpreter is tail-
recursive only when run in a Common Lisp that is tail-recursive. To see the problem, 
consider the following Scheme procedure: 

(define (traverse lyst) 
(if lyst (traverse (cdr lyst)))) 

Trace the function interp and execute (interp '(traverse '(a b c d))). The 
nested calls to i nterp go 16 levels deep. In general, the level of nesting is 4 plus 3 
times the length of the hst. Each call to interp requires Common Lisp to allocate 
some storage on the stack, so for very long lists, we will eventually run out of storage. 
To earn the name Scheme, a language must guarantee that such a program does not 
run out of storage. 

The problem, in this example, lies in two places. Everytime we interpret an i f 
form or a procedure call, we descend another recursive level into i nterp. But that 
extra level is not necessary. Consider the i f form. It is certainly necessary to call 
i nterp recursively to decide if the test is true or not. For the sake of argument, let's 
say the test is true. Thenwecall i nterp again on the i/zen part This recursive call will 
return a value, which will then be immediately returned as the value of the original 
call as well. 

The alternative is to replace the recursive call to interp with a renaming of 
variables, followed by a goto statement. That is, instead of calling interp and thereby 
binding a new instance of the variable . to the then part, we just assign the then part 
to X, and branch to the top of the i nterp routine. This works because we know we 
have no more use for the old value of x. A similar technique is used to eliminate the 
recursive call for the last expression in a beg i . form. (Many programmers have been 
taught the "structured programming" party line that goto statements are harmful. In 
this case, the goto is necessary to implement a low-level feature efficiently.) 


<a id='page-767'></a>
The final thing we need to do is explicitly manage Scheme procedures. Instead 
of implementing Scheme procedures as Common Lisp closures, we will define a 
structure, . roc, to contain the code, environment, parameter list, and optionally the 
name of the procedure. Then when we are evaluating a procedure call, we can assign 
the body of the procedure to x rather than recursively calling i nterp. 

(defstruct (proc (rprint-function print-proc)) 
"Represent a Scheme procedure" 
code (env nil) (name nil) (parms nil)) 

The following is a properly tail-recursive interpreter. The macro prog sets up a 
tagbody within which we can use go statements to branch to labels, and it also sets 
up a bl ock from which we can return a value. It can also bind variables like let, 
although in this usage, the variable list is empty. Any symbol within the body of a 
prog is considered a label. In this case, the label : INTERP is the target of the branch 
statements (GO :I NTERP). I use uppercase to indicate that go-to statements are being 
used, but this convention has not been widely adopted. 

(defun interp (x &optional env) 
"Evaluate the expression . in the environment env. 
This version is properly tail-recursive." 
(prog () 

:INTERP 
(return 

(cond 
((symbolp x) (get-var . env)) 
((atom x) x) 
((scheme-macro (first x)) 

(setf X (scheme-macro-expand x)) (go :INTERP)) 
((case (first x) 

(QUOTE (second x)) 
(BEGIN (pop x) ; pop off the BEGIN to get at the args 
Now interpret all but the last expression 
(loop while (rest x) do (interp (pop x) env)) 
Finally, rename the last expression as . 
(setf X (firs t X)) 
(GO :INTERP)) 
(SETI (set-varl (second x) (interp (third x) env) env)) 
(IF (setf X (if (interp (second x) env) 
(third X) 
(fourth X))) 
That is . rename the right expression as . 
(GO :INTERP)) 

(LAMBDA (make-proc :env env :parms (second x) 
:code (maybe-add 'begin (rest2 x)))) 


<a id='page-768'></a>

(t a procedure application 
(let ((proc (interp (first x) env)) 
(args (mapcar #*(lambda (v) (interp . env)) 
(rest X)))) 
(if (proc-p proc) 
Execute procedure with rename+goto 

(progn 
(setf X (proc-code proc)) 
(setf env (extend-env (proc-parms proc) args 

(proc-env proc))) 
(GO :INTERP)) 
else apply primitive procedure 
(apply proc args)))))))))) 

(defun print-proc (proc &optional (stream *standard-output*) depth) 
(declare (ignore depth)) 
(format stream "{~a}" (or (proc-name proc) '??))) 

By tracing the tail-recursive version of interp, you can see that calls to traverse 
descend only three recursive levels of interp, regardless of the length of the list 
traversed. 

Note that we are not claiming that this interpreter allocates no storage when 
it makes tail-recursive calls. Indeed, it wastes quite a bit of storage in evaluating 
arguments and building environments. The claim is that since the storage is allocated 
on the heap rather than on the stack, it can be reclaimed by the garbage collector. So 
even if traverse is applied to an infinitely long list (i.e., a circular list), the interpreter 
will never run out of space - it will always be able to garbage-collect and continue. 

There are many improvements that could be made to this interpreter, but effort 
is better spent in improving a compiler rather than an interpreter. The next chapter 
does just that. 

22.4 Throw, Catch, and Call/cc 
Tail-recursion is crucial to Scheme. The idea is that when the language is guaranteed 
to optimize tail-recursive calls, then there is no need for special forms to do iteration. 
All loops can be written using recursion, without any worry of overflowing the nm-
time stack. This helps keep the language simple and rules out the goto statement, the 
scourge of the structured programming movement. However, there are cases where 
some kind of nonlocal exit is the best alternative. Suppose that some unexpected 
event happens deep inside your program. The best action is to print an error message 
and pop back up to the top level of your program. This could be done trivially with a 
goto-like statement. Without it, every function along the calling path would have to 


<a id='page-769'></a>
be altered to accept either a valid result or an indication of the exceptional condition, 
which just gets passed up to the next level. 

In Common Lisp, the functions throw and catch are provided for this kind of 
nonlocal exit. Scott Zimmerman, the perennial world Frisbee champion, is also 
a programmer for a Southern California firm. He once told me, "I'm starting to 
learn Lisp, and it must be a good language because it's got throw and catch in it." 
Unfortunately for Scott, throw and catch don't refer to Frisbees but to transfer of 
control. They are both special forms, with the following syntax: 

(catch tag body...) 

(throw tag value) 

The first argument to catch is a tag, or label. The remaining arguments are evaluated 
one at a time, and the last one is returned. Thus, catch is much like progn. The 
difference is that if any code in the dynamic extent of the body of the catch evaluates 
the special form throw, then control is immediately passed to the enclosing catch 
with the same tag. 

For example, the form 

(catch 'tag 
(print 1) (throw 'tag 2) (print 3)) 

prints 1 and returns 2, without going on to print 3. A more representative example 
is: 

(defun print-table (1) 
(catch 'not-a-number (mapcar #*print-sqrt-abs 1))) 

(defun print-sqrt-abs (x) 
(print (sqrt (abs (must-be-number x))))) 

(defun must-be-number (x) 
(if (numberp x) . 
(throw 'not-a-number "huh?"))) 

> (print-table '(1 4 -9 . 10 20)) 

1 

2 

3 
"huh?" 

Here pri nt-tablecalls print-sqrt-abs, which callsmust-be-number. Thefirstthree 
times all is fine and the values 1,2,3 get printed. The next time . is not a number, so 
the value "huh?" gets thrown to the tag not-a-number established by catch in f. The 


<a id='page-770'></a>

throw bypasses the pending calls to abs, sqrt, and print, as well as the rest of the 
call to mapcar. 

This kind of control is provided in Scheme with a very general and powerful 
procedure, cal 1 -with-current-continuati on, which is often abbreviated cal 1 /cc. 
cal 1 /cc is a normal procedure (not a special form like throw and catch) that takes 
a single argument. Let's call the argument computation, computation must be a 
procedure of one argument. When cal 1 /cc is invoked, it calls computation, and 
whatever computat i on returns is the value of the call to call /cc. The trick is that the 
procedure computati on also takes an argument (which we'll call cc) that is another 
procedure representing the current continuation point. If cc is applied to some value, 
that value is returned as the value of the call to call / cc. Here are some examples: 

> (scheme) 
=> (+ 1 (call/cc (lambda (cc) (+ 20 300)))) 
321 

This example ignores cc and just computes (+ 1 (+ 20 300)). More precisely, it is 
equivalent to: 

((lambda (val) (+ 1 val)) 
(+ 20 300)) 

The next example does make use of cc: 

=> (+ 1 (call/cc (lambda (cc) (+ 20 (cc 300))))) 
301 

This passes 300 to cc, thus bypassing the addition of 20. It effectively throws 300 out 
of the computation to the catch point estabUshed by cal 1 / cc. It is equivalent to: 

((lambda (val) (+ 1 val)) 
300) 

or to: 

((lambda (val) (+ 1 val)) 
(catch 'cc 
((lambda (v) (+ 20 v)) 
(throw 'cc 300)))) 


<a id='page-771'></a>
Here's how the throw/catch mechanism would look in Scheme: 

(define (print-table 1) 
(call/cc 

(lambda (escape) 
(set! not-a-number escape) 
(map print-sqrt-abs 1)))) 

(define (print-sqrt-abs x) 
(write (sqrt (abs (must-be-number x))))) 

(define (must-be-number x) 
(if (numberp x) . 
(not-a-number "huh?"))) 

(define (map fn 1) 
(if (null? 1) 
.() 

(cons (fn (first D) 
(map fn (rest 1))))) 

The ability to return to a pending point in the computation is useful for this kind of 
error and interrupt handling. However, the truly amazing, wonderful thing about 
cal 1 /cc is the ability to return to a continuation point more than once. Consider a 
slight variation: 

=> (+ 1 (call/cc (lambda (cc) 
(set! old-cc cc) 
(+ 20 (cc 300))))) 

301 

=> (old-cc 500) 
501 

Here, we first computed 301, just as before, but along the way saved cc in the global 
variable old-cc. Afterward, calling (old-cc 500) returns (for the second time) to the 
point in the computation where 1 is added, this time returning 501. The equivalent 
Common Lisp code leads to an error: 

> (+ 1 (catch 'tag (+ 20 (throw 'tag 300)))) 
301 

> (throw 'tag 500) 

Error: there was no pending CATCH for the tag TAG 

In other words, cal 1 /cc's continuations have indefinite extent, while throw/catch 
tags only have dynamic extent. 


<a id='page-772'></a>

We can use cal 1 /cc to implement automatic backtracking (among other things). 
Suppose we had a special form, amb, the "ambiguous" operator, which returns one of 
its arguments, chosen at random. We could write: 

(define (integer) (amb 1 (+ 1 (integer)))) 

and a call to integer would return some random positive integer. In addition, 
suppose we had a function, fail, which doesn't return at all but instead causes 
execution to continue at a prior amb point, with the other choice taken. Then we could 
write succinct^ backtracking code like the following: 

(define (prime) 
(let ((n (integer))) 
(if (prime? n) . (fail)))) 

If pri me? is a predicate that returns true only when its argument is a prime number, 
then prime will always return some prime number, decided by generating random 
integers. While this looks like a major change to the language - adding backtracking 
and nondeterminism - it turns out that amb and fa i 1 can be implemented quite easily 
with cal 1 /cc. First, we need to make amb be a macro: 

(def-scheme-macro amb (x y) 
'(random-choice (lambda () ,x) (lambda () .y)))) 

The rest is pure Scheme. We maintain a Ust of backtrack-points, which are implemented 
as functions of no arguments. To backtrack, we just call one of these 
functions. Thatis what fail does. The function choose-first takes two functions 
and pushes the second, along with the proper continuation, on backtrack-points, 
and then calls the first, returning that value. The function random-choi ce is what 
amb expands into: it decides which choice is first, and which is second. (Note that 
the convention in Scheme is to write global variables like backt rack- poi nts without 
asterisks.) 

(define backtrack-points nil) 

(define (fail) 

(let ((last-choice (car backtrack-points))) 

(setl backtrack-points (cdr backtrack-points)) 

(last-choice))) 

although inefficient 


<a id='page-773'></a>
(define (random-choice f g) 

(if (= 1 (random 2)) 
(choose-first f g) 
(choose-first g f))) 

(define (choose-first f g) 
(call/cc 
(lambda (k) 
(set! backtrack-points 
(cons (lambda () (k (g))) backtrack-points)) 
(f)))) 

This implements chronological backtracking, as in Prolog. However, we actually 
have the freedom to do other kinds of backtracking as well. Instead of having f ai1 
take the first element of backtrack-points, we could choose a random element 
instead. Or, we could do some more complex analysis to choose a good backtrack 
point. 

cal 1 / cc can be used to implement a variety of control structures. As another 
example, many Lisp implementations provide a re s et function that aborts the current 
computation and returns control to the top-level read-eval-print loop, reset can be 
defined quite easily using cal 1 /cc. The trick is to capture a continuation that is at 
the top level and save it away for future use. The following expression, evaluated at 
the top level, saves the appropriate continuation in the value of reset: 

(call/cc (lambda (cc) (set! reset (lambda () 
(cc "Back to top level"))))) 

&#9635; Exercise 22.2 [m] Can you implement cal 1 /cc in Common Lisp? 

&#9635; Exercise 22.3 [s] Can you implement amb and fai1 in Common Lisp? 

&#9635; Exercise 22.4 [m] f ai 1 could be written 
(define (fail) ((pop backtrack-points))) if we had the pop macro in Scheme. 
Write pop. 

22.5 An Interpreter Supporting Call/cc 
It is interesting that the more a host language has to offer, the easier it is to write 
an interpreter. Perhaps the hardest part of writing a Lisp interpreter (or compiler) 
is garbage collection. By writing our interpreter in Lisp, we bypassed the problem 


<a id='page-774'></a>

all together - the host language automatically collects garbage. Similarly, if we are 
using a Common Lisp that is properly tail-recursive, then our interpreter will be too, 
without taking any special steps. If not, the interpreter must be rewritten to take care 
of tail-recursion, as we have seen above. 

It is the same with cal 1 /cc. If our host language provides continuations with 
indefinite extent, then it is trivial to implement cal 1 /cc. If not, we have to rewrite 
the whole interpreter, so that it explicitly handles continuations. The best way to do 
this is to make i . te rp a function of three arguments: an expression, an environment, 
and a continuation. That means the top level will have to change too. Rather than 
having i nterp return a value that gets printed, we just pass it the function pri nt as 
a continuation: 

(defun scheme () 
"A Scheme read-eval-print loop (using interp). 
Handles call/cc by explicitly passing continuations." 
(init-scheme-interp) 
(loop (format t ""&==> ") 

(interp (read) nil #'print))) 

Nowweareready to tackle i nterp. For clarity, we will base it on the non-tail-recursive 
version. The cases for symbols, atoms, macros, and quote are almost the same as 
before. The difference is that the result of each computation gets passed to the 
continuation, cc, rather than just being returned. 

The other cases are all more complex, because they all require explicit representation 
of continuations. That means that calls to i nterp cannot be nested. Instead, 
we call i nterp with a continuation that includes another call to i nterp. For example, 
to interpret (If . . y), we first call interp on the second element of the form, 
the predicate p. The continuation for this call is a function that tests the value of 
. and interprets either . or y accordingly, using the original continuation for the 
recursive call to i nterp. The other cases are similar. One important change is that 
Scheme procedures are implemented as Lisp functions where the first argument is 
the continuation: 

(defun interp (x env cc) 
"Evaluate the expression . in the environment env. 
and pass the result to the continuation cc." 
(cond 

((symbolp x) (funcall cc (get-var . env))) 
((atom x) (funcall cc x)) 
((scheme-macro (first x)) 

(interp (scheme-macro-expand x) env cc)) 

((case (first x) 
(QUOTE (funcall cc (second x))) 
(BEGIN (interp-begin (rest x) env cc)) 


<a id='page-775'></a>
(SET! (interp (third x) env 
#*(lambda (val) 
(funcall cc (set-var! (second x) 
val env))))) 
(IF (interp (second x) env 
#.(lambda (pred) 
(interp (if pred (third x) (fourth x)) 
env cc)))) 
(LAMBDA (let ((parms (second x)) 
(code (maybe-add 'begin (rest2 x)))) 

(funcall 
cc 
#*(lambda (cont &rest args) 

(interp code 
(extend-env parms args env) 
cont))))) 

(t (interp-call . env cc)))))) 

A few auxiliary functions are defined, in the same continuation-passing style: 

(defun interp-begin (body env cc) 
"Interpret each element of BODY, passing the last to CC." 
(interp (first body) env 

#.(lambda (val) 

(if (null (rest body)) 
(funcall cc val) 
(interp-begin (rest body) env cc))))) 

(defun interp-call (call env cc) 
"Interpret the call (f x...) and pass the result to CC." 
(map-interp call env 

#'(lambda (fn-and-args) 

(apply (first fn-and-args) 
cc 
(rest fn-and-args))))) 

(defun map-interp (list env cc) 
"Interpret each element of LIST, and pass the list to CC." 
(if (null list) 

(funcall cc nil) 
(interp (first list) env 
#'(lambda (x) 
(map-interp (rest list) env 
#'(lambda (y) 
(funcall cc (cons . y)))))))) 


<a id='page-776'></a>

Because Scheme procedures expect a continuation as the first argument, we need to 
redefine init-scheme-proc to install procedures that accept and apply the 
continuation: 

(defun init-scheme-proc (f) 
"Define a Scheme primitive procedure as a CL function." 
(if (listp f) 

(set-global-var! (first f) 
#'(lambda (cont &rest args) 
(funcall cont (apply (second f) args)))) 
(init-scheme-proc (list f f)))) 

We also need to define cal 1 /cc. Think for a moment about what cal 1 /cc must do. 
Like all Scheme procedures, it takes the current continuation as its first argument. 
The second argument is a procedure - computation to be performed, call/cc 
performs the computation by calling the procedure. This is just a normal call, 
so it uses the current continuation. The tricky part is what call/cc passes the 
computation as its argument. It passes an escape procedure, which can be invoked 
to return to the same point that the original call to cal 1 / cc would have returned to. 
Once the working of cal 1 /cc is understood, the implementation is obvious: 

(defun call/cc (cc computation) 
"Make the continuation accessible to a Scheme procedure." 
(funcall computation cc 

;; Package up CC into a Scheme function: 

#.(lambda (cont val) 
(declare (ignore cont)) 
(funcall cc val)))) 

Now install call/cc in the global environment 
(set-global-var! 'call/cc #'can/cc) 
(set-global-var! 'call-with-current-continuation #'call/cc) 

22.6 History and References 
Lisp interpreters and AI have a long history together. MIT AI Lab Memo No. 1 
(McCarthy 1958) was the first paper on Lisp. McCarthy's students were working 
on a Lisp compiler, had written certain routines - read, print, etc. - in assembly 


<a id='page-777'></a>
language, and were trying to develop a full Lisp interpreter in assembler. Sometime 
around the end of 1958, McCarthy wrote a theoretical paper showing that Lisp was 
powerful enough to write the universal function, eva 1. A programmer on the project, 
Steve Russell, saw the paper, and, according to McCarthy: 

Steve Russell said, look, lohy don't I program this eval and-you remember the 
interpreter-and I said to him, ho, ho, you're confusing theory with practice, this 
eval is intended for reading not for computing. But he went ahead and did it. 
That is, he compiled the eval in my paper into 704 machine code fixing bugs 
and then advertised this as a Lisp interpreter, which it certainly was.^ 

So the first Lisp interpreter was the result of a programmer ignoring his boss's 
advice. The first compiler was for the Lisp 1.5 system (McCarthy et al. 1962). The 
compiler was written in Lisp; it was probably the first compiler written in its own 
language. 

Allen's Anatomy of Lisp (1978) was one of the first overviews of Lisp implementation 
techniques, and it remains one of the best. However, it concentrates on the 
dynamic-scoping Lisp dialects that were in use at the time. The more modern view 
of a lexically scoped Lisp was documented in an influential pair of papers by Guy 
Steele (1976a,b). His papers "Lambda: the ultimate goto" and "Compiler optimization 
based on viewing lambda as rename plus goto" describe properly tail-recursive 
interpreters and compilers. 

The Scheme dialect was invented by Gerald Sussman and Guy Steele around 
1975 (see their MIT AI Memo 349). The Revised^ Report on the Algorithmic Language 
Scheme (dinger et al. 1991) is the definitive reference manual for the current version 
of Scheme. 

Abelson and Sussman (1985) is probably the best introduction to computer science 
ever written. It may or may not be a coincidence that it uses Scheme as the 
programming language. It includes a Scheme interpreter. Winston and Horn's Lisp 
(1989) also develops a Lisp interpreter. 

The amb operator for nondeterministic choice was proposed by John McCarthy 
(1963) and used in SCHEMER (Zabih et al. 1987), a nondeterministic Lisp. Ruf 
and Weise (1990) present another implementation of backtracking in Scheme that 
incorporates all of logic programming. 

^McCarthy's words from a talk on the history of Lisp, 1974, recorded by Stoyan (1984). 


<a id='page-778'></a>

22.7 Exercises 
&#9635; Exercise 22.5 [m] While Scheme does not provide full-blown support for optional 
and keyword arguments, it does support rest parameters. Modify the interpreter to 
support the Scheme syntax for rest parameters: 
Scheme(lambda(lambda 
. body) 
(x y . .) body) 
Common Lisp 
(lambda (&rest x) 
(lambda (x y &rest 
body) 
z) body) 

&#9635; Exercise 22.6 [h] The representation of environments is somewhat wasteful. Currently 
it takes 3n cons cells to represent an environment with . variables. Change 
the representation to take less space. 

&#9635; Exercise 22.7 [m] As we've implemented macros, they need to be expanded each 
time they are encountered. This is not so bad for the compiler - you expand the 
source code and compile it, and then never refer to the source code again. But for 
the interpreter, this treatment of macros is most unsatisfactory: the work of macro-
expansion must be done again and again. How can you eliminate this duplicated 
effort? 

&#9635; Exercise 22.8 [m] It turns out Scheme allows some additional syntax in let and 
cond. First, there is the "named-let" expression, which binds initial values for variables 
but also defines a local function that can be called within the body of the let. 
Second, cond recognizes the symbol => when it is the second element of a cond clause, 
and treats it as a directive to pass the value of the test (when it is not false) to the 
third element of the clause, which must be a function of one argument. Here are two 
examples: 
(define (fact n) 
Iterative factorial: does not grow the stack 
(let loop ((result 1) (i n)) 
(if (= i 0) result (loop (* result i) (-i 1))))) 
(define (lookup key alist) 
:: Find key's value in alist 
(cond ((assoc key alist) => cdr) 
(else #f))) 
These are equivalent to: 


<a id='page-779'></a>

(define (fact n) 
(letrec 
((loop (lambda (result i) 

(if (= i 0) 
result 
(loop (* result i) (-i 1)))))) 

(loop 1 n))) 

(define (lookup key alist) 
(let ((g0030 (assoc key alist))) 

(if gOOSO 
(cdr g0030) 
#f))) 

Write macro definitions for let and cond allowing these variations. 

&#9635; Exercise 22.9 Pi] Some Scheme implementations permit def i ne statements inside 
the body of a 1 ambda (and thus of a def i ne, let, let*, or letrec as well). Here is an 
example: 

(define (length 1) 
(define (len 1 n) 
(if (null? 1) . (len (cdr 1) (+ . 1)))) 
(len 1 0)) 

The internal definition of len is interpreted not as defining a global name but rather 

as defining a local name as if with letrec. The above definition is equivalent to: 

(define (length 1) 
(letrec (den (lambda (1 n) 
(if (null? 1) . (len (cdr 1) (+ . 1)))))) 
(len 1 0))) 

Make changes to the interpreter to allow this kind of internal definition. 

&#9635; Exercise 22.10 Scheme programmers are often disdainful of the function or # ' 
notation in Common Lisp. Is it possible (without changing the compiler) to make 
Common Lisp accept (1 ambda () ...) instead of # ' (1 ambda () ...) and f . 
instead of #'fn? 

&#9635; Exercise 22.11 [m] The top level of the continuation-passing version of scheme 
includes the call: (i nterp (read) nil #' pr int). Will this always result in some 


<a id='page-780'></a>

value being printed? Or is it possible that the expression read might call some escape 
function that ignores the value without printing anything? 

&#9635; Exercise 22.12 [h] What would have to be added or changed to turn the Scheme 
interpreter into a Common Lisp interpreter? 

&#9635; Exercise 22.13 \h] How would you change the interpreter to allow for multiple 
values? Explain how this would be done both for the first version of the interpreter 
and for the continuation-passing version. 

22.8 Answers 
Answer 22.2 There is no way to implement a full ca . / cc to Common Lisp, but the 
following works for cases where the continuation is only used with dynamic extent: 

(defun call/cc (computation) 
"Call computation, passing it the current continuation. 
The continuation has only dynamic extent." 
(funcall computation #'(lambda (x) (return-from call/cc x)))) 

Answer 22.3 No. fail requires continuations with dynamic extent. 

Answer 22.5 We need only modify extend - en . to know about an atomic vars list. 
While we're at it, we might as well add some error checking: 

(defun extend-env (vars vals env) 
"Add some variables and values to an environment." 
(cond ((null vars) 

(assert (null vals) () "Too many arguments supplied") 
env) 
((atom vars) 
(cons (list vars vals) env)) 
(t (assert (rest vals) () "Too few arguments supplied") 
(cons (list (first vars) (first vals)) 
(extend-env (rest vars) (rest vals) env))))) 


<a id='page-781'></a>

Answer 22.6 Storing the environment as an association list, {{var val),,.), makes 
it easy to look up variables with assoc. We could save one cons cell per variable 
just by changing to {{var . val)..,). But even better is to switch to a different 
representation, one presented by Steele and Sussman in The Art of the Interpreter 
(1978). In this representation we switch from a single list of var/val pairs to a list of 
frames, where each frame is a var-list/val-list pair. It looks like this: 

{{{var...) . {val...)) 
{{var...) . {val...)) 
...) 

Now extend-env is trivial: 

(defun extend-env (vars vals env) 
"Add some variables and values to an environment." 
(cons (cons vars vals) env)) 

The advantage of this approach is that in most cases we already have a list of 
variables (the procedure's parameter list) and values (from the mapcar of interp 
over the arguments). So it is cheaper to just cons these two lists together, rather than 
arranging them into pairs. Of course, get - va r and set - va r! become more complex. 

Answer 22.7 One answer is to destructively alter the source code as it is macro-
expanded, so that the next time the source code is interpreted, it will already be 
expanded. The following code takes care of that: 

(defun scheme-macro-expand (x) 
(displace . (apply (scheme-macro (first x)) (rest x)))) 

(defun displace (old new) 
"Destructively change old cons-cell to new value." 
(if (consp new) 

(progn (setf (car old) (car new)) 
(setf (cdr old) (cdr new)) 
old) 

(displace old '(begin .new)))) 

One drawback to this approach is that the user's source code is actually changed, 

which may make debugging confusing. An alternative is to expand into something 

that keeps both the original and macro-expanded code around: 


<a id='page-782'></a>

(defun displace (old new) 
"Destructively change old to a DISPLACED structure." 
(setf (car old) 'DISPLACED) 
(setf (cdr old) (list new old)) 
old) 

This means that DISPLACED is a new special form, and we need a clause for it in the 
interpreter. It would look something like this: 

(case (first x) 

(DISPLACED (interp (second x) env)) 

We'd also need to modify the printing routines to print just ol d whenever they see 
(displaced old new). 

Answer 22.8 

(def-scheme-macro let (vars &rest body) 
(if (symbolp vars) 
named let 
(let ((f vars) (vars (first body)) (body (rest body))) 
'(letrec ((,f (lambda .(mapcar #'first vars) ..body))) 
(.f ..(mapcar #*second vars)))) 
"regular" let 
'((lambda .(mapcar #'first vars) . .body) 
. .(mapcar #*second vars))))) 

(def-scheme-macro cond (&rest clauses) 
(cond ((null clauses) nil) 
((length=1 (first clauses)) 
'(or .(first clauses) (cond ..(rest clauses)))) 
((starts-with (first clauses) 'else) 

'(begin..(rest (first clauses)))) 
((eq (second (first clauses)) *=>) 
(assert (= (length (first clauses)) 3)) 
(let ((var (gensym))) 

'(let ((.var .(first (first clauses)))) 
(if .var (.(third (first clauses)) .var) 
(cond ..(rest clauses)))))) 
(t '(if .(first (first clauses)) 
(begin ..(rest (first clauses))) 
(cond ..(rest clauses))))))) 


<a id='page-783'></a>

Answer 22.10 It is easy to define . ambda as a macro, eliminating the need for 
#.(lambda ...): 

(defmacro lambda (args &rest body) 
'(function (lambda ,args .body))) 

If this were part of the Common Lisp standard, I would gladly use it. But because it 
is not, I have avoided it, on the grounds that it can be confusing. 
It is also possible to write a new function-defining macro that would do the 
following type of expansion: 

(defn double (x) (* 2 x)) 
(defparameter double (defun double (x) (* 2 x))) 

This makes doubl e a special variable, so we can write doubl e instead of # 'doubl e. 
But this approach is not recommended - it is dangerous to define special variables 
that violate the asterisk convention, and the Common Lisp compiler may not be able 
to optimize special variable references the way it canfunction special forms. Also, 
this approach would not interact properly with flet and 1 abel s. 


## Chapter 23
<a id='page-784'></a>

Compiling Lisp 

M
M
any textbooks show simple interpreters for Lisp, because they are simple to write, 
and because it is useful to know how an interpreter works. Unfortunately, not as 
many textbooks show how to write a compiler, even though the same two reasons 
hold. The simplest compiler need not be much more complex than an interpreter. 

One thing that makes a compiler more complex is that we have to describe the output of 
the compiler: the instruction set of the machine we are compiling for. For the moment let's 
assume a stack-based machine. The calling sequence on this machine for a function call with 
. arguments is to push the . arguments onto the stack and then push the function to be called. 
A "CALL n" instruction saves the return point on the stack and goes to the first instruction of 
the called function. By convention, the first instruction of a function will always be "ARGS w", 
which pops . arguments off the stack, putting them in the new function's environment, where 
they can be accessed by LVAR and LSET instructions. The function should return with a RETURN 
instruction, which resets the program counter and the environment to the point of the original 
CALL instruction. 

In addition, our machine has three JUMP instructions; one that branches unconditionally, and 
two that branch depending on if the top of the stack is nil or non-nil. There is also an instruction 
for popping unneeded values off the stack, and for accessing and altering global variables. The 
instruction set is shown in figure 23.1. A glossary for the compiler program is given in figure 23.2. 
A summary of a more complex version of the compiler appears on [page 795](chapter23.md#page-795). 


<a id='page-785'></a>

opcode args description 
CONST X push a constant on the stack 
LVAR push a local variable's value 
GVAR sym push a global variable's value 
LSET . store top-of-stack in a local variable 
GSET sym store top-of-stack in a global variable 
POP pop the stack 
TJUMP label go to label if top-of-stack is non-nil; pop stack 
FJUMP label go to label if top-of-stack is nil; pop stack 
JUMP label go to label (don't pop stack) 
RETURN go to last return point 
ARGS . move . arguments from stack to environment 
CALL . go to start of function, saving return point 

. is the number of arguments passed 
FN fn create a closure from argument and current environment 
and push it on the stack 

Figure 23.1: Instruction Set for Hypothetical Stack Machine 

As an example, the procedure 

(lambda () (if (= . y) (f (g x)) (h . y (h 1 2)))) 

should compile into the following instructions: 

ARGS 0 
GVAR X 
GVAR Y 
GVAR = 
CALL 2 
FJUMP LI 
GVAR X 
GVAR G 
CALL 1 
GVAR F 
CALL 1 
JUMP L2 

LI: GVAR X 
GVAR Y 
CONST 1 
CONST 2 
GVAR . 
CALL 2 

<a id='page-786'></a>

GVAR . 
CALL 3 
L2: RETURN 

Top-Level Functions 

comp-show Compile an expression and show the resulting code. 
compiler Compile an expression as a parameterless function. 

Special Variables 

*1abel-num* Number for the next assembly language label. 
*primitive-fns * List of built-in Scheme functions. 

Data Types 

fn A Scheme function. 

Major Functions 

comp Compile an expression into a list of instructions. 
comp-begi . Compile a sequence of expressions. 
comp-if Compile a conditional (i f) expression. 
comp-lambda Compile a lambda expression. 

Auxiliary Functions 

gen Generate a single instruction. 
seq Generate a sequence of instructions. 
gen-label Generate an assembly language label. 
gen-var Generate an instruction to reference a variable. 
gen-set Generate an instruction to set a variable. 
namel Set the name of a function to a given value. 
print-fn Print a Scheme function (just the name). 
show-fn Print the instructions in a Scheme function. 
label-p Is the argument a label? 
in-env-p Is the symbol in the environment? If so, where? 

Figure 23.2: Glossary for the Scheme Compiler 

The first version of the Scheme compiler is quite simple. It mimics the structure 
of the Scheme evaluator. The difference is that each case generates code rather than 
evaluating a subexpression: 

(defun comp (. env) 
"Compile the expression . into a list of instructions." 
(cond 

((symbolp x) (gen-var . env)) 
((atom X) (gen 'CONST x)) 
((scheme-macro (first x)) (comp (scheme-macro-expand x) env)) 
((case (first x) 


<a id='page-787'></a>

(QUOTE (gen 'CONST (second x))) 
(BEGIN (comp-begin (rest x) env)) 
(SETI (seq (comp (third x) env) (gen-set (second x) env))) 
(IF (comp-if (second x) (third x) (fourth x) env)) 
(LAMBDA (gen 'FN (comp-lambda (second x) (rest (rest x)) env))) 

Procedure application: 
:: Compile args. then fn, then the call 
(t (seq (mappend #'(lambda (y) (comp y env)) (rest x)) 

(comp (first x) env) 
(gen 'call (length (rest x))))))))) 

The compiler comp has the same nine cases - in fact the exact same structure - as 
the interpreter i nterp from chapter 22. Each case is slightly more complex, so the 
three main cases have been made into separate fimctions: comp - beg i ., comp - i f, and 
comp-1 ambda. A begi . expression is compiled by compiling each argument in turn 
but making sure to pop each value but the last off the stack after it is computed. The 
last element in the begi. stays on the stack as the value of the whole expression. Note 
that the function gen generates a single instruction (actually a list of one instruction), 
and seq makes a sequence of instructions out of two or more subsequences. 

(defun comp-begin (exps env) 
"Compile a sequence of expressions, popping all but the last." 
(cond ((null exps) (gen 'CONST nil)) 

((length=1 exps) (comp (first exps) env)) 

(t (seq (comp (first exps) env) 
(gen 'POP) 
(comp-begin (rest exps) env))))) 

An i f expression is compiled by compiling the predicate, then part, and else part, 
and by inserting appropriate branch instructions. 

(defun comp-if (pred then else env) 
"Compile a conditional expression." 
(let ((LI (gen-label)) 

(L2 (gen-label))) 

(seq (comp pred env) (gen 'FJUMP LI) 
(comp then env) (gen 'JUMP L2) 
(list LI) (comp else env) 
(list L2)))) 

Finally, a 1 ambda expression is compiled by compiling the body, surrounding it with 
one instruction to set up the arguments and another to return from the function, and 


<a id='page-788'></a>

then storing away the resulting compiled code, along with the environment. The 
data type f . is implemented as a structure with slots for the body of the code, the 
argument list, and the name of the function (for printing purposes only). 

(defstruct (fn (:print-function print-fn)) 
code (env nil)(name nil) (args nil)) 

(defun comp-1ambda (args body env) 
"Compile a lambda form into a closure with compiled code." 
(assert (and distp args) (every #*symbolp args)) () 

"Lambda arglist must be a list of symbols, not ~a" args) 
;; For now, no &rest parameters. 
The next version will support Scheme's version of &rest 

(make-fn 
:env env :args args 
:code (seq (gen 'ARGS (length args)) 

(comp-begin body (cons args env)) 
(gen 'RETURN)))) 

The advantage of compiling over interpreting is that much can be decided at compile 
time. For example, the compiler can determine if a variable reference is to a global 
or lexical variable, and if it is to a lexical variable, exactly where that lexical variable 
is stored. This computation is done only once by the compiler, but it has to be done 
each time the expression is encountered by the interpreter. Similarly, the compiler 
can count up the number of arguments once and for all, while the interpreter must 
go through a loop, counting up the number of arguments, and testing for the end of 
the arguments after each one is interpreted. So it is clear that the compiler can be 
more efficient than the interpreter. 

Another advantage is that the compiler can be more robust. For example, in 
comp-1 ambda, we check that the parameter list of a lambda expression is a list containing 
only symbols. It would be too expensive to make such checks in an interpreter, 
but in a compiler it is a worthwhile trade-off to check once at compile time for error 
conditions rather than checking repeatedly at run time. 

Before we show the rest of the compiler, here's a useful top-level interface to comp: 

(defvar *1abel-num* 0) 

(defun compiler (x) 
"Compile an expression as if it were in a parameterless lambda." 
(setf *label-num* 0) 
(comp-lambda '() (list x) nil)) 


<a id='page-789'></a>

(defun comp-show (x) 
"Compile an expression and show the resulting code" 
(show-fn (compiler x)) 
(values)) 

Now here's the code to generate individual instructions and sequences of instructions. 
A sequence of instructions is just a list, but we provide the function seq rather 
than using append directly for purposes of data abstraction. A label is just an atom. 

(defun gen (opcode &rest args) 
"Return a one-element list of the specified instruction.' 
(list (cons opcode args))) 

(defun seq (&rest code) 
"Return a sequence of instructions" 
(apply #'append code)) 

(defun gen-label (&optional (label .)) 

"Generate a label (a symbol of the form Lnnn)" 

(intern (format nil "^a^d" label (incf *1abel-num*)))) 

Environments are now represented as lists of frames, where each frame is a sequence 
of variables. Local variables are referred to not by their name but by two integers: 
the index into the list of frames and the index into the individual frame. As usual, 
the indexes are zero-based. For example, given the code: 

(let ((a 2.0) 
(b 2.1)) 
(let ((c 1.0) 
(d l.D) 
(let ((e 0.0) 
(f O.D) 
(+ a b c d e f)))) 

the innermost environment is((e f) (c d) (a b)). The function i.- en. - . tests 

if a variable appears in an environment. If this environment were called env, then 

(in-env-p ' f env) would return (2 1) and (in-env-p 'x env) would return nil. 


<a id='page-790'></a>

(defun gen-var (var env) 
"Generate an instruction to reference a variable's value." 
(let ((p (in-env-p var env))) 

(if . 
(gen 'LVAR (first p) (second p) ";" var) 
(gen 'GVAR var)))) 

(defun gen-set (var env) 
"Generate an instruction to set a variable to top-of-stack.' 
(let ((p (in-env-p var env))) 

(if . 
(gen 'LSET (first p) (second p) ";" var) 
(gen 'GSET var)))) 

Finally, we have some auxiliary functions to print out the results, to distinguish 
between labels and instructions, and to determine the index of a variable in an 
environment. Scheme functions now are implemented as structures, which must 
have a field for the code, and one for the environment. In addition, we provide 
a field for the name of the function and for the argument list; these are used only 
for debugging purposes. We'll adopt the convention that the def i ne macro sets the 
function's name field, by calling name! (which is not part of standard Scheme). 

(def-scheme-macro define (name &rest body) 
(if (atom name) 

'(name! (set! ,name . .body) '.name) 
(scheme-macro-expand 
'(define .(first name) 
(lambda .(rest name) . .body))))) 

(defun namel (fn name) 
"Set the name field of fn. if it is an un-named fn." 
(when (and (fn-p fn) (null (fn-name fn))) 

(setf (fn-name fn) name)) 
name) 

;; This should also go in init-scheme-interp: 
(set-global-var! 'name! #'name!) 

(defun print-fn (fn &optional (stream *standard-output*) depth) 
(declare (ignore depth)) 
(format stream "{~a}" (or (fn-name fn) '??))) 


<a id='page-791'></a>

(defun show-fn (fn &optional (stream *standard-output*) (depth 0)) 
"Print all the instructions in a function. 
If the argument is not a function, just princ it, 
but in a column at least 8 spaces wide." 
(if (not (fn-p fn)) 

(format stream ""Ba" fn) 

(progn 
(fresh-line) 
(incf depth 8) 
(dolist (instr (fn-code fn)) 

(if (label-p instr) 
(format stream "~a:" instr) 
(progn 

(format stream "'^VT" depth) 
(dolist (arg instr) 
(show-fn arg stream depth)) 
(fresh-line))))))) 

(defun label-p (x) "Is . a label?" (atom x)) 

(defun in-env-p (symbol env) 
"If symbol is in the environment, return its index numbers." 
(let ((frame (find symbol env :test #'find))) 

(if frame (list (position frame env) (position symbol frame))))) 

Now we are ready to show the compiler at work: 

> (comp-show '(if (= . y) (f (g x)) (h . y (h 1 2)))) 

ARGS 0 
GVAR X 
GVAR Y 
GVAR = 
CALL 2 
FJUMP LI 
GVAR X 
GVAR G 
CALL 1 
GVAR F 
CALL 1 
JUMP L2 
LI: GVAR X 
GVAR Y 
CONST 1 
CONST 2 
GVAR . 
CALL 2 
GVAR . 
CALL 3 
L2: RETURN 


<a id='page-792'></a>

This example should give the reader a feeling for the code generated by the compiler. 
Another reason a compiler has an advantage over an interpreter is that the compiler 
can afford to spend some time trying to find a more efficient encoding of an 
expression, v^hile for the interpreter, the overhead of searching for a more efficient 
interpretation usually offsets any advantage gained. Here are some places where 
a compiler could do better than an interpreter (although our compiler currently 
does not): 

> (comp-show '(begin "doc" (write x) y)) 
ARGS 0 
CONST doc 
POP 
GVAR X 
GVAR WRITE 
CALL 1 
POP 
GVAR Y 
RETURN 

In this example, code is generated to push the constant "doc" on the stack and then 
immediately pop it off. If we have the compiler keep track of what expressions are 
compiled "for value" - as y is the value of the expression above-and which are only 
compiled "for effect," then we can avoid generating any code at all for a reference to 
a constant or variable for effect. Here's another example: 

> (comp-show '(begin (+ (* a x) (f x)) x)) 
ARGS 0 
GVAR A 
GVAR X 
GVAR * 
CALL 2 
GVAR X 
GVAR F 
CALL 1 
GVAR + 
CALL 2 
POP 
GVAR X 
RETURN 


<a id='page-793'></a>

In this expression, if we can be assured that + and * refer to the normal arithmetic 
functions, then we can compile this as if it were (begin (fx) .). Furthermore, it 
is reasonable to assume that + and * will be instructions in our machine that can be 
invoked inline, rather than having to call out to a function. Many compilers spend 
a significant portion of their time optimizing arithmetic operations, by taking into 
account associativity, commutativity, distributivity, and other properties. 

Besides arithmetic, compilers often have expertise in conditional expressions. 
Consider the following: 

> (comp-show '(if (and . q) . y)) 
ARGS 0 
GVAR . 
FJUMP L3 
GVAR Q 
JUMP L4 

L3: GVAR NIL 

L4: FJUMP LI 
GVAR X 
JUMP L2 

LI: GVAR Y 
L2: RETURN 
Note that (and . q) macro-expands to (i f . q nil ). The resulting compiled code 
is correct, but inefficient. First, there is an unconditional jump to L4, which labels 
a conditional jump to LI. This could be replaced with a conditional jump to LI. 
Second, at L3 we load NIL and then jump on nil to LI. These two instructions could 
be replaced by an unconditional jump to LI. Third, the FJUMP to L3 could be replaced 
by an FJUMP to LI, since we now know that the code at L3 unconditionally goes to LI. 

Finally, some compilers, particularly Lisp compilers, have expertise in function 
calling. Consider the following: 

> (comp-show '(f (g . y))) 
ARGS 0 
GVAR X 
GVAR Y 
GVAR G 
CALL 2 
GVAR F 
CALL 1 
RETURN 


<a id='page-794'></a>

Here we call g and when g returns we call f, and when f returns we return from this 
function. But this last return is wasteful; we push a return address on the stack, and 
then pop it off, and return to the next return address. An alternative function-calling 
protocol involves pushing the return address before calling g, but then not pushing 
a return address before calling f; when f returns, it returns directly to the calling 
function, whatever that is. 

Such an optimization looks like a small gain; we basically eliminate a single 
instruction. In fact, the implications of this new protocol are enormous: we can 
now invoke a recursive function to an arbitrary depth without growing the stack at 
all - as long as the recursive call is the last statement in the function (or in a branch 
of the function when there are conditionals). A function that obeys this constraint 
on its recursive calls is known as aproperly tail-recursive function. This subject was 
discussed in section 22.3. 

All the examples so far have only dealt with global variables. Here's an example 
using local variables: 

(comp-show '((lambda (x) ((lambda (y z) (f . y .)) 3 .)) 4)) 
ARGS 
CONST 
FN 

ARGS 1 
CONST 3 
LVAR 0 
FN 

ARGS 
LVAR 
LVAR 
LVAR 
GVAR 
CALL 
RETURN 

CALL 2 

RETURN 
CALL 1 
RETURN 

The code is indented to show nested functions. The top-level function loads the 
constant 4 and an anonymous function, and calls the function. This function loads 
the constant 3 and the local variable x, which is the first (0th) element in the top 
(0th) frame. It then calls the double-nested function on these two arguments. This 
function loads x, y, and z: . is now the 0th element in the next-to-top (1st) frame, 
and y and . are the 0th and 1st elements of the top frame. With all the arguments in 


<a id='page-795'></a>

place, the function f is finally called. Note that no continuations are stored - f can 
return directly to the caller of this function. 
However, all this explicit manipulation of environments is inefficient; in this case 
we could have compiled the whole thing by simply pushing 4, 3, and 4 on the stack 

and calling f. 

scheme 
comp-go 
machine 

prim 
ret-addr 

arg-count 
comp-list 
comp-const 
comp-var 
comp-funcal1 
primitive-. 
init-scheme-comp 
gen-args 
make-true-list 
new-fn 
is 
optimize 
geni 

target 
next-instr 
quasi-q 

assemble 
asm-first-pass 
asm-second-pass 
opcode 
args 
argi 

Top-Level Functions 

A read-compile-execute-print loop. 
Compile and execute an expression. 
Run the abstract machine. 

Data Types 

A Scheme primitive function. 
A return address (function, program counter, environment). 

Auxiliary Functions 

Report an error for wrong number of arguments. 
Compile a list of expressions onto the stack. 
Compile a constant expression. 
Compile a variable reference. 
Compile a function application. 
Is this function a primitive? 
Initialize primitives used by compiler. 
Generate code to load arguments to a function. 
Convert a dotted list to a nondotted one. 
Build a new function. 
Predicate is true if instructions opcode matches. 
A peephole optimizer. 
Generate a single instruction. 

The place a branch instruction branches to. 
The next instruction in a sequence. 
Expand a quasiquote form into append, cons, etc. 

Functions for the Abstract Machine 

Turn a list of instructions into a vector. 
Find labels and length of code. 
Put code into the code vector. 
The opcode of an instruction. 
The arguments of an instruction. 
For i = 1,2,3 - select zth argument of instruction. 

Figure 23.3: Glossary of the Scheme Compiler, Second Version 


<a id='page-796'></a>

23.1 A Properly Tail-Recursive Lisp Compiler 
In this section we describe a new version of the compiler, first by showing examples 
of its output, and then by examining the compiler itself, which is summarized in 
figure 23.3. The new version of the compiler also makes use of a different function 
calling sequence, using two new instructions, CALLJ and SAVE. As the name implies, 
SAVE saves a return address on the stack. The CALLJ instruction no longer saves 
anything; it can be seen as an unconditional jump - hence the J in its name. 

First, we see how nested function calls work: 

> (comp-show '(f (g x))) 
ARGS 0 
SAVE Kl 
GVAR X 
GVAR G 
CALLJ 1 

Kl: GVAR F 
CALLJ 1 

The continuation point Kl is saved so that g can return to it, but then no continuation 
is saved for f, so f returns to whatever continuation is on the stack. Thus, there is 
no need for an explicit RETURN instruction. The final CALL is like an unconditional 
branch. 

The following example shows that all functions but the last (f) need a continuation 
point: 

> (comp-show '(f (g (h x) (h y)))) 

ARGS 0 
SAVE Kl 
SAVE K2 
GVAR X 
GVAR . 
CALLJ 1 
K2: SAVE K3 
GVAR Y 
GVAR . 
CALLJ 1 
K3: GVAR G 
CALLJ 2 
Kl: GVAR F 
CALLJ 1 


<a id='page-797'></a>

This code first computes (h .) and returns to K2. Then it computes (h y) and returns 
to K3. Next it calls g on these two values, and returns to KI before transferring to f. 
Since whatever f returns will also be the final value of the function we are compiling, 
there is no need to save a continuation point for f to return to. 

In the next example we see that unneeded constants and variables in begin 
expressions are ignored: 

> (comp-show '(begin "doc" . (f x) y)) 
ARGS 0 
SAVE KI 
GVAR X 
GVAR F 
CALLJ 1 

KI: POP 
GVAR Y 
RETURN 

One major flaw with the first version of the compiler is that it could pass data 
around, but it couldn't actually do anything to the data objects. We fix that problem 
by augmenting the machine with instructions to do arithmetic and other primitive 
operations. Unneeded primitive operations, like variables constants, and arithmetic 
operations are ignored when they are in the nonfinal position within begins. Contrast 
the following two expressions: 

> (comp-show '(begin (+ (* a x) (f x)) x)) 
ARGS 0 
SAVE KI 
GVAR X 
GVAR F 
CALLJ 1 

KI: POP 
GVAR X 
RETURN 

> (comp-show '(begin (+ (* a x) (f x)))) 
ARGS 0 
GVAR A 
GVAR X 
' 
SAVE KI 
GVAR X 
GVAR F 
CALLJ 1 

KI: + 
RETURN 


<a id='page-798'></a>

The first version of the compiler was context-free, in that it compiled all equivalent expressions 
equivalently, regardless of where they appeared. A properly tail-recursive 
compiler needs to be context-sensitive: it must compile a call that is the final value of 
a function differently than a call that is used as an intermediate value, or one whose 
value is ignored. In the first version of the compiler, comp -1 ambda was responsible for 
generating the RETURN instruction, and all code eventually reached that instruction. 
To make sure the RETURN was reached, the code for the two branches of i f expressions 
had to rejoin at the end. 

In the tail-recursive compiler, each piece of code is responsible for inserting its 
own RETURN instruction or implicitly returning by calling another function without 
saving a continuation point. 

We keep track of these possibilities with two flags. The parameter val ? is true 
when the expression we are compiling returns a value that is used elsewhere. The 
parameter more? is false when the expression represents the final value, and it is true 
when there is more to compute. In summary, there are three possibilities: 

val? more? example: the X in: 
true true (if X y z)or( f X y) 
true false (if . X .)or(begi n y X) 
false true (begin X y) 
false false impossible 

The code for the compiler employing these conventions follows: 

(defun comp (. env val? more?) 
"Compile the expression . into a list of instructions." 

(cond 
((member . '(t nil)) (comp-const . val? more?)) 
((symbolp x) (comp-var . env val? more?)) 
((atom x) (comp-const . val? more?)) 

((scheme-macro (first x)) (comp (scheme-macro-expand x) env val? more?)) 
((case (first x) 
(QUOTE (arg-count . 1) 

(comp-const (second x) val? more?)) 
(BEGIN (comp-begin (rest x) env val? more?)) 
(SET! (arg-count . 2) 

(assert (symbolp (second x)) (x) 
"Only symbols can be set!, not ''a in ~a" 
(second x) x) 

(seq (comp (third x) env t t) 
(gen-set (second x) env) 
(if (not val?) (gen 'POP)) 
(unless more? (gen 'RETURN)))) 


<a id='page-799'></a>
(IF (arg-count . 2 3) 
(comp-if (second x) (third x) (fourth x) 
env val? more?)) 
(LAMBDA (when val? 
(let ((f (comp-lambda (second x) (rest2 x) env))) 
(seq (gen 'FN f) (unless more? (gen 'RETURN)))))) 
(t (comp-funcall (first x) (rest x) env val? more?)))))) 

Here we've added one more case: t and .i 1 compile directly into primitive instructions, 
rather than relying on them being bound as global variables. (In real Scheme, 
the Boolean values are #t and #f, which need not be quoted, the empty list is (), which 
must be quoted, and t and .i 1 are ordinary symbols with no special significance.) 

I've also added some error checking for the number of arguments supplied to 
quote, set! and i f. Note that it is reasonable to do more error checking in a compiler 
than in an interpreter, since the checking need be done only once, not each time 
through. The function to check arguments is as follows: 

(defun arg-count (form min &optional (max min)) 
"Report an error if form has wrong number of args." 
(let ((n-args (length (rest form)))) 

(assert (<= min n-args max) (form) 
"Wrong number of arguments for ~a in ~a: 
~d supplied, ~d~@[ to ~d~] expected" 
(first form) form n-args min (if (/= min max) max)))) 

&#9635; Exercise 23.1 [m] Modify the compiler to check for additional compile-time errors 
suggested by the following erroneous expression: 

(cdr (+ (list X y) 'y (3 x) (car 3 x))) 

The tail-recursive compiler still has the familiar nine cases, but I have introduced 
comp - var, comp - const, comp -i f, and comp -f un ca 11 to handle the increased complexity 
introduced by the var? and more? parameters. 

Let's go through the comp- functions one at a time. First, comp-begin and 
comp-1 ist just handle and pass on the additional parameters, comp-1 ist will be 
used in comp -funcall, a new function that will be introduced to compile a procedure 
appUcation. 


<a id='page-800'></a>

(defun comp-begin (exps env val? more?) 
"Compile a sequence of expressions, 
returning the last one as the value." 
(cond ((null exps) (comp-const nil val? more?)) 

((length=1 exps) (comp (first exps) env val? more?)) 
(t (seq (comp (first exps) env nil t) 
(comp-begin (rest exps) env val? more?))))) 

(defun comp-list (exps env) 
"Compile a list, leaving them all on the stack." 
(if (null exps) nil 

(seq (comp (first exps) env t t) 
(comp-list (rest exps) env)))) 

Then there are two trivial functions to compile variable access and constants. If the 
value is not needed, these produce no instructions at all. If there is no more to be 
done, then these functions have to generate the return instruction. This is a change 
from the previous version of comp, where the caller generated the return instruction. 
Note I have extended the machine to include instructions for the most common 
constants: t, nil, and some small integers. 

(defun comp-const (x val? more?) 
"Compile a constant expression." 
(if val? (seq (if (member . '(t nil -1 0 1 2)) 

(gen x) 
(gen 'CONST x)) 
(unless more? (gen 'RETURN))))) 

(defun comp-var (x env val? more?) 
"Compile a variable reference." 
(if val? (seq (gen-var . env) (unless more? (gen 'RETURN))))) 

The remaining two functions are more complex. First consider comp - i f. Rather than 
blindly generating code for the predicate and both branches, we will consider some 
special cases. First, it is clear that (if t . y) can reduce to x and (if nil . y) 
can reduce to y. It is perhaps not as obvious that (i f . . x) can reduce to (begi . 
. .), or that the comparison of equality between the two branches should be done 
on the object code, not the source code. Once these trivial special cases have been 
considered, we're left with three more cases: (if . x nil), (if . nil y), and (if 
. . y). The pattern of labels and jumps is different for each. 


<a id='page-801'></a>
(defun comp-if (pred then else env val? more?) 
"Compile a conditional (IF) expression." 
(cond 

((null pred) ; (if nil . y) ==> y 
(comp else env val? more?)) 
((constantp pred) ; (if t . y) ==> . 
(comp then env val? more?)) 

((and distp pred) ; (if (not p) . y) ==> (if pyx) 
(length=1 (rest pred)) 
(primitive-p (first pred) env 1) 
(eq (prim-opcode (primitive-p (first pred) env 1)) *not)) 

(comp-if (second pred) else then env val? more?)) 

(t det ((pcode (comp pred env t t)) 
(tcode (comp then env val? more?)) 
(ecode (comp else env val? more?))) 

(cond 
((equal tcode ecode) ; (if . . x) ==> (begin . .) 
(seq (comp pred env nil t) ecode)) 
((null tcode) ; (if . nil y) ==> . (TJUMP L2) y L2: 
det ((L2 (gen-label))) 
(seq pcode (gen 'TJUMP L2) ecode (list L2) 
(unless more? (gen 'RETURN))))) 
((null ecode) ; (if . .) ==> . (FJUMP LI) . LI: 
det ((LI (gen-label))) 
(seq pcode (gen 'FJUMP LI) tcode (list LI) 
(unless more? (gen 'RETURN))))) 
(t ; (if . X y) ==> . (FJUMP LI) . LI: y 
; or . (FJUMP LI) . (JUMP L2) LI: y L2: 
det ((LI (gen-label)) 
(L2 (if more? (gen-label)))) 

(seq pcode (gen 'FJUMP LI) tcode 
(if more? (gen 'JUMP L2)) 
(list LI) ecode (if more? (list L2)))))))))) 

Here are some examples of i f expressions. First, a very simple example: 

> (comp-show '(if . (+ . y) (* . y))) 
ARGS O 
GVAR . 
FJUMP LI 
GVAR X 
GVAR Y 
+ 
RETURN 

LI: GVAR X 
GVAR Y 
' 
RETURN 


<a id='page-802'></a>

Each branch has its own RETURN instruction. But note that the code generated is 
sensitive to its context. For example, if we put the same expression inside a beg i . 
expression, we get something quite different: 

> (comp-show '(begin (if . (+ . y) (* . y)) .)) 

ARGS O 
GVAR 
RETURN 

What happens here is that (+ . y)and(* . y), when compiled in a context where 
the value is ignored, both result in no generated code. Thus, the if expression 
reduces to (if . nil nil), which is compiled like (begin . nil), which also 
generates no code when not evaluated for value, so the final code just references 

z. The compiler can only do this optimization because it knows that + and * are 
side-effect-free operations. Consider what happens when we replace + with f: 
> (comp-show '(begin (if . (f x) (* . .)) .)) 

ARGS O 
GVAR . 
FJUMP L2 
SAVE Kl 
GVAR X 
GVAR F 
CAL U 1 
Kl: POP 
L2: GVAR . 
RETURN 

Here we have to call (f .) if . is true (and then throw away the value returned), but 
we don't have to compute (* . .) when . is false. 

These examples have inadvertently revealed some of the structure of comp -funcall, 
which handles five cases. First, it knows some primitive functions that have corresponding 
instructions and compiles these instructions inline when their values are 
needed. If the values are not needed, then the function can be ignored, and just the 
arguments can be compiled. This assumes true functions with no side effects. If 
there are primitive operations with side effects, they too can be compiled inline, but 
the operation can never be ignored. The next case is when the function is a lambda 
expression of no arguments. We can just compile the body of the lambda expression 
as if it were a begin expression. Nonprimitive functions require a function call. 
There are two cases: when there is more to compile we have to save a continuation 


<a id='page-803'></a>
point, and when we are compiling the final value of a function, we can just branch to 
the called function. The whole thing looks like this: 

(defun comp-funcall (f args env val? more?) 
"Compile an application of a function to arguments." 
(let ((prim (primitive-p f env (length args)))) 

(cond 
(prim ; function compilable to a primitive instruction 
(if (and (not val?) (not (prim-side-effects prim))) 
Side-effect free primitive when value unused 
(comp-begin args env nil more?) 
Primitive with value or call needed 

(seq (comp-list args env) 
(gen (prim-opcode prim)) 
(unless val? (gen 'POP)) 
(unless more? (gen 'RETURN))))) 

((and (starts-with f 'lambda) (null (second f))) 

((lambda () body)) => (begin body) 
(assert (null args) () "Too many arguments supplied") 
(comp-begin (restZ f) env val? more?)) 

(more? ; Need to save the continuation point 
(let ((k (gen-label 'k))) 

(seq (gen 'SAVE k) 
(comp-list args env) 
(comp f env t t) 
(gen 'CALLJ (length args)) 
(list k) 
(if (not val?) (gen 'POP))))) 

(t ; function call as rename plus goto 

(seq (comp-list args env) 
(comp f env t t) 
(gen 'CALLJ (length args))))))) 

The support for primitives is straightforward. The prim data type has five slots. The 

first holds the name of a symbol that is globally bound to a primitive operation. The 

second, .-a rgs, is the number of arguments that the primitive requires. We have to 

take into account the number of arguments to each function because we want (->-. 

y) to compile into a primitive addition instruction, while (+ x y z) should not. It 
will compile into a call to the function instead. The opcode slot gives the opcode 
that is used to implement the primitive. The always field is true if the primitive 
always returns non-nil, f al se if it always returns nil, and nil otherwise. It is used in 
exercise 23.6. Finally, the side- effects field says if the function has any side effects, 
like doing I/O or changing the value of an object. 

<a id='page-804'></a>

(defstruct (prim (:type list)) 
symbol n-args opcode always side-effects) 

(defparameter *primitive-fns* 

'((+ 2 + true) (- 2 - true) (* 2 * true) (/ 2 / true) 
(< 2 <) (> 2 >) (<= 2 <=) (>= 2 >=) (/= 2 /=) (= 2 =) 
(eq? 2 eq) (equal? 2 equal) (eqv? 2 eql) 
(not 1 not) (null? 1 not) 
(car 1 car) (cdr 1 cdr) (cadr 1 cadr) (cons 2 cons true) 
(list 1 listl true) (list 2 list2 true) (list 3 lists true) 
(read 0 read nil t) (write 1 write nil t) (display 1 display nil t) 
(newline 0 newline nil t) (compiler 1 compiler t) 
(name! 2 name! true t) (random 1 random true nil))) 

(defun primitive-p (f env n-args) 
"F is a primitive if it is in the table, and is not shadowed 
by something in the environment, and has the right number of args." 
(and (not (in-env-p f env)) 

(find f *primitive-fns* 
:test #*(lambda (f prim) 

(and (eq f (prim-symbol prim)) 
(= n-args (prim-n-args prim))))))) 
(defun list l (x) (list x)) 

(defun list2 (x y) (list . y)) 
(defun lista (. y .) (list . y .)) 
(defun display (.) (princ .)) 
(defun newline O (terpri)) 

These optimizations only work if the symbols are permanently bound to the global 
values given here. We can enforce that by altering gen-set to preserve them as 
constants: 

(defun gen-set (var env) 
"Generate an instruction to set a variable to top-of-stack." 
(let ((p (in-env-p var env))) 

(if . 
(gen 'LSET (first p) (second p) ";" var) 
(if (assoc var *primitive-fns*) 

(error "Can't alter the constant ~a" var) 
(gen 'GSET var))))) 


<a id='page-805'></a>
Now an expression like (+ . 1) will be properly compiled using the + instruction 
rather than a subroutine call, and an expression like (set! + *) will be flagged as 
an error when + is a global variable, but allowed when it has been locally bound. 
However, we still need to be able to handle expressions like (set! add +) and then 
(add . y). Thus, we need some function object that + will be globally bound to, even 
if the compiler normally optimizes away references to that function. The function 
init - scheme - comp takes care of this requirement: 

(defun i nit-scheme-comp () 
"Initialize the primitive functions." 
(dolist (prim *primitive-fns*) 

(setf (get (prim-symbol prim) 'global-val) 
(new-fn :env nil :name (prim-symbol prim) 
icode (seq (gen 'PRIM (prim-symbol prim)) 
(gen 'RETURN)))))) 

There is one more change to make - rewriting comp-1 ambda. We still need to get the 
arguments off the stack, but we no longer generate a RETURN instruction, since that is 
done by comp-begi n, if necessary. At this point we'll provide a hook for a peephole 
optimizer, which will be introduced in section 23.4, and for an assembler to convert 
the assembly language to machine code, new-fn provides this interface, but for now, 
new- f . acts just like make - f n. 

We also need to account for the possibility of rest arguments in a lambda list. A 
new function, gen-args, generates the single instruction to load the arguments of 
the stack. It introduces a new instruction, ARGS., into the abstract machine. This 
instruction works just like ARGS, except it also conses any remaining arguments on 
the stack into a list and stores that list as the value of the rest argument. With this 
innovation, the new version of comp -1ambda looks like this: 


<a id='page-806'></a>

(defun comp-lambda (args body env) 
"Compile a lambda form into a closure with compiled code." 
(new-fn :env env :args args 

:code (seq (gen-args args 0) 

(comp-begin body 
(cons (make-true-list args) env) 
t nil)))) 

(defun gen-args (args n-so-far) 
"Generate an instruction to load the arguments." 
(cond ((null args) (gen 'ARGS n-so-far)) 

((symbolp args) (gen 'ARGS. n-so-far)) 

((and (consp args) (symbolp (first args))) 
(gen-args (rest args) (+ n-so-far 1))) 

(t (error "Illegal argument list")))) 

(defun make-true-list (dotted -1ist) 
"Convert a possibly dotted list into a true, non-dotted list." 
(cond ((null dotted-list) nil) 

((atom dotted-list) (list dotted-list)) 
(t (cons (first dotted-list) 
(make-true-list (rest dotted-list)))))) 

(defun new-fn (&key code env name args) 
"Build a new function." 
(assemble (make-fn :env env :name name :args args 

:code (optimize code)))) 

new-fn includes calls to an assembler and an optimizer to generate actual machine 
code. For the moment, both will be identity functions: 

(defun optimize (code) code) 
(defun assemble (fn) fn) 

Here are some more examples of the compiler at work: 

> (comp-show '(if (null? (car D) (f (+ (* a x) b)) 

(g (/ . 2)))) 
ARGS 0 
GVAR L 
CAR 
FJUMP LI 
GVAR X 
2 
/ 
GVAR G 
CALLJ 1 
LI: GVAR A 


<a id='page-807'></a>
GVAR X 

' 

GVAR . 

+ 

GVAR F 

CALLJ 1 

There is no need to save any continuation points in this code, because the only calls to 
nonprimitive functions occur as the final values of the two branches of the function. 

> (comp-show '(define (last l 1) 
(if (null ? (cdr D ) (car 1) 
(last l (cdr 1))))) 
ARGS 0 
FN 
ARGS 1 
LVAR 0 0 : L 
CDR 
FJUMP LI 
LVAR 0 0 ; L 
CDR 
GVAR LASTl 
CALLJ 1 
LI: LVAR 0 0 ; L 
CAR 
RETURN 
GSET LASTl 
CONST LASTl 
NAMEl 
RETURN 

The top-level function just assigns the nested function to the global variable last1. 
Since last1 is tail-recursive, it has only one return point, for the termination case, 
and just calls itself without saving continuations until that case is executed. 

Contrast that to the non-tail-recursive definition of length below. It is not tail-
recursive because before it calls length recursively, it must save a continuation point, 
Kl, so that it will know where to return to to add 1. 


<a id='page-808'></a>

> (comp-show '(define (length 1) 

(if (null? 1) 0 (+ 1 (length (cdr 1)))))) 
ARGS 0 
FN 

ARGS 1 
LVAR 0 0 ; L 
FJUMP L2 
1 
SAVE KI 
LVAR 0 0 ; L 
CDR 
GVAR LENGTH 
CALLJ 1 

KI: + 
RETURN 
L2: 0 

RETURN 
GSET LENGTH 
CONST LENGTH 
NAME! 
RETURN 

Of course, it is possible to write length in tail-recursive fashion: 

> (comp-show '(define (length 1) 
(letrec (den (lambda (1 n) 
(if (null? 1) . 
(len (rest 1) (+ . 1)))))) 

(len 1 0))) ) 
ARGS 0 
FN 
ARGS 1 
NIL 
FN 
ARGS 1 
FN 
ARGS 2 
LVAR 0 0 ; L 
FJUMP L2 
SAVE KI 
LVAR 0 0 ; L 
GVAR REST 
CALLJ 1 
KI: LVAR 0 1 : . 
1 
+ 
LVAR 1 0 ; LEN 


<a id='page-809'></a>

CALLJ 
L2: LVAR 

RETURN 
LSET 0 LEN 
POP 
LVAR L 
0 
LVAR LEN 
CALLJ 

CALLJ 1 
GSET LENGTH 
CONST LENGTH 
NAME! 
RETURN 

Let's look once again at an example with nested conditionals: 

> (comp-show '(if (not (and . q (not r))) . y)) 
ARGS 0 
GVAR . 
FJUMP L3 
GVAR Q 
FJUMP LI 
GVAR R 
NOT 
JUMP L2 

LI: NIL 
L2: JUMP L4 
L3: NIL 
L4: FJUMP L5 
GVAR Y 
RETURN 
L5: GVAR X 
RETURN 

Here the problem is with multiple JUMPs and with not recognizing negation. If . is 
false, then the and expression is false, and the whole predicate is true, so we should 
return x. The code does in fact return x, but it first jumps to L3, loads NIL, and then 
does an FJUMP that will always jump to L5. Other branches have similar inefficiencies. 
A sufficiently clever compiler should be able to generate the following code: 


<a id='page-810'></a>

ARGS O 
GVAR . 
FJUMP LI 
GVAR Q 
FJUMP LI 
GVAR R 
TJUMP LI 
GVAR Y 
RETURN 

LI: GVAR X 
RETURN 
23.2 Introducing Call/cc 
Now that the basic compiler works, we can think about how to implement call /cc 
in our compiler. First, remember that call / cc is a normal function, not a special 
form. So we could define it as a primitive, in the manner of ca r and cons. However, 
primitives as they have been defined only get to see their arguments, and cal 1 / cc 
will need to see the run-time stack, in order to save away the current continuation. 
One choice is to install cal 1 / cc as a normal Scheme nonprimitive function but to 
write its body in assembly code ourselves. We need to introduce one new instruction, 
CC, which places on the stack a function (to which we also have to write the assembly 
code by hand) that saves the current continuation (the stack) in its environment, and, 
when called, fetches that continuation and installs it, by setting the stack back to that 
value. This requires one more instruction, SET-CC. The details of this, and of all the 
other instructions, are revealed in the next section. 

23.3 The Abstract Machine 
So far we have defined the instruction set of a mythical abstract machine and generated 
assembly code for that instruction set. It's now time to actually execute the 
assembly code and hence have a useful compiler. There are several paths we could 
pursue: we could implement the machine in hardware, software, or microcode, or 
we could translate the assembly code for our abstract machine into the assembly 
code of some existing machine. Each of these approaches has been taken in the past. 

Hardware. If the abstract machine is simple enough, it can be implemented directly 
in hardware. The Scheme-79 and Scheme-81 Chips (Steele and Sussman 1980; 
Batali et al. 1982) were VLSI implementations of a machine designed specifically to 
run Scheme. 


<a id='page-811'></a>

Macro-Assembler. In the translation or macro-assembler approach, each instruction 
in the abstract machine language is translated into one or more instructions 
in the host computer's instruction set. This can be done either directly or by generating 
assembly code and passing it to the host computer's assembler. In general this 
will lead to code expansion, because the host computer probably will not provide 
direct support for Scheme's data types. Thus, whereas in our abstract machine we 
could write a single instruction for addition, with native code we might have to execute 
a series of instructions to check the type of the arguments, do an integer add if 
they are both integers, a floating-point add if they are both floating-point numbers, 
and so on. We might also have to check the result for overflow, and perhaps convert 
to bignum representation. Compilers that generate native code often include more 
sophisticated data-flow analysis to know when such checks are required and when 
they can be omitted. 

Microcode. The MIT Lisp Machine project, unlike the Scheme Chip, actually 
resulted in working machines. One important decision was to go with microcode 
instead of a single chip. This made it easy to change the system as experienced was 
gained, and as the host language was changed from ZetaLisp to Common Lisp. The 
most important architectural feature of the Lisp Machine was the inclusion of tag 
bits on each word to specify data types. Also important was microcode to implement 
certain frequently used generic operations. For example, in the Symbolics 3600 
Lisp Machine, the microcode for addition simultaneously did an integer add, a 
floating-point add, and a check of the tag bits. If both arguments turned out to 
be either integers or floating-point numbers, then the appropriate result was taken. 
Otherwise, a trap was signaled, and a converison routine was entered. This approach 
makes the compiler relatively simple, but the trend in architecture is away from highly 
microcoded processors toward simpler (RISC) processors. 

Software. We can remove many of these problems with a technique known as 
byte-code assembly. Here we translate the instructions into a vector of bytes and then 
interpret the bytes with a byte-code interpreter. This gives us (almost) the machine 
we want; it solves the code expansion problem, but it may be slower than native code 
compilation, because the byte-code interpreter is written in software, not hardware 
or microcode. 

Each opcode is a single byte (we have less than 256 opcodes, so this will work). 
The instructions with arguments take their arguments in the following bytes of the 
instruction stream. So, for example, a CALL instruction occupies two bytes; one for 
the opcode and one for the argument count. This means we have imposed a limit 
of 256 arguments to a function call. An LVAR instruction would take three bytes; 
one for the opcode, one for the frame offset, and one for the offset within the frame. 
Again, we have imposed 256 as the limit on nesting level and variables per frame. 
These limits seem high enough for any code written by a human, but remember, 
not only humans write code. It is possible that some complex macro may expand 
into something with more than 256 variables, so a full implementation would have 


<a id='page-812'></a>

some way of accounting for this. The GVAR and CONST instructions have to refer to an 
arbitrary object; either we can allocate enough bytes to fit a pointer to this object, or 
we can add a constants field to the f . structure, and follow the instructions with a 
single-byte index into this vector of constants. This latter approach is more common. 

We can now handle branches by changing the program counter to an index into 
the code vector. (It seems severe to limit functions to 256 bytes of code; a two-byte 
label allows for 65536 bytes of code per function.) In summary, the code is more 
compact, branching is efficient, and dispatching can be fast because the opcode is a 
small integer, and we can use a branch table to go to the right piece of code for each 
instruction. 

Another source of inefficiency is implementing the stack as a list, and consing up 
new cells every time something is added to the stack. The alternative is to implement 
the stack as a vector with a fill-pointer. That way a push requires no consing, only a 
change to the pointer (and a check for overflow). The check is worthwhile, however, 
because it allows us to detect infinite loops in the user's code. 

Here follows an assembler that generates a sequence of instructions (as a vector). 
This is a compromise between byte codes and the assembly language format. First, 
we need some accessor functions to get at parts of an instruction: 

(defun opcode (instr) (if (label-p instr) ilabel (first instr))) 
(defun args (instr) (if (listp instr) (rest instr))) 
(defun argl (instr) (if (listp instr) (second instr))) 
(defun arg2 (instr) (if (listp instr) (third instr))) 
(defun arg3 (instr) (if (listp instr) (fourth instr))) 

(defsetf argl (instr) (val) '(setf (second .instr) ,val)) 

Now we write the assembler, which already is integrated into the compiler with a 
hook in new-fn. 

(defun assemble (fn) 
"Turn a list of instructions into a vector." 
(multiple-value-bind (length labels) 

(asm-first-pass (fn-code fn)) 
(setf (fn-code fn) 
(asm-second-pass (fn-code fn) 
length labels)) 
fn)) 

(defun asm-first-pass (code) 
"Return the labels and the total code length." 
(let ((length 0) 

(labels nil)) 
(dolist (instr code) 
(if (label-p instr) 


<a id='page-813'></a>
(push (cons instr length) labels) 
(incf length))) 
(values length labels))) 

(defun asm-second-pass (code length labels) 
"Put code into code-vector, adjusting for labels." 
(let ((addr 0) 

(code-vector (make-array length))) 
(dolist (instr code) 
(unless (label-p instr) 
(if (is instr '(JUMP TJUMP FJUMP SAVE)) 
(setf (argl instr) 

(cdr (assoc (argl instr) labels)))) 
(setf (aref code-vector addr) instr) 
(incf addr))) 

code-vector)) 

If we want to be able to look at assembled code, we need a new printing function: 

(defun show-fn (fn &optional (stream *standard-output*) (indent 2)) 
"Print all the instructions in a function. 
If the argument is not a function, just princ it, 
but in a column at least 8 spaces wide." 

This version handles code that has been assembled into a vector 

(if (not (fn-p fn)) 
(format stream ""Sa" fn) 
(progn 

(fresh-1ine) 
(dotimes (i (length (fn-code fn))) 
(let ((instr (elt (fn-code fn) i))) 

(if (label-p instr) 
(format stream ""a:" instr) 
(progn 

(format stream "~VT~2d: " indent i) 
(dolist (arg instr) 
(show-fn arg stream (+ indent 8))) 
(fresh-line)))))))) 

(defstruct ret-addr fn pc env) 

(defun is (instr op) 
"True if instr's opcode is OP, or one of OP when OP is a list." 
(if (listp op) 

(member (opcode instr) op) 
(eq (opcode instr) op))) 

(defun top (stack) (first stack)) 


<a id='page-814'></a>

(defun machine (f) 
"Run the abstract machine on the code for f." 
(let* ((code (fn-code f)) 

(pc 0) 
(env nil) 
(stack nil) 
(n-args 0) 
(instr)) 

(loop 
(setf instr (elt code pc)) 
(incf pc) 
(case (opcode instr) 

Variable/stack manipulation instructions: 
(LVAR (push (elt (elt env (argl instr)) (arg2 instr)) 
stack)) 
(LSET (setf (elt (elt env (argl instr)) (arg2 instr)) 

(top stack))) 
(GVAR (push (get (argl instr) 'global-val) stack)) 
(GSET (setf (get (argl instr) 'global-val) (top stack))) 
(POP (pop stack)) 
(CONST (push (argl instr) stack)) 

Branching instructions: 
(JUMP (setf pc (argl instr))) 
(FJUMP (if (null (pop stack)) (setf pc (argl instr)))) 
(TJUMP (if (pop stack) (setf pc (argl instr)))) 

;; Function call/return instructions: 
(SAVE (push (make-ret-addr :pc (argl instr) 
:fn f :env env) 
stack)) 
(RETURN return value is top of stack; ret-addr is second 

(setf f (ret-addr-fn (second stack)) 
code (fn-code f) 
env (ret-addr-env (second stack)) 
pc (ret-addr-pc (second stack))) 

;; Get rid of the ret-addr. but keep the value 
(setf stack (cons (first stack) (rest2 stack)))) 

(CALLJ (pop env) : discard the top frame 
(setf f (pop stack) 
code (fn-code f) 
env (fn-env f) 
pc 0 
n-args (argl instr))) 
(ARGS (assert (= n-args (argl instr)) () 


<a id='page-815'></a>
"Wrong number of arguments:~ 
"d expected, ~d supplied" 
(argl instr) n-args) 

(push (make-array (argl instr)) env) 

(loop for i from (- n-args 1) downto 0 do 
(setf (elt (first env) i) (pop stack)))) 

(ARGS. (assert (>= n-args (argl instr)) () 
"Wrong number of arguments:~ 
~d or more expected, ~d supplied" 
(argl instr) n-args) 

(push (make-array (+ 1 (argl instr))) env) 
(loop repeat (- n-args (argl instr)) do 
(push (pop stack) (elt (first env) (argl instr)))) 
(loop for i from (- (argl instr) 1) downto 0 do 
(setf (elt (first env) i) (pop stack)))) 
(FN (push (make-fn :code (fn-code (argl instr)) 
:env env) stack)) 
(PRIM (push (apply (argl instr) 

(loop with args = nil repeat n-args 
do (push (pop stack) args) 
finally (return args))) 

stack)) 

Continuation instructions: 
(SET-CC (setf stack (top stack))) 
(CC (push (make-fn 

:env (list (vector stack)) 
:code '((ARGS 1) (LVAR 1 0 ";" stack) (SET-CC) 
(LVAR 0 0) (RETURN))) 
stack)) 

Nullary operations: 
((SCHEME-READ NEWLINE) 
(push (funcall (opcode instr)) stack)) 

Unary operations: 
((CAR CDR CADR NOT LISTl COMPILER DISPLAY WRITE RANDOM) 
(push (funcall (opcode instr) (pop stack)) stack)) 

Binary operations: 
((+.*/<><=>=/:. = CONS LIST2 NAME! EQ EQUAL EQL) 
(setf stack (cons (funcall (opcode instr) (second stack) 
(first stack)) 
(rest2 stack)))) 


<a id='page-816'></a>

Ternary operations: 
(LIST3 
(setf stack (cons (funcall (opcode instr) (third stack) 
(second stack) (first stack)) 
(rests stack)))) 

;; Constants: 
((T NIL -10 12) 
(push (opcode instr) stack)) 

Other: 
((HALT) (RETURN (top stack))) 
(otherwise (error "Unknown opcode: ~a" instr)))))) 

(defun init-scheme-comp () 
"Initialize values (including call/cc) for the Scheme compiler." 
(set-global-var! 'exit 

(new-fn :name 'exit :args '(val) :code '((HALT)))) 
(set-global-var! 'call/cc 
(new-fn :name 'call/cc :args '(f) 
:code '((ARGS 1) (CC) (LVAR 0 0 f) (CALLJ 1)))) 
(dolist (prim *primitive-fns*) 
(setf (get (prim-symbol prim) 'global-val) 
(new-fn :env nil :name (prim-symbol prim) 
:code (seq (gen 'PRIM (prim-symbol prim)) 
(gen 'RETURN)))))) 

Here's the Scheme top level. Note that it is written in Scheme itself; we compile 
the definition of the read-eval-print loop/ load it into the machine, and then start 
executing it. There's also an interface to compile and execute a single expression, 
comp-go. 

(defconstant scheme-top-level 

'(begin(define (scheme) 
(newline) 
(display "=> ") 
(write ((compiler (read)))) 
(scheme)) 

(scheme))) 

(defun scheme () 
"A compiled Scheme read-eval-print loop" 
(init-scheme-comp) 
(machine (compiler scheme-top-1evel))) 

^Strictly speaking, this is a read-compile-funcall-vmte loop. 


<a id='page-817'></a>
(defun comp-go (exp) 
"Compile and execute the expression." 
(machine (compiler '(exit .exp)))) 

&#9635; Exercise 23.2 [m] This implementation of the machine is wasteful in its representation 
of environments. For example, consider what happens in a tail-recursive 
function. Each ARG instruction builds a new frame and pushes it on the environment. 
Then each CALL pops the latest frame off the environment. So, while the stack does 
not grow with tail-recursive calls, the heap certainly does. Eventually, we will have 
to garbage-collect all those unused frames (and the cons cells used to make lists out 
of them). How could we avoid or limit this garbage collection? 

23.4 A Peephole Optimizer 
In this section we investigate a simple technique that will generate slightly better 
code in cases where the compiler gives inefficient sequences of instructions. The 
idea is to look at short sequences of instructions for prespecified patterns and replace 
them with equivalent but more efficient instructions. 

In the following example, comp - i f has already done some source-level optimization, 
such as eliminating the (fx) call, 

> (comp-show '(begin (if (if t 1 (f x)) (set! . 2)) .)) 

O:ARGS O 
1: 1 
2: FJUMP 6 
3: 2 
4:GSET X 
5: POP 
6:GVAR X 
7:RETURN 
But the generated code could be made much better. This could be done with more 
source-level optimizations to transform the expression into (set! . 2). Alternatively, 
it could also be done by looking at the preceding instruction sequence and 
transforming local inefficiencies. The optimizer presented in this section is capable 
of generating the following code: 


<a id='page-818'></a>

> (comp-show '(begin (if (if t 1 (f x)) (set! . 2)) .)) 

0: ARGS O 
1: 2 
2:GSET X 
3:RETURN 
The function optimize is implemented as a data-driven function that looks at 
the opcode of each instruction and makes optimizations based on the following 
instructions. To be more specific, opti mi ze takes a hst of assembly language instructions 
and looks at each instruction in order, trying to apply an optimization. If any 
changes at all are made, then opti mi ze will be called again on the whole instruction 
list, because further changes might be triggered by the first round of changes. 

(defun optimize (code) 
"Perform peephole optimization on assembly code." 
(let ((any-change nil)) 

Optimize each tail 
(loop for code-tail on code do 
(setf any-change (or (optimize-1 code-tail code) 

any-change))) 
;; If any changes were made, call optimize again 
(if any-change 

(optimize code) 
code))) 

The function optimize-1 is responsible for each individual attempt to optimize. It 
is passed two arguments: a list of instructions starting at the current one and going 
to the end of the list, and a list of all the instructions. The second argument is 
rarely used. The whole idea of a peephole optimizer is that it should look at only a 
few instructions following the current one. opti mi ze -1 is data-driven, based on the 
opcode of the first instruction. Note that the optimizer functions do their work by 
destructively modifying the instruction sequence, not by consing up and returning a 
new sequence. 

(defun optimize-1 (code all-code) 
"Perform peephole optimization on a tail of the assembly code. 
If a change is made, return true." 
;; Data-driven by the opcode of the first instruction 
(let* ((instr (first code)) 

(optimizer (get-optimizer (opcode instr)))) 
(when optimizer 
(funcall optimizer instr code all-code)))) 


<a id='page-819'></a>
We need a table to associate the individual optimizer functions with the opcodes. 
Since opcodes include numbers as well as symbols, an eq 1 hash table is an appropriate 
choice: 

(let ((optimizers (make-hash-table :test #'eql))) 

(defun get-optimizer (opcode) 
"Get the assembly language optimizer for this opcode." 
(gethash opcode optimizers)) 

(defun put-optimizer (opcode fn) 
"Store an assembly language optimizer for this opcode." 
(setf (gethash opcode optimizers) fn))) 

We could now build a table with put-opt i mi zer, but it is worth defining a macro to 
make this a Httle neater: 

(defmacro def-optimizer (opcodes args &body body) 
"Define assembly language optimizers for these opcodes." 
(assert (and (listp opcodes) (listp args) (= (length args) 3))) 
'(dolist (op '.opcodes) 

(put-optimizer op #*(lambda .args ..body)))) 

Before showing example optimizer functions, we will introduce three auxiliary functions, 
geni generates a single instruction, target finds the code sequence that a 
jump instruction branches to, and next-i nstr finds the next actual instruction in a 
sequence, skipping labels. 

(defun geni (&rest args) "Generate a single instruction" args) 
(defun target (instr code) (second (member (argl instr) code))) 
(defun next-instr (code) (find-if (complement #*label-p) code)) 

Here are six optimizer functions that implement a few important peephole optimizations. 


(def-optimizer (:LABEL) (instr code all-code) 
... L ... => ;if no reference to L 
(when (not (find instr all-code :key #'argl)) 
(setf (first code) (second code) 
(rest code) (rest2 code)) 
t)) 


<a id='page-820'></a>

(def-optimizer (GSET LSET) (instr code all-code) 
;; ex: (begin (set! . y) (if . .)) 
(SET .) (POP) (VAR X) ==> (SET X) 
(when (and (is (second code) 'POP) 
(is (third code) '(GVAR LVAR)) 
(eq (argl instr) (argl (third code)))) 
(setf (rest code) (nthcdr 3 code)) 
t)) 

(def-optimizer (JUMP CALL CALLJ RETURN) (instr code all-code) 
(JUMP LI) ...dead code... L2 ==> (JUMP LI) L2 
(setf (rest code) (member-if #'label-. (rest code))) 
(JUMP LI) ... LI (JUMP L2) ==> (JUMP L2) ... LI (JUMP L2) 
(when (and (is instr 'JUMP) 
(is (target instr code) '(JUMP RETURN)) 
(setf (first code) (copy-list (target instr code))) 
t))) 

(def-optimizer (TJUMP FJUMP) (instr code all-code) 
(FJUMP LI) .. . LI (JUMP L2) ==> (FJUMP L2) .. . LI (JUMP L2) 
(when (is (target instr code) 'JUMP) 
(setf (second instr) (argl (target instr code))) 
t)) 

(def-optimizer (T -1 0 1 2) (instr code all-code) 
(case (opcode (second code)) 
(NOT :; (T) (NOT) ==> NIL 
(setf (first code) (geni 'NID 
(rest code) (rest2 code)) 
t) 
(FJUMP (T) (FJUMP L) ... => .. . 
(setf (first code) (third code) 
(rest code) (rest3 code)) 
t) 
(TJUMP ;: (T) (TJUMP L) ... => (JUMP L) .. . 
(setf (first code) (geni 'JUMP (argl (next-instr code)))) 
t))) 


<a id='page-821'></a>
(def-optimizer (NIL) (instr code all-code) 
(case (opcode (second code)) 
(NOT ;; (NIL) (NOT) ==> . 
(setf (first code) (geni '.) 
(rest code) (rest2 code)) 
t) 
(TJUMP (NIL) (TJUMP L) ... => .. . 
(setf (first code) (third code) 
(rest code) (rest3 code)) 
t) 

(FJUMP (NIL) (FJUMP L) ==> (JUMP L) 
(setf (first code) (geni 'JUMP (argl (next-instr code)))) 
t))) 

23.5 Languages with Different Lexical 
Conventions 
This chapter has shown how to evaluate a language with Lisp-like syntax, by writing 
a read-eval-print loop where only the eval needs to be replaced. In this section we 
see how to make the read part slightly more general. We still read Lisp-like syntax, 
but the lexical conventions can be slightly different. 

The Lisp function read is driven by an object called the readtable, which is stored 
in the special variable *readtabl e*. This table associates some action to take with 
each of the possible characters that can be read. The entry in the readtable for the 
character #\ (, for example, would be directions to read a list. The entry for # \; would 
be directions to ignore every character up to the end of the line. 

Because the readtable is stored in a special variable, it is possible to alter completely 
the way read works just by dynamically rebinding this variable. 

The new function scheme - read temporarily changes the readtable to a new one, 
the Scheme readtable. It also accepts an optional argument, the stream to read 
from, and it returns a special marker on end of file. This can be tested for with the 
predicate eof-object?. Note that once scheme- read is installed as the value of the 
Scheme symbol read we need do no more-scheme- read will always be called when 
appropriate (by the top level of Scheme, and by any user Scheme program). 

(defconstant eof "EoF") 
(defun eof-object? (x) (eq . eof)) 
(defvar *scheme-readtable* (copy-readtable)) 


<a id='page-822'></a>

(defun scheme-read (&optional (stream *standard-input*)) 
(let ((*readtable* *scheme-readtable*)) 
(read stream nil eof))) 

The point of having a special eof constant is that it is unforgeable. The user cannot 
type in a sequence of characters that will be read as something eq to eof. In Common 
Lisp, but not Scheme, there is an escape mechanism that makes eof forgable. The 
user can type #.eof to get the effect of an end of file. This is similar to the "D 
convention in UNIX systems, and it can be quite handy. 

So far the Scheme readtable is just a copy of the standard readtable. The next step 
in implementing scheme-read is to alter *scheme- readtabl e*, adding read macros 
for whatever characters are necessary. Here we define macros for #t and #f (the true 
and false values), for #d (decimal numbers) and for the backquote read macro (called 
quasiquote in Scheme). Note that the backquote and conruna characters are defined 
as read macros, but the @ in ,@ is processed by reading the next character, not by a 
read macro on @. 

(set-dispatch-macro-character #\# #\t 
#*(lambda (&rest ignore) t) 
*scheme-readtable*) 

(set-dispatch-macro-character #\# #\f 
#.(lambda (&rest ignore) nil) 
*scheme-readtable*) 

(set-dispatch-macro-character #\# #\d 
In both Common Lisp and Scheme, 
;; #x, #0 and #b are hexidecimal, octal, and binary, 

e.g. #xff = #o377 = #bllllllll = 255 
In Scheme only, #d255 is decimal 255. 
#*(lambda (stream &rest ignore) 
(let ((*read-base* 10)) (scheme-read stream))) 
*scheme-readtable*) 

(set-macro-character #\* 
#*(lambda (s ignore) (list 'quasiquote (scheme-read s))) 
nil *scheme-readtable*) 

(set-macro-character #\, 
#'(lambda (stream ignore) 
(let ((ch (read-char stream))) 

(if (char= ch #\@) 
(list 'unquote-splicing (read stream)) 
(progn (unread-char ch stream) 

(list 'unquote (read stream)))))) 
nil *scheme-readtable*) 

Finally, we install scheme- read and eof-object? as primitives: 


<a id='page-823'></a>
(defparameter *primitive-fns* 

.((+ 2 + true nil) (-2 - true nil) (* 2 * true nil) (/ 2 / true nil) 
(< 2 < nil nil) (> 2 > nil nil) (<= 2 <= nil nil) (>= 2 >= nil nil) 
(/= 2 /= nil nil) (= 2 = nil nil) 
(eq? 2 eq nil nil) (equal? 2 equal nil nil) (eqv? 2 eql nil nil) 
(not 1 not nil nil) (null? 1 not nil nil) (cons 2 cons true nil) 
(car 1 car nil nil) (cdr 1 cdr nil nil) (cadr 1 cadr nil nil) 
(list 1 listl true nil) (list 2 list2 true nil) (list 3 list3 true nil) 
(read 0 read nil t) (write 1 write nil t) (display 1 display nil t) 
(newline 0 newline nil t) (compiler 1 compiler t nil) 
(name! 2 name! true t) (random 1 random true nil))) 

Here we test scheme -read. The characters in italics were typed as a response to the 
scheme-read. 

> (scheme-read) #f 
. 

> (scheme-read) #/ 
NIL 

> (scheme-read) '(a,b,@cd) 
(QUASIQUOTE (A (UNQUOTE B) (UNQUOTE-SPLICING C) D)) 

The final step is to make quasi quote a macro that expands into the proper sequence 
of calls to cons, 1 i st, and append. The careful reader will keep track of the difference 
between the form returned by scheme-read (something starting with quasi quote), 
the expansion of this form with the Scheme macro quasi quote (which is implemented 
with the Common Lisp function qua si - q), and the eventual evaluation of the 
expansion. In an environment where b is bound to the number 2 and c is bound to 
the Ust (cl c2), we might have: 

Typed: '(a ,b .@c d) 
Read: (quasiquote (a (unquote b) (unquote-splicing c) d)) 
Expanded: (cons 'a (cons b (append c '(d)))) 
Evaluated: (a 2 cl c2 d) 

The implementation of the quasi quote macro is modeled closely on the one given 
in Charniak et al.'s Artificial Intelligence Programming. I added support for vectors. In 
combi ne - quas i quote I add the trick of reusing the old cons cell . rather than consing 
together 1 eft and ri ght when that is possible. However, the implementation still 
wastes cons cells - a more efficient version would pass back multiple values rather 
than consing quote onto a list, only to strip it off again. 


<a id='page-824'></a>

(setf (scheme-macro 'quasiquote) 'quasi-q) 

(defun quasi-q (x) 
"Expand a quasi quote form into append, list, and cons calls. " 
(cond 
((vectorp x) 
(list 'apply 'vector (quasi-q (coerce . 'list)))) 
((atom x) 
(if (constantp x) . (list 'quote x))) 
((starts-with . 'unquote) 
(assert (and (rest x) (null (rest2 x)))) 
(second x)) 
((starts-with . 'quasiquote) 
(assert (and (rest x) (null (rest2 x)))) 
(quasi-q (quasi-q (second x)))) 
((starts-with (first x) 'unquote-splicing) 
(if (null (rest x)) 
(second (first x)) 
(list 'append (second (first x)) (quasi-q (rest x))))) 
(t (combine-quasiquote (quasi-q (car x)) 
(quasi-q (cdr x)) 
x)))) 

(defun combine-quasiquote (left right x) 
"Combine left and right (car and cdr), possibly re-using x." 
(cond ((and (constantp left) (constantp right)) 
(if (and (eql (eval left) (first x)) 
(eql (eval right) (rest x))) 
(list 'quote x) 
(list 'quote (cons (eval left) (eval right))))) 
((null right) (list 'list left)) 
((starts-with right 'list) 
(list* 'list left (rest right))) 
(t (list 'cons left right)))) 

Actually, there is a major problem with the quasi quote macro, or more accurately, in 
the entire approach to macro-expansion based on textual substitution. Suppose we 
wanted a function that acted like this: 

> (extrema '(3 1 10 5 20 2)) 
((max 20) (min D ) 


<a id='page-825'></a>
We could write the Scheme function: 

(define (extrema list) 
Given a list of numbers, return an a-list 
with max and min values 

'((max .(apply max list)) (min .(apply min list)))) 

After expansion of the quasiquote, the definition of extrema will be: 

(define extrema 
(lambda (list) 
(list (list 'max (apply max list)) 
(list 'min (apply min list))))) 

The problem is that 1 i st is an argument to the function extrema, and the argument 
shadows the global definition of 1 i st as a function. Thus, the function will fail. One 
way around this dilemma is to have the macro-expansion use the global value of 1 is t 
rather than the symbol 1 i st itself. In other words, replace the 'list in quasi -q with 
(get - gl oba 1 - va r 'list). Then the expansion can be used even in an environment 
where 1 i st is locally bound. One has to be careful, though: if this tack is taken, then 
comp - funcall should be changed to recognize function constants, and to do the right 
thing with respect to primitives. 

It is problems like these that made the designers of Scheme admit that they 
don't know the best way to specify macros, so there is no standard macro definition 
mechanism in Scheme. Such problems rarely come up in Common Lisp because 
functions and variables have different name spaces, and because local function 
definitions (with flet or 1 abel s) are not widely used. Those who do define local 
functions tend not to use already estabUshed names like 1 i st and append. 

23.6 History and References 
Guy Steele's 1978 MIT master's thesis on the language Scheme, rewritten as Steele 
1983, describes an innovative and influential compiler for Scheme, called RABBFI.^ 
A good article on an "industrial-strength" Scheme compiler based on this approach 
is described in Kranz et al.'s 1986 paper on ....., the compiler for the . dialect of 
Scheme. 

Abelson and Sussman's Structure and Interpretation of Computer Programs (1985) 
contains an excellent chapter on compilation, using slightly different techniques and 
compiling into a somewhat more confusing machine language. Another good text 

^At the time, the MacLisp compiler dealt with something called "lisp assembly code" or 
LAP. The function to input LAP was called 1 api .. Those who know French will get the pun. 


<a id='page-826'></a>

is John Allen's Anatomy of Lisp (1978). It presents a very clear, simple compiler, 
although it is for an older, dynamically scoped dialect of Lisp and it does not address 
tail-recursion or cal 1 / cc. 
The peephole optimizer described here is based on the one in Masinter and 
Deutsch 1980. 
23.7 Exercises 
&#9635; Exercise 23.3 [h] Scheme's syntax for numbers is slightly different from Common 
Lisp's. In particular, complex numbers are written like 3+4i rather than #c(3 4). 
How could you make scheme - read account for this? 

&#9635; Exercise 23.4 [m] Is it possible to make the core Scheme language even smaller, 
by eliminating any of the five special forms (quote, begin, set! , if, lambda) and 
replacing them with macros? 

&#9635; Exercise 23.5 [m] Add the ability to recognize internal defines (see [page 779](chapter22.md#page-779)). 

&#9635; Exercise 23.6 [h] In comp-if we included a special case for (i f t . y) and (i f 
nil X y). But there are other cases where we know the value of the predicate. For 
example, (i f (* a b). y) can also reduce to x. Arrange for these optimizations to 
be made. Note the prim -a 1 ways field of the prim structure has been provided for this 
purpose. 

&#9635; Exercise 23.7 [m] Consider the following version of the quicksort algorithm for 
sorting a vector: 
(define (sort-vector vector test) 
(define (sort lo hi) 
(if (>= lo hi) 
vector 
(let ((pivot (partition vector lo hi test))) 
(sort lo pivot) 
(sort (+ pivot 1) hi)))) 
(sort 0 (- (vector-length vector 1)))) 
Here the function parti ti on takes a vector, two indices into the vector, and a comparison 
function, test . It modifies the vector and returns an index, pi vot, such that 
all elements of the vector below pi vot are less than all elements at pi vot or above. 


<a id='page-827'></a>
It is well known that quicksort takes time proportional to . log . to sort a vector of 
. elements, if the pivots are chosen well. With poor pivot choices, it can take time 
proportional to TI?. 

The question is, what is the space required by quicksort? Besides the vector itself, 
how much additional storage must be temporarily allocated to sort a vector? 
Now consider the following modified version of quicksort. What time and space 
complexity does it have? 

(define (sort-vector vector test) 
(define (sort lo hi) 

(if (>= lo hi) 
vector 
(let ((pivot (partition vector lo hi))) 

(if (> (- hi pivot) (- pivot lo)) 
(begin (sort lo pivot) 
(sort (+ pivot 1) hi)) 
(begin (sort (+ pivot 1) hi) 
(sort lo pivot)))))) 
(sort 0 (- (vector-length vector 1)))) 

The next three exercises describe extensions that are not part of the Scheme 
standard. 

&#9635; Exercise 23.8 [h] The set! special form is defined only when its first argument is 
a symbol. Extend setl to work like setf when the first argument is a hst. That is, 
(set! (car x) y) should expand into something like ((setter car) y .), where 
(setter car) evaluates to the primitive procedure set-car!. You will need to add 
some new primitive functions, and you should also provide a way for the user to 
define new set! procedures. One way to do that would be with a setter function 
for set!, for example: 

(set! (setter third) 
(lambda (val list) (set-car! (cdr (cdr list)) val))) 

&#9635; Exercise 23.9 [m] Itis a curious asymmetry of Scheme that there isa special notation 
for lambda expressions within def i ne expressions, but not within let. Thus, we see 
the following: 

(define square (lambda (x) (* . .))) listhesameas 
(define (square .) (* . .)) 


<a id='page-828'></a>

(let ((square (lambda (x) (* . .)))) ...) ; is not the same as 
(let (((square x) (* . .))) ...) : <=illegal! 

Do you think this last expression should be legal? If so, modify the macros for 
let, let*, and letrec to allow the new syntax. If not, explain why it should not be 
included in the language. 

&#9635; Exercise 23.10 [m] Scheme does not define funcall, because the normal function-
call syntax does the work of funcall. This suggests two problems. (1) Is it possible 
to define funcall in Scheme? Show a definition or explain why there can't be one. 
Would you ever have reason to use funcall in a Scheme program? (2) Scheme does 
define appl y, as there is no syntax for an application. One might want to extend the 
syntax to make (+ . numbers) equivalent to (apply + numbers). Would this be a 
good idea? 

&#9635; Exercise 23.11 [d] Write a compiler that translates Scheme to Common Lisp. This 
will involve changing the names of some procedures and special forms, figuring out 
a way to map Scheme's single name space into Common Lisp's distinct function and 
variable name spaces, and dealing with Scheme's continuations. One possibility is 
to translate a cal 1 /cc into a catch and throw, and disallow dynamic continuations. 

23.8 Answers 
Answer 23.2 We can save frames by making a resource for frames, as was done 
on [page 337](chapter10.md#page-337). Unfortunately, we can't just use the def resource macro as is, because 
we need a separate resource for each size frame. Thus, a two-dimensional array or 
a vector of vectors is necessary. Furthermore, one must be careful in determining 
when a frame is no longer needed, and when it has been saved and may be used again. 
Some compilers will generate a special calling sequence for a tail-recursive call where 
the environment can be used as is, without discarding and then creating a new frame 
for the arguments. Some compilers have varied and advanced representations for 
environments. An environment may never be represented explicitly as a list of 
frames; instead it may be represented implicitly as a series of values in registers. 


<a id='page-829'></a>
Answer 23.3 We could read in Scheme expressions as before, and then convert any 
symbols that looked Hke complex numbers into numbers. The following routines do 
this without consing. 

(defun scheme-read (&optional (stream *standard-input*)) 
(let ((*readtable* *scheme-readtable*)) 
(convert-numbers (read stream nil eof)))) 

(defun convert-numbers (x) 
"Replace symbols that look like Scheme numbers with their values." 
Don't copy structure, make changes in place, 
(typecase . 
(cons (setf (car x) (convert-numbers (car x))) 
(setf (cdr x) (convert-numbers (cdr x))) 

X) 

(symbol (or (convert-number x) x)) 
(vector (dotimes (i (length x)) 
(setf (aref . i) (convert-numbers (aref . i)))) 
.) 
(t .))) 

(defun convert-number (symbol) 
"If str looks like a complex number, return the number." 
(let* ((str (symbol-name symbol)) 

(pos (position-if #'sign-p str)) 
(end (- (length str) 1))) 
(when (and pos (char-equal (char str end) #\i)) 
(let ((re (read-from-string str nil nil istart 0 :end pos)) 
(im (read-from-string str nil nil :start pos :end end))) 
(when (and (numberp re) (numberp im)) 
(complex re im)))))) 

(defun sign-p (char) (find char "+-")) 

Actually, that's not quite good enough, because a Scheme complex number can have 
multiple signs in it, as in 3. 4e- 5+6. 7e->-8i, and it need not have two numbers, as in 
31 or 4+i or just +i. The other problem is that complex numbers can only have a 
lowercase i, but read does not distinguish between the symbols 3+4i and 3+41. 


<a id='page-830'></a>

Answer 23.4 Yes, it is possible to implement begi . as a macro: 

(setf (scheme-macro 'begin) 
#'(1ambda (&rest exps) '((lambda () .,exps)))) 

With some work we could also eliminate quote. Instead of 'x, we could use 
(stri ng ->synibol " X"), and instead of ' (1 2), we could use something like (list 1 
2). The problem is in knowing when to reuse the same list. Consider: 

=> (define (one-two) '(1 2)) 
ONE-TWO 

=> (eq? (one-two) (one-two)) 

. 

=> (eq? '(1 2) '(1 2)) 
NIL 

A clever memoized macro for quote could handle this, but it would be less efficient 
than having quote as a special form. In short, what's the point? 
It is also (nearly) possible to replace i f with alternate code. The idea is to replace: 

(if test then-part else-part) 

with 

(test (delay then-part) (delay else-part)) 

Now if we are assured that any test returns either #t or #f, then we can make the 
following definitions: 

(define #t (lambda (then-part else-part) (force then-part))) 
(define #f (lambda (then-part else-part) (force else-part))) 

The only problem with this is that any value, not just #t, counts as true. 

This seems to be a common phenomenon in Scheme compilers: translating 
everything into a few very general constructs, and then recognizing special cases of 
these constructs and compiling them specially. This has the disadvantage (compared 
to explicit use of many special forms) that compilation may be slower, because all 
macros have to be expanded first, and then special cases have to be recognized. It 
has the advantage that the optimizations will be applied even when the user did not 
have a special construct in mind. Common Lisp attempts to get the advantages of 
both by allowing implementations to play loose with what they implement as macros 
and as special forms. 


<a id='page-831'></a>
Answer 23.6 We define the predicate a 1 ways and install it in two places in comp - i f: 

(defun always (pred env) 
"Does predicate always evaluate to true or false? " 
(cond ((eq pred t) 'true) 

((eq pred nil) 'false) 
((symbolp pred) nil) 
((atom pred) 'true) 
((scheme-macro (first pred)) 

(always (scheme-macro-expand pred) env)) 

((case (first pred) 
(QUOTE (if (null (second pred)) 'false 'true)) 
(BEGIN (if (null (rest pred)) 'false 

(always (lastl pred) env))) 
(SET! (always (third pred) env)) 
(IF (let ((test (always (second pred)) env) 

(then (always (third pred)) env) 
(else (always (fourth pred)) env)) 

(cond ((eq test 'true) then) 
((eq test 'false) else) 
((eq then else) then)))) 

(LAMBDA 'true) 
(t (let ((prim (primitive-p (first pred) env 
(length (rest pred))))) 
(if prim (prim-always prim)))))))) 

(defun comp-if (pred then else env val? more?) 
(case (always pred env) 

(true ; (if nil . y) ==> y ; *** 
(comp then env val? more?)) ; *** 
(false ; (if t . y) ==> . ; *** 
(comp else env val? more?)) ; *** 

(otherwise 

(let ((pcode (comp pred env t t)) 
(tcode (comp then env val? more?)) 
(ecode (comp else env val? more?))) 

(cond 

((and (listp pred) ; (if (not p) . y) ==> (if pyx) 
(length=1 (rest pred)) 
(primitive-p (first pred) env 1) 
(eq (prim-opcode (primitive-p (first pred) env 1)) 

'not)) 
(comp-if (second pred) else then env val? more?)) 
((equal tcode ecode) ; (if . . x) ==> (begin . .) 
(seq (comp pred env nil t) ecode)) 
((null tcode) ; (if . nil y) ==> . (TJUMP L2) y L2: 
(let ((L2 (gen-label))) 
(seq pcode (gen 'TJUMP L2) ecode (list L2) 


<a id='page-832'></a>

(unless more? (gen 'RETURN))))) 
((null ecode) ; (if . .) ==> . (FJUMP LI) . LI: 
(let ((LI (gen-label))) 
(seq pcode (gen TJUMP LI) tcode (list LI) 
(unless more? (gen 'RETURN))))) 
(t ; (if . X y) ==> . (FJUMP LI) . LI: y 
: or . (FJUMP LI) . (JUMP L2) LI: y L2: 
(let ((LI (gen-label)) 
(L2 (if more? (gen-label)))) 

(seq pcode (gen 'FJUMP LI) tcode 
(if more? (gen 'JUMP L2)) 
(list LI) ecode (if more? (list L2)))))))))) 

Developnient note: originally, I had coded a1 ways as a predicate that took a Boolean 
value as input and returned true if the expression always had that value. Thus, you 
had to ask first if the predicate was always true, and then if it was always false. Then 
I realized this was duplicating much effort, and that the duplication was exponential, 
not just linear: for a triply-nested conditional I would have to do eight times the 
work, not tw^ice the work. Thus I switched to the above formulation, where always 
is a three-valued function, returning true, f al se, or ni 1 for none-of-the-above. But 
to demonstrate that the right solution doesn't always appear the first time, I give my 
original definition as well: 

(defun always (boolean pred env) 
"Does predicate always evaluate to boolean in env?" 
(if (atom pred) 

(and (constantp pred) (equiv boolean pred)) 

(case (first pred) 
(QUOTE (equiv boolean pred)) 
(BEGIN (if (null (rest pred)) (equiv boolean nil) 

(always boolean (lastl pred) env))) 
(SET! (always boolean (third pred) env)) 
(IF (or (and (always t (second pred) env) 

(always boolean (third pred) env)) 
(and (always nil (second pred) env) 
(always boolean (fourth pred) env)) 
(and (always boolean (third pred) env) 

(always boolean (fourth pred) env)))) 
(LAMBDA (equiv boolean t)) 
(t (let ((prim (primitive-p (first pred) env 

(length (rest pred))))) 
(and prim 
(eq (prim-always prim) 
(if boolean 'true 'false)))))))) 

(defun equiv (x y) "Boolean equivalence" (eq (not x) (not y))) 


<a id='page-833'></a>

Answer 23.7 The original version requires 0 (n) stack space for poorly chosen 
pivots. Assuming a properly tail-recursive compiler, the modified version will never 
require more than O(logn) space, because at each step at least half of the vector is 
being sorted tail-recursively. 

Answer 23.10 (1) (defun (funcall fn . args) (apply fn args)) 

(2) Suppose you changed the piece of code (+ . numbers) to (+ . (map sqrt 
numbers)). The latter is the same expression as (+ map sqrt numbers), which is 
not the intended result at all. So there would be an arbitrary restriction: the last 
argument in an apply form would have to be an atom. This kind of restriction goes 
against the grain of Scheme. 

## Chapter 24
<a id='page-834'></a>

ANSI Common Lisp 

I 1 his chapter briefly covers some advanced features of Conunon Lisp that were not used 

in the rest of the book. The first topic, packages, is crucial in building large systems but 

was not covered in this book, since the programs are concise. The next four topics-error 
handling, pretty printing, series, and the loop macro - are covered in Common Lisp the Language, 
2d edition, but not in the first edition of the book. Thus, they may not be applicable to your Lisp 
compiler. The final topic, sequence functions, shows how to write efficient functions that work 
for either lists or vectors. 

I. 

24.1 Packages 
Apackage is a symbol table that maps from strings to symbols named by those strings. When 
read is confronted with a sequence of characters like 1 i st, it uses the symbol table to determine 
that this refers to the symbol 1 i st. The important point is that every use of the symbol name 
1 i st refers to the same symbol. That makes it easy to refer to predefined symbols, but it also 
makes it easy to introduce unintended name conflicts. For example, if I wanted to hook up the 
emyci . expert system from chapter 16 with the parser from chapter 19, there would be a conflict 
because both programs use the symbol def rul e to mean different things. 


<a id='page-835'></a>
Common Lisp uses the package system to help resolve such conflicts. Instead of 
a single symbol table. Common Lisp allows any number of packages. The function 
read always uses the current package, which is defined to be the value of the special 
variable ^package*. By default. Lisp starts out in the common-1 i sp-user package.^ 
That means that if we type a new symbol, like zxv@!?+qw, it will be entered into 
that package. Converting a string to a symbol and placing it in a package is called 
interning. It is done automatically by read, and can be done by the function i ntern 
if necessary. Name conflicts arise when there is contention for names within the 
common -1 i sp- user package. 

To avoid name conflicts, simply create your new symbols in another package, one 
that is specific to your program. The easiest way to implement this is to split each 
system into at least two files - one to define the package that the system resides in, and 
the others for the system itself. For example, the emyci. system should start with a 
file that defines the emyci . package. The following form defines the emyci . package 
to use the 1 i sp package. That means that when the current package is emyci n, you 
can still refer to all the built-in Lisp symbols. 

(make-package "EMYCIN" :use '("LISP")) 

The file containing the package definition should always be loaded before the rest 
of the system. Those files should start with the following call, which insures that all 
new symbols will be interned in the emyci . package: 

(in-package "EMYCIN") 

Packages are used for information-hiding purposes as well as for avoiding name 
clashes. A distinction is made between internal and external symbols. External 
symbols are those that a user of a system would want to refer to, while internal 
symbols are those that help implement the system but are not needed by a user of the 
system. The symbol rul e would probably be internal to both the emyci. and parser 
package, but def rul e would be external, because a user of the emyci . system uses 
def rul e to define new rules. The designer of a system is responsible for advertising 
which symbols are external. The proper call is: 

(export '(emycin defrule defcontext defparm yes/no yes no is)) 

Now the user who wants to refer to symbols in the emyci. package has four choices. 
First, he or she can use the package prefix notation. To refer to the symbol def rul e 
in the emycin package, type emycin: def rule. Second, the user can make emycin 
be the current package with (in-package "EMYCIN"). Then, of course, we need 

^Or in the user package in non-ANSI systems. 


<a id='page-836'></a>

only type def rul e. Third, if we only need part of the functionahty of a system, we 
can import specific symbols into the current package. For example, we could call 
(i mport ' emyci .: def rul e). From then on, typing def rul e (in the current package) 
will refer to emyci .: def rul e. Fourth, if we want the full functionahty of the system, 
we call (use-package "EMYCIN"). This makes all the external symbols of the emyci . 
package accessible in the current package. 

While packages help eliminate name conflicts, import and use-package allow 
them to reappear. The advantage is that there will only be conflicts between external 
symbols. Since a carefully designed package should have far fewer external than 
internal symbols, the problem has at least been reduced. But if two packages both 
have an external def rul e symbol, then we cannot use- package both these packages, 
nor 1 mport both symbols without producing a genuine name conflict. Such conflicts 
can be resolved by shadowing one symbol or the other; see Common Lisp the Language 
for details. 

The careful reader may be confused by the distinction between "EMYCIN" and 
emycin. In Common Lisp the Language, it was not made clear what the argument 
to package functions must be. Thus, some implementations signal an error when 
given a symbol whose print name is a package. In ANSI Common Lisp, all package 
functions are specified to take either a package, a package name (a string), or a 
symbol whose print name is a package name. In addition, ANSI Common Lisp adds 
the convenient def package macro. It can be used as a replacement for separate calls 
to make-package, use-package, import, and export. Also note that ANSI renames 
the lisp package as common - lisp. 

(defpackage emycin 
(ruse common-lisp) 
(:export emycin defrule defcontext defparm yes/no yes no is)) 

For more on packages and building systems, see section 25.16 or Common Lisp the 
Language. 

The Seven Name Spaces 

One important fact to remember about packages is that they deal with symbols, and 
only indirectly deal with the uses those symbols might have. For example, you may 
think of (export 'parse) as exporting the function parse, but really it is exporting 
the symbol parse, which may happen to have a function definition associated with 
it. However, if the symbol is put to another use - perhaps as a variable or a data 
type - then those uses are made accessible by the export statement as well. 

Common Lisp has at least seven name spaces. The two we think of most often 
are (1) for functions and macros and (2) for variables. We have seen that Scheme 


<a id='page-837'></a>
conflates these two name spaces, but Common Lisp keeps them separate, so that in 
a function application like (f) the function/macro name space is consulted for the 
value of f, but in (+ f), f is treated as a variable name. Those who understand the 
scope and extent rules of Common Lisp know that (3) special variables form a distinct 
name space from lexical variables. So the f in (+ f) is treated as either a special or 
lexical variable, depending on if there is an applicable special declaration. There 
is also a name space (4) for data types. Even if f is defined as a function and/or a 
variable, it can also be defined as a data type with defstruct, deftype, or def cl ass. 
It can also be defined as (5) a label for go statements within a tagbody or (6) a block 
name for return-from statements within a bl ock. Finally, symbols inside a quoted 
expression are treated as constants, and thus form name space (7). These symbols 
are often used as keys in user-defined tables, and in a sense each such table defines 
a new name space. One example is the tag name space, used by catch and throw. 
Another is the package name space. 

It is a good idea to limit each symbol to only one name space. Common Lisp will 
not be confused if a symbol is used in multiple ways, but the poor human reader 
probably will be. 

In the following example f, can you identify which of the twelve uses off refer to 
which name spaces? 

(defun f (f) 
(block f 
(tagbody 
f (catch 'f 
(if (typep f 'f) 
(throw *f (go f))) 
(funcall #'f (get (symbol-value *f) 'f)))))) 

24.2 Conditions and Error Handling 
An extraordinary feature of ANSI Common Lisp is the facility for handling errors. 
In most languages it is very difficult for the programmer to arrange to recover from 
an error. Although Ada and some implementations of C provide functions for error 
recovery, they are not generally part of the repertoire of most programmers. Thus, 
we find C programs that exit with the ungraceful message Segmentati on violation: 
core dumped. 

Common Lisp provides one of the most comprehensive and easy-to-use error-
handling mechanism of any programming language, which leads to more robust 
programs. The process of error handling is divided into two parts: signaling an error, 
and handling it. 


<a id='page-838'></a>

Signaling Errors 

Anenor is a condition that the program does not know how to handle. Since the 
program does not know what to do, its only recourse is to announce the occurrence of 
the error, with the hope that some other program or user will know what to do. This 
announcement is called signaling an error. An error can be signaled by a Common 
Lisp built-in function, as when (/ 3 0) signals a divide-by-zero error. Errors can also 
be signaled explicitly by the programmer, as in a call to (error "111 egal val ue."). 

Actually, it is a bit of a simplification to talk only of signaling errors. The precise 
term is signaling a condition. Some conditions, like end-of-file, are not considered 
errors, but nevertheless they are unusual conditions that must be dealt with. The 
condition system in Conunon Lisp allows for the definition of all kinds of conditions, 
but we will continue to talk about errors in this brief discussion, since most conditions 
are in fact error conditions. 

Handling Errors 

By default, signaling an error invokes the debugger. In the following example, the > 
prompt means that the user is in the debugger rather than at the top level. 

> (/ 3 0) 
Error: An attempt was made to divide by zero. 
> 

ANSI Common Lisp provides ways of changing this default behavior. Conceptually, 
this is done by setting up an error handler which handles the error in some way. Error 
handlers are bound dynamically and are used to process signaled errors. An error 
handler is much like a catch, and signaling an error is like a throw. In fact, in many 
systems catch and throw are implemented with the error-condition system. 

Thesimplestwayof handling an error is with the macro i gnore-errors. If noerror 
occurs, i gnore-errors is just like progn. But if an error does occur, i gnore-errors 
will retiu-n nil as its first value and t as its second, to indicate that an error has 
occurred but without doing anything else: 

> (ignore-errors (/ 3 D) 3 NIL 

> (ignore-errors (/ 3 0)) ^ NIL . 

i gnore-errors isavery coarse-grain tool. Inaninteractiveinterpreter, i gnore-errors 
can be used to recover from any and all errors in the response to one input and get 
back to the read-process-print loop for the next input. If the errors that are ignored 
are not serious ones, this can be a very effective way of transforming a buggy program 
into a useful one. 


<a id='page-839'></a>
But some errors are too important to ignore. If the error is rurming out of memory, 
then ignoring it will not help. Instead, we need to find some way of freeing up memory 
and continuing. 

The condition-handling system can be used to handle only certain errors. The 
macro handl er-case, is a convenient way to do this. Like case, its first argument is 
evaluated and used to determine what to do next. If no error is signaled, then the 
value of the expression is returned. But if an error does occtu:, the following clauses 
are searched for one that matches the type of the error. In the following example, 
handl er - case is used to handle division by zero and other arithmetic errors (perhaps 
floating-point underflow), but it allows all other errors to pass unhandled. 

(defun div (x y) 

(handler-case (/ . y) 
(division-by-zero () most-positive-fixnum) 
(arithmetic-error () 0))) 

> (div 8 2) 4 

> (div 3 0)=^ 16777215 

> (div 'xyzzy 1) 
Error: The value of NUMBER, XYZZY, should be a number 

Through judicious use of handl er - case, the programmer can create robust code that 
reacts well to unexpected situations. For more details, see chapter 29 of Common Lisp 
the Language, 2d edition. 

24.3 Pretty Printing 
ANSI Common Lisp adds a facility for user-controlled pretty printing. In general, 
pretty printing refers to the process of printing complex expressions in a format that 
uses indentation to improve readability. The function ppr 1 nt was always available, 
but before ANSI Common Lisp it was left unspecified, and it could not be extended 
by the user. Chapter 27 of Common Lisp the Language, 2d edition presents a pretty-
printing facility that gives the user fine-grained control over the printing of all types 
of objects. In addition, the facility is integrated with the format function. 

24.4 Series 
The functional style of programming with higher-order functions is one of the at


tractions of Lisp. The following expression to sum the square roots of the positive 
numbers in the list nums is clear and concise: 


<a id='page-840'></a>

(reduce #*+ (mapcar #'sqrt (find-all-if #*plusp nums))) 

Unfortunately, it is inefficient: both f i nd - a 11 -i f and ma pea r cons up intermediate 
Hsts that are not needed in the final sum. The following two versions using 1 oop and 
dol i st are efficient but not as pretty: 

;; Using Loop ;; Using dolist 

(loop for num in nums (let ((sum 0)) 

when (plusp num) (dolist (num nums sum) 

sum (sqrt num)) (when (plusp num) 

(incf sum num)))) 

A compromise between the two approaches is provided by the series faciUty, defined 
in appendix A ofCommon Lisp the Language, 2d edition. The example using series 
would look like: 

(collect-sum (#Msqrt (choose-if #'plusp nums))) 

This looks very much like the functional version: only the names have been changed. 
However, it compiles into efficient iterative code very much like the dol i st version. 

Like pipes (see section 9.3), elements of a series are only evaluated when they 
are needed. So we can write (scan - range : from 0) to indicate the infinite series of 
integers starting from 0, but if we only use, say, the first five elements of this series, 
then only the first five elements will be generated. 

The series facility offers a convenient and efficient alternative to iterative loops 
and sequence functions. Although the series proposal has not yet been adopted as an 
official part of ANSI Common Lisp, its inclusion in the reference manual has made 
it increasingly popular. 

24.5 The Loop Macro 
The original specification of Common Lisp included a simple 1 oop macro. The body 
of the loop was executed repeatedly, until a return was encountered. ANSI Common 
Lisp officially introduces a far more complex 1 oop macro, one that had been used in 
ZetaLisp and its predecessors for some time. This book has occasionally used the 
complex 1 oop in place of alternatives such as do, dotimes, dol i st, and the mapping 
functions. 

If your Lisp does not include the complex 1 oop macro, this chapter gives a definition 
that will run all the examples in this book, although it does not support all the 
features of 1 oop. This chapter also serves as an example of a complex macro. As with 


<a id='page-841'></a>
any macro, the first thing to do is to look at some macro calls and what they might 
expand into. Here are two examples: 

(loop for i from 1 to . do (print (sqrt i))) . 
(LET* ((I 1) 
(TEMP N)) 
(TAGBODY 
LOOP 
(IF (> I TEMP) 

(GO END)) 
(PRINT (SQRT I)) 
(SETF I (+ I D) 
(GO LOOP) 

END)) 

(loop for V in list do (print v)) = 
(LET* ((IN LIST) 
(V (CAR IN))) 
(TAGBODY 
LOOP 
(IF (NULL IN) 

(GO END)) 
(PRINT V) 
(SETF IN (CDR IN)) 
(SETF V (CAR IN)) 
(GO LOOP) 

END)) 

Each loop initializes some variables, then enters a loop with some exit tests and a 
body. So the template is something like: 

(let* (variables...) 
(tagbody 
loop 
(if exit-tests 
(go end)) 

body 

(go loop) 
end)) 

Actually, there's more we might need in the general case. There may be a prologue 
that appears before the loop but after the variable initialization, and similarly there 
may be an epilogue after the loop. This epilogue may involve returning a value, and 
since we want to be able to return from the loop in any case, we need to wrap a bl ock 
around it. So the complete template is: 


<a id='page-842'></a>

(let* (variables.,.) 
(block name 
prologue 

(tagbody 
loop 

body 

(go loop) 
end 

epilogue 

(return result)))) 

To generate this template from the body of a 1 oop form, we will employ a structure 
with fields for each of the parts of the template: 

(defstruct loop 
"A structure to hold parts of a loop as it is built." 
(vars nil) (prologue nil) (body nil) (steps nil) 
(epilogue nil) (result nil) (name nil)) 

Now the 1 oop macro needs to do four things: (1) decide if this is a use of the simple, 
non-keyword 1 oop or the complex ANSI 1 oop. If it is the latter, then (2) make an 
instance of the 1 oop structure, (3) process the body of the loop, filling in apprpriate 
fields of the structure, and (4) place the filled fields into the template. Here is the 
1 oop macro: 

(defmacro loop (&rest exps) 
"Supports both ANSI and simple LOOP. 
Warning: Not every loop keyword is supported." 
(if (every #'listp exps) 

No keywords implies simple loop: 
'(block nil (tagbody loop ,@exps (go loop))) 
;; otherwise process loop keywords: 
(let ((1 (make-loop))) 

(parse-loop-body 1 exps) 

(fill-loop-template 1)))) 

(defun fill-loop-tempi ate (1) 
"Use a loop-structure instance to fill the template." 
'(let* .(nreverse (loop-vars 1)) 

(block ,(loop-name 1) 
.(nreverse (loop-prologue 1)) 
(tagbody 

loop 
.(nreverse (loop-body 1)) 
.(nreverse (loop-steps D) 
(go loop) 


<a id='page-843'></a>

end 
,(nreverse (loop-epilogue D) 
(return ,(loop-result 1)))))) 

Most of the work is in writing parse-1 oop-body, which takes a Ust of expressions 
and parses them into the proper fields of a loop structure. It will use the following 
auxiliary functions: 

(defun add-body (1 exp) (push exp (loop-body 1))) 

(defun add-test (1 test) 
"Put in a test for loop termination." 
(push *(if .test (go end)) (loop-body 1))) 

(defun add-var (1 var init &optional (update nil update?)) 
"Add a variable, maybe including an update step." 
(unless (assoc var (loop-vars 1)) 

(push (list var init) (loop-vars 1))) 
(when update? 
(push '(setq .var .update) (loop-steps 1)))) 

There are a number of alternative ways of implementing this kind of processing. One 
would be to use special variables: *prol ogue*, *body*, *epi 1 ogue*, and so on. This 
would mean we wouldn't have to pass around the loop structure 1, but there would 
be significant clutter in having seven new special variables. Another possibility is to 
use local variables and close the definitions of 1 oop, along with the add- functions in 
that local environment: 

(let (body prologue epilogue steps vars name result) 
(defmacro loop ...) 
(defun add-body ...) 
(defun add-test ...) 
(defun add-var ...)) 

This is somewhat cleaner style, but some early Common Lisp compilers do not 
support embedded def uns, so I chose to write in a style that I knew would work in 
all implementations. Another design choice would be to return multiple values for 
each of the components and have parse-loop-body put them all together. This is in 
fact done in one of the Lisp Machine implementations of 1 oop, but I think it is a poor 
decision: seven components are too many to keep track of by positional notation. 

Anatomy of a Loop 

All this has just been to set up for the real work: parsing the expressions that make 
up the loop with the function pa rse -1 oop- body. Every loop consists of a sequence of 


<a id='page-844'></a>

