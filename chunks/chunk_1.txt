## Frontmatter
Paradigms of 
Artificial Intelligence 
Programming: 

CASE STUDIES IN COMMON LISP 

Peter Norvig 

MORGAN KAUFMANN PUBLISHERS ^ SAN FRANCISCO, CALIFORNIA 


Sponsoring Editor Michael B. Morgan 
Production Manager Yonie Overton 
Cover Designer Sandra Popovich 
Text Design/Composition SuperScnpt Typography 
Copyeditor Barbara Beidler Kendnck 
Proofreaders Lynn Meinhardt, Shanlyn Hovind, Gary Morus 
Printer Malloy Lithographing 

Morgan Kaufmann Publishers, Inc. 

Editorial and Sales Office: 

340 Pine Street, Sbcth Floor 
San Francisco, CA 94104-3205 
USA 
Telephone 415/392-2665 
Facsimile 415/982-2665 
Internet mkp@mkp.com 
Web site http://mkp.com 

© 1992 Morgan Kaufmann Publishers, Inc. 
All rights reserved 

Printed in the United States of America 

03 02 Ol 8 7 6 
No part of this publication may be reproduced, stored in a retrieval system, or 
transmitted in any form or by any means-electronic, photocopying, recording, or 
otherwise—without the prior written permission of the publisher. 

Library of Congress Cataloging-in-Publication Data 

Norvig, Peter. 
Paradigms of artificial inteUigence programming: case studies in 
common Lisp / Peter Norvig. 

p. cm. 
Includes bibliographical references and index. 
ISBN 1-55860-191-0: 
1. Electronic digital computers-Programming. 2. COMMON LISP 
(Computer program language) 3. Artificial intelligence. I. Title. 
QA76.6.N6871991 
006.3-dc20 91-39187 
CIP 


To my family,.. 


## Preface
<a id='page-vii'></a>

> **paradigm** *n* **1** an example or pattern; *esp* an outstandingly clear or typical example. 
>
> -*Longman's Dictionary of the English Language*, 1984 

This book is concerned with three related topics: the field of artificial intelligence, or AI; the skill 
of computer programming; and the programming language Common Lisp. Careful readers of 
this book can expect to come away with an appreciation of the major questions and techniques 
of AI, an understanding of some important AI programs, and an ability to read, modify, and 
create programs using Common Lisp. The examples in this book are designed to be clear 
examples of good programming style—paradigms of programming. They are also paradigms 
of AI research—historically significant programs that use widely applicable techniques to solve 
important problems. 

Just as a liberal arts education includes a course in "the great books" of a culture, so this book 
is, at one level, a course in "the great programs" that define the AI culture.[TK fn1] 

At another level, this book is a highly technical compendium of the knowledge you will need 
to progress from being an intermediate Lisp programmer to being an expert. Parts I and II are 
designed to help the novice get up to speed, but the complete beginner may have a hard time 
even with this material. Fortunately, there are at least five good texts available for the beginner; 
see [page xiii](preface#page-xiii) for my recommendations. 

[TK fn1] This does not imply that the programs chosen are the best of all AI programs—just that 
they are representative. 


<a id='page-viii'></a>

All too often, the teaching of computer programming consists of explaining the 
syntax of the chosen language, showing the student a 10-line program, and then 
asking the student to write programs. In this book, we take the approach that the 
best way to learn to write is to read (and conversely, a good way to improve reading 
skills is to write). After the briefest of introductions to Lisp, we start right off with 
complex programs and ask the reader to understand and make small modifications 
to these programs. 

The premise of this book is that you can only write something useful and interesting 
when you both understand what makes good writing and have something 
interesting to say. This holds for writing programs as well as for writing prose. As 
Kernighan and Plauger put it on the cover of *Software Tools in Pascal*: 

> Good programming is not learned from generalities, but by seeing how significant 
programs can be made clean, easy to read, easy to maintain and modify, 
human-engineered, efficient, and reliable, by the application of common sense 
and good programming practices. Careful study and imitation of good programs 
leads to better writing. 

The proud craftsman is often tempted to display only the finished work, without 
any indication of the false starts and mistakes that are an unfortunate but unavoidable 
part of the creative process. Unfortunately, this reluctance to unveil the process is 
a barrier to learning; a student of mathematics who sees a beautiful 10-line proof in 
a textbook can marvel at its conciseness but does not learn how to construct such a 
proof. This book attempts to show the complete programming process, "warts and 
all." Each chapter starts with a simple version of a program, one that works on some 
examples but fails on others. Each chapter shows how these failures can be analyzed 
to build increasingly sophisticated versions of the basic program. Thus, the reader 
can not only appreciate the final result but also see how to learn from mistakes and 
refine an initially incomplete design. Furthermore, the reader who finds a particular 
chapter is becoming too difficult can skip to the next chapter, having gained some 
appreciation of the problem area, and without being overwhelmed by the details. 

This book presents a body of knowledge loosely known as "AI programming 
techniques," but it must be recognized that there are no clear-cut boundaries on this 
body of knowledge. To be sure, no one can be a good AI programmer without first 
being a good programmer. Thus, this book presents topics (especially in parts III 
and V) that are not AI per se, but are essential background for any AI practitioner. 

### Why Lisp? Why Common Lisp? 

Lisp is one of the oldest programming languages still in widespread use today. There 
have been many versions of Lisp, each sharing basic features but differing in detail. 
In this book we use the version called Common Lisp, which is the most widely 
accepted standard. Lisp has been chosen for three reasons. 


<a id='page-ix'></a>

First, Lisp is the most popular language for AI programming, particularly in the 
United States. If you're going to learn a language, it might as well be one with a 
growing literature, rather than a dead tongue. 

Second, Lisp makes it easy to capture relevant generalizations in defining new 
objects. In particular. Lisp makes it easy to define new languages especially targeted 
to the problem at hand. This is especially handy in AI applications, which often 
manipulate complex information that is most easily represented in some novel form. 
Lisp is one of the few languages that allows full flexibility in defining and manipulating 
programs as well as data. All programming languages, by definition, provide 
a means of defining programs, but many other languages limit the ways in which a 
program can be used, or limit the range of programs that can be defined, or require 
the programmer to explicitly state irrelevant details. 

Third, Lisp makes it very easy to develop a working program fast. Lisp programs 
are concise and are uncluttered by low-level detail. Common Lisp offers an unusually 
large number of useful predefined objects, including over 700 functions. The programming 
environment (such as debugging tools, incremental compilers, integrated 
editors, and interfaces to window systems) that surround Lisp systems are usually 
very good. And the dynamic, interactive nature of Lisp makes it easy to experiment 
and change a program while it is being developed. 

It must be mentioned that in Europe and Japan, Prolog has been as popular as 
Lisp for AI work. Prolog shares most of Lisp's advantages in terms of flexibility and 
conciseness. Recently, Lisp has gained popularity worldwide, and Prolog is becoming 
more well known in the United States. As a result, the average AI worker today is 
likely to be bilingual. This book presents the key ideas behind Prolog in chapters 11 
and 12, and uses these ideas in subsequent chapters, particularly 20 and 21. 

The dialect of Lisp known as Scheme is also gaining in popularity, but primarily 
for teaching and experimenting with programming language design and techniques, 
and not so much for writing large AI programs. Scheme is presented in chapters 22 
and 23. Other dialects of Lisp such as Franz Lisp, MacLisp, InterLisp, ZetaLisp, 
and Standard Lisp are now considered obsolete. The only new dialect of Lisp to be 
proposed recently is EuLisp, the European Lisp. A few dialects of Lisp live on as 
embedded extension languages. For example, the Gnu Emacs text editor uses elisp, 
and the AutoCad computer-aided design package uses AutoLisp, a derivative of Xlisp. 
In the future, it is likely that Scheme will become a popular extension language, since 
it is small but powerful and has an officially sanctioned standard definition. 

There is a myth that Lisp (and Prolog) are "special-purpose" languages, while 
languages like Pascal and C are "general purpose." Actually, just the reverse is 
true. Pascal and C are special-purpose languages for manipulating the registers and 
memory of a von Neumann-style computer. The majority of their syntax is devoted 
to arithmetic and Boolean expressions, and while they provide some facilities for 
forming data structures, they have poor mechanisms for procedural abstraction 
or control abstraction. In addition, they are designed for the state-oriented style 

<a id='page-x'></a>
of programming: computing a result by changing the value of variables through 
assignment statements. 

Lisp, on the other hand, has no special syntax for arithmetic. Addition and 
multiplication are no more or less basic than list operations like appending, or string 
operations like converting to upper case. But Lisp provides all you will need for 
programming in general: defining data structures, functions, and the means for 
combining them. 

The assignment-dominated, state-oriented style of programming is possible in 
Lisp, but in addition object-oriented, rule-based, and functional styles are all supported 
within Lisp. This flexibility derives from two key features of Lisp: First, Lisp 
has a powerful *macro* facility, which can be used to extend the basic language. When 
new styles of programming were invented, other languages died out; Lisp simply 
incorporated the new styles by defining some new macros. The macro facility is 
possible because Lisp programs are composed of a simple data structure: the list. 
In the early days, when Lisp was interpreted, most manipulation of programs was 
done through this data structure. Nowadays, Lisp is more often compiled than interpreted, 
and programmers rely more on Lisp's second great flexible feature: the 
*function*. Of course, other languages have functions, but Lisp is rare in allowing the 
creation of new functions while a program is running. 

Lisp's flexibility allows it to adapt as programming styles change, but more importantly. 
Lisp can adapt to your particular programming problem. In other languages 
you fit your problem to the language; with Lisp you extend the language to fit your 
problem. 

Because of its flexibility. Lisp has been succesful as a high-level language for rapid 
prototyping in areas such as AI, graphics, and user interfaces. Lisp has also been 
the dominant language for exploratory programming, where the problems are so 
complex that no clear solution is available at the start of the project. Much of AI falls 
under this heading. 

The size of Common Lisp can be either an advantage or a disadvantage, depending 
on your outlook. In David Touretzky's (1989) fine book for beginning programmers, 
the emphasis is on simplicity. He chooses to write some programs slightly less 
concisely, rather than introduce an esoteric new feature (he cites `pushnew` as an 
example). That approach is entirely appropriate for beginners, but this book goes 
well past the level of beginner. This means exposing the reader to new features of 
the language whenever they are appropriate. Most of the time, new features are 
described as they are introduced, but sometimes explaining the details of a low-
level function would detract from the explanation of the workings of a program. 
In accepting the privilege of being treated as an "adult," the reader also accepts a 
responsibility—to look up unfamiliar terms in an appropriate reference source. 


<a id='page-xi'></a>

### Outline of the Book 

This book is organized into five parts. 

**Part I** introduces the Common Lisp programming language. 

Chapter 1 gives a quick introduction by way of small examples that demonstrate 
the novel features of Lisp. It can be safely skipped or skimmed by the experienced 
programmer. 

Chapter 2 is a more extended example showing how the Lisp primitives can be 
put together to form a program. It should be studied carefully by the novice, and 
even the experienced programmer will want to look through it to get a feel for my 
programming style. 

Chapter 3 provides an overview of the Lisp primitives. It can be skimmed on first 
reading and used as a reference whenever an unfamiliar function is mentioned in 
the text. 

Part I has been kept intentionally brief, so that there is more room for presenting 
actual AI programs. Unfortunately, that means that another text or reference book 
(or online help) may be needed to clarify some of the more esoteric features of the 
language. My recommendations for texts are on [page xiii](preface#page-xiii). 

The reader may also want to refer to chapter 25, which offers some debugging 
and troubleshooting hints. 

**Part II** covers four early AI programs that all use rule-based pattern-matching 
techniques. By starting with relatively simple versions of the programs and then 
improving them and moving on to more complex programs, the reader is able to 
gradually acquire increasingly advanced programming skills. 

Chapter 4 presents a reconstruction of GPS, the General Problem Solver. The 
implementation follows the STRIPS approach. 

Chapter 5 describes ELIZA, a program that mimics human dialogue. This is 
followed by a chapter that generalizes some of the techniques used in GPS and ELIZA 
and makes them available as tools for use in subsequent programs. 

Chapter 7 covers STUDENT, a program that solves high-school-level algebra word 
problems. 

Chapter 8 develops a small subset of the MACSYMA program for doing symbolic 
algebra, including differential and integral calculus. It may be skipped by those who 
shy away from heavy mathematics. 

**Part III** detours from AI for a moment to present some general tools for more 
efficient programming. The reader who masters the material in this part can be 
considered an advanced Lisp programmer. 

Chapter 9 is a detailed study of efficiency techniques, concentrating on caching, 
indexing, compilation, and delaying computation. Chapter 10 covers lower-level efficiency 
issues such as using declarations, avoiding garbage generation, and choosing 
the right data structure. 


<a id='page-xii'></a>

Chapter 11 presents the Prolog language. The aim is two-fold: to show how to 
write an interpreter for another language, and to introduce the important features 
of Prolog, so that they can be used where appropriate. Chapter 12 shows how a 
compiler for Prolog can be 20 to 200 times faster than the interpreter. 

Chapter 13 introduces object-oriented programming in general, then explores the 
Common Lisp Object System (CLOS). 

Chapter 14 discusses the advantages and limitations of both logic-oriented and 
object-oriented programming, and develops a knowledge representation formalism 
using all the techniques of part III. 

**Part IV** covers some advanced AI programs. 

Chapter 15 uses the techniques of part III to come up with a much more efficient 
implementation of MACSYMA. It uses the idea of a canonical form, and replaces the 
very general rewrite rule approach with a series of more specific functions. 

Chapter 16 covers the EMYCIN expert system shell, a backward chaining rule-based 
system based on certainty factors. The MYCIN medical expert system is also 
covered briefly. 

Chapter 17 covers the Waltz line-labeling algorithm for polyhedra (using Huffman-Clowes 
labels). Different approaches to constraint propagation and backtracking 
are discussed. 

Chapter 18 presents a program that plays an excellent game of Othello. The 
technique used, alpha-beta searching, is appropriate to a wide variety of two-person 
games. 

Chapter 19 is an introduction to natural language processing. It covers context-free 
grammar, top-down and bottom-up parsing, chart parsing, and some semantic 
interpretation and preferences. 

Chapter 20 extends the linguistic coverage of the previous chapter and introduces 
logic grammars, using the Prolog compiler developed in chapter 11. 

Chapter 21 is a fairly comprehensive grammar of English using the logic grammar 
formalism. The problems of going from a simple idea to a realistic, comprehensive 
program are discussed. 

**Part V** includes material that is peripheral to AI but important for any serious 
Lisp programmer. 

Chapter 22 presents the Scheme dialect of Lisp. A simple Scheme interpreter is 
developed, then a properly tail-recursive interpreter, then an interpreter that explicitly 
manipulates continuations and supports `call/cc`. Chapter 23 presents a Scheme 
compiler. 

Chapter 24 presents the features that are unique to American National Standards 
Institute (ANSI) Common Lisp. This includes the `loop` macro, as well as error 
handling, pretty printing, series and sequences, and the package facility. 

Chapter 25 is a guide to troubleshooting and debugging Lisp programs. 


<a id='page-xiii'></a>

The bibliography lists over 200 sources, and there is a comprehensive index. In 
addition, the appendix provides a directory of publicly available Lisp programs. 

### How to Use This Book 

The intended audience for this book is broad: anyone who wants to become an advanced 
Lisp programmer, and anyone who wants to be an advanced AI practitioner. 
There are several recommended paths through the book: 

* *In an Introductory AI Course:* Concentrate on parts I and II, and at least one 
example from part IV. 
* *In an Advanced AI Programming Course:* Concentrate on parts I, II and IV, skipping 
chapters that are of less interest and adding as much of part III as time permits. 
* *In an Advanced Programming Languages Course:* Concentrate on parts I and V, 
with selections from part III. Cover chapters 11 and 13 if similar material is not 
presented with another text. 
* *For the Professional Lisp Programmer:* Read as much of the book as possible, and 
refer back to it often. Part III and chapter 25 are particularly important. 

### Supplementary Texts and Reference Books 

The definitive reference source is Steele's *Common Lisp the Language.* From 1984 
to 1990, this unambiguously defined the language Common Lisp. However, in 
1990 the picture became more complicated by the publication of *Common Lisp the 
Language,* 2d edition. This book, also by Steele, contains the recommendations of 
ANSI subcommittee X3J13, whose charter is to define a standard for Lisp. These 
recommendations include many minor changes and clarifications, as well as brand 
new material on object-oriented programming, error condition handling, and the 
loop macro. The new material doubles the size of the book from 465 to 1029 pages. 

Until the ANSI recommendations are formally accepted, Common Lisp users 
are in the unfortunate situation of having two distinct and incompatible standards: 
"original" Common Lisp and ANSI Common Lisp. Most of the code in this book is 
compliant with both standards. The most significant use of an ANSI function is the 
`loop` macro. The ANSI `map-into`, `complement`, and `reduce` functions are also used, 
although rarely. Definitions for all these functions are included, so even those using 
an "original" Common Lisp system can still run all the code in the book. 

While *Common Lisp the Language* is the definitive standard, it is sometimes terse 
and can be difficult for a beginner. *Common Lisp: the Reference,* published by Franz 
Inc., offers complete coverage of the language with many helpful examples. *Common 
LISPcraft,* by Robert Wilensky, and *Artificial Intelligence Programming,* by Charniak 

<a id='page-xiv'></a>
et al., also include brief summaries of the Common Lisp functions. They are not 
as comprehensive, but that can be a blessing, because it can lead the reader more 
directly to the functions that are important (at least in the eyes of the author). 

It is a good idea to read this book with a computer at hand, to try out the examples 
and experiment with examples of your own. A computer is also handy because Lisp 
is self-documenting, through the functions `apropos`, `describe`, and `documentation`. 
Many implementations also provide more extensive documentation through some 
kind of 'help' command or menu. 

The five introductory Lisp textbooks I recommend are listed below. The first is 
more elementary than the others. 

* *Common Lisp: A Gentle Introduction to Symbolic Computation* by David Touretzky. 
Most appropriate for beginners, including those who are not computer 
scientists. 

* *A Programmer's Guide to Common Lisp* by Deborah G. Tatar. Appropriate for 
those with experience in another programming language, but none in Lisp. 

* *Common LISPcraft* by Robert Wilensky. More comprehensive and faster paced, 
but still useful as an introduction as well as a reference. 

* *Common Lisp* by Wade L. Hennessey. Somewhat hit-and-miss in terms of the 
topics it covers, but with an enlightened discussion of implementation and 
efficiency issues that do not appear in the other texts. 

* *LISP* (3d edition) by Patrick H. Winston and Bertold Horn. Covers the most 
ground in terms of programming advice, but not as comprehensive as a reference. 
May be difficult for beginners. Includes some AI examples. 

While it may be distracting for the beginner to be continually looking at some 
reference source, the alternative—to have this book explain every new function in 
complete detail as it is introduced—would be even more distracting. It would interrupt 
the description of the AI programs, which is what this book is all about. 

There are a few texts that show how to write AI programs and tools, but none 
that go into the depth of this book. Nevertheless, the expert AI programmer will 
want to be familiar with all the following texts, listed in rough order of increasing 
sophistication: 

* *LISP* (3d edition). (See above.) 

* *Programming Paradigms in Lisp* by Rajeev Sangal. Presents the different styles 
of programming that Lisp accommodates, illustrating them with some useful 
AI tools. 


<a id='page-xv'></a>

* *Programming for Artificial Intelligence* by Wolfgang Kreutzer and Bruce McKenzie. 
Covers some of the basics of rule-based and pattern-matching systems well, 
but covers Lisp, Prolog, and Smalltalk, and thus has no time left for details in 
any of the languages. 

* *Artificial Intelligence Programming* (2d edition) by Eugene Charniak, Christopher 
Riesbeck, Drew McDermott, and James Meehan. Contains 150 pages of 
Lisp overview, followed by an advanced discussion of AI tools, but no actual 
AI programs. 

* *AI in Practice: Examples in Pop-11* by Allan Ramsey and Rosalind Barrett. Advanced, 
high-quality implementations of five AI programs, unfortunately using 
a language that has not gained popularity. 

The current text combines the virtues of the last two entries: it presents both actual 
AI programs and the tools necessary to build them. Furthermore, the presentation is 
in an incremental fashion, with simple versions presented first for clarity, followed 
by more sophisticated versions for completeness. 

### A Note on Exercises 

Sample exercises are provided throughout. Readers can test their level of understanding 
by faithfully doing the exercises. The exercises are graded on the scale [s], 
[m], [h], [d], which can be interpreted either as a level of difficulty or as an expected 
time it will take to do the exercise: 

| Code | Difficulty | Time to Do  |
|------|------------|-------------|
| [s]  | Simple     | Seconds     |
| [m]  | Medium     | Minutes     |
| [h]  | Hard       | Hours       |
| [d]  | Difficult  | Days        |

The time to do the exercise is measured from the point that the concepts have 
been well understood. If the reader is unclear on the underlying concepts, it might 
take hours of review to understand a [m] problem. Answers to the exercises can be 
found in a separate section at the end of each chapter. 

### Acknowledgments 

A great many people contributed to this book. First of all I would like to thank my 
students at USC and Berkeley, as well as James Martin's students at Colorado and 
Michael Pazzani's students at Irvine, who course-tested earlier versions of this book. 
Useful suggestions, corrections, and additions were made by: 


<a id='page-xvi'></a>

Nina Amenta (Berkeley), Ray S. Babcock and John Paxton (Montana State), 
Bryan A. Bentz (BBN), Mary P. Boelk (Johnson Controls), Michael Braverman (Berkeley), 
R. Chandrasekar and M. Sasikumar (National Centre for Software Technology, 
Bombay), Mike Clancy (Berkeley), Michael Covington (Georgia), Bruce D'Ambrosio 
(Oregon State), Piew Datta (Irvine), Shawn Dettrey (USC), J. A. Durieux (AI Engineering 
BV, Amsterdam), Joseph Faletti (ETS), Paul Fuqua (Texas Instruments), 
Robert Goldman (Tulane), Marty Hall (Johns Hopkins), Marti Hearst (Berkeley), Jim 
Hendler (Maryland), Phil Laird (NASA), Raymond Lang (Tulane), David D. Loeffler 
(MCC), George Luger (New Mexico), Rob MacLachlan (CMU), Barry Margolin 
(Thinking Machines), James Mayfield (UMBC), Sanjay Manchandi (Arizona), Robert 
McCartney (Connecticut), James Meehan (DEC), Andrew L. Ressler, Robert S. Rist 
(University of Technology, Sydney), Paul Snively (Apple), Peter Van Roy (Berkeley), 
David Gumby Wallace (Cygnus), and Jeff Wu (Colorado). 

Sam Dooley and Eric Wefald both wrote Othello-playing programs without which 
I would not have written chapter 18. Eric also showed me Aristotle's quotes on means-ends 
analysis. Tragically, Eric died in August 1989. He is sorely missed by his friends 
and colleagues. Richard Fateman made suggestions for chapter 8, convinced me to 
write chapter 15, and, with help from Peter Klier, wrote a substantial program from 
which I adapted some code for that chapter. Charley Cox (Franz Inc.), Jamie Zawinski 
(Lucid Inc.), and Paul Fuqua (Texas Instruments) explained the inner workings of 
their respective companies' compilers. Mike Harrison, Paul Hilfinger, Marc Luria, 
Ethan Munson, and Stephan Slade helped with LATEX. Narciso Jarimillo tested all the 
code and separated it into the files that are available to the reader (see [page 897](appendix.md#page-897)). 

During the writing of this book I was supported by a grant from the Defense 
Advanced Research Projects Agency (DoD), Arpa Order No. 4871, monitored by 
Space and Naval Warfare Systems Command under Contract N00039-84-C-0089. 
Special thanks to DARPA and to Robert Wilensky and the rest of my colleagues and 
students at Berkeley for providing a stimulating environment for research, programming, 
and writing. 

Finally, thanks to Mike Morgan and Yonie Overton for overseeing the production 
of the book and encouraging me to finish on time. 


## Chapter 1
<a id='page-3'></a>

Introduction to Lisp 

You think you know when you learn, are more sure 
when you can write, even more when you can teach, 
hut certain when you can program. 

—Alan Perils 
Yale University computer scientist 

.1 his chapter is for people with little or no experience in Lisp. Readers who feel confident 
in their Lisp programming ability can quickly skim the chapter or skip it entirely. This 
chapter necessarily moves quickly, so those with little programming experience, or any 
reader who finds this chapter tough going, should seek out a supplementary introductory text. 
My recommendations are in the preface. 
Computers allow one to carry out computations. A word processing program deals with 
words while a calculator deals with numbers, but the principles are the same. In both cases, 
you provide the input (words or numbers) and specify the operations (such as deleting a word 
or adding two numbers) to yield a result (a completed document or calculation). 
We will refer to anything that can be represented in the memory of a computer as a computational 
object, or just an object. So, words, paragraphs, and numbers can be objects. And because 
the operations (deleting and adding) must be represented somewhere in the computer's memory, 
they are objects, too. 


<a id='page-4'></a>

Normally, the distinction between a computer "user" and a computer "programmer" 
is that the user provides new input, or data (words or numbers), while the 
programmer defines new operations, or programs, as well as new types of data. Every 
new object, be it datum or operation, must be defined in terms of previously defined 
objects. The bad news is that it can be quite tedious to get these definitions right. 
The good news is that each new object can in turn be used in the definition of future 
objects. Thus, even complex programs can be built out of smaller, simpler objects. 
This book covers a number of typical AI problems, showing how each problem can 
be broken down into manageable pieces, and also how each piece can be described in 
the programming language Common Lisp. Ideally, readers will learn enough through 
studying these examples to attack new AI problems with style, grace, and success. 

Let's consider a simple example of a computation: finding the sum of two numbers, 
let's say 2 and 2. If we had a calculator handy, we would type "2 -f 2 =" and see 
the answer displayed. On a calculator using reverse Polish notation, we would have 
to type" 22+ " to see the same answer. In Lisp, as with the calculator, the user carries 
out an interactive dialog with the computer by typing in an expression and seeing the 
computer print the value of that expression. This interactive mode is different from 
many other programming languages that only offer a batch mode, wherein an entire 
program is compiled and run before any output can be seen. 

We start up a pocket calculator by flipping the on/off switch. The Lisp program 
must also be started, but the details vary from one computer to another, so I can't 
explain how your Lisp will work. Assuming we have managed to start up Lisp, we 
are likely to see a prompt of some kind. On my computer. Lisp types " > " to indicate 
it is ready to accept the next computation. So we are faced with a screen that looks 
like this: 

We may now type in our computation and see the result displayed. It turns out that 
the Lisp convention for arithemtic expressions is slightly different: a computation 
consists of a parenthesized list with the operation name first, followed by any number 
of operands, or arguments. This is called prefix notation. 

> (+ 2 2) 

> 

We see that Lisp has printed the answer, 4, and then another prompt, >, to indicate 
it is ready for the next computation. Throughout this book, all Lisp expressions will 
be displayed in typewriter font. Text on the same line as the ">" prompt is input 
typed by the user, and text following it is output printed by the computer. Usually, 
input that is typed by the programmer will be in 1 owercase letters, while output that 


<a id='page-5'></a>

is printed back by the computer will be in UPPERCASE letters. Of course, with symbols 
like + and 4 there is no difference. 

To save space on the page, the output will sometimes be shown on the same line 
as the input, separated by an arrow which can be read as "evaluates to," and 
can also be thought of as standing for the return or enter key that the user presses to 
complete the input: 

> (+ 2 2) ^ 4 

One advantage of parenthesized prefix notation is that the parentheses clearly mark 
the beginning and end of an expression. If we want, we can give + more than two 
arguments, and it will still add them all: 

> (+ 1 2 3 4 5 6 7 8 9 10) 55 

This time we try (9000 + 900 + 90 -f 9) - (5000 + 500 + 50 + 5): 

> (- (+ 9000 900 90 9) (+ 5000 500 50 5)) => 4444 

This example shows that expressions can be nested. The arguments to the function 
are parenthesized lists, while the arguments to each + are atoms. The 
Lisp notation may look unusual compared to standard mathematical notation, but 
there are advantages to this notation; since Lisp expressions can consist of a function 
followed by any number of arguments, we don't have to keep repeating the More 
important than the notation is the rule for evaluation. In Lisp, lists are evaluated 
by first evaluating all the arguments, then applying the function to the arguments, 
thereby computing the result. This rule is much simpler than the rule for evaluating 
normal mathematical expressions, where there are many conventions to remember, 
such as doing multiplications and divisions before sums and differences. We will see 
below that the actual Lisp evaluation rule is a little more complicated, but not much. 

Sometimes programmers who are familiar with other languages have preconceptions 
that make it difficult for them to learn Lisp. For them, three points are worth 
stressing here. First, many other languages make a distinction between statements 
and expressions. An expression, like 2 + 2, has a value, but a statement, like . = 
2 + 2, does not. Statements have effects, but they do not return values. In Lisp, 
there is no such distinction: every expression returns a value. It is true that some 
expressions have effects, but even those expressions also return values. 

Second, the lexical rules for Lisp are much simpler than the rules for other 
languages. In particular, there are fewer punctuation characters: only parentheses, 
quote marks (single, double, and backward), spaces, and the comma serve to separate 
symbols from each other. Thus, while the statement y=a*x+3 is analyzed as seven 
separate tokens in other languages, in Lisp it would be treated as a single symbol. To 


<a id='page-6'></a>

get a list of tokens, we would have to insert spaces: (y = a * . + 3).^ 

Third, while many languages use semicolons to delimit statements. Lisp has no 
need of semicolons, since expressions are delimited by parentheses. Lisp chooses 
to use semicolons for another purpose—to mark the beginning of a comment, which 
lasts until the end of the line: 

> (+ 2 2) ; this is a comment 

1.1 Symbolic Computation 
All we've done so far is manipulate numbers in the same way a simple pocket 
calculator would. Lisp is more useful than a calculator for two main reasons. First, 
it allows us to manipulate objects other than numbers, and second, it allows us 
to define new objects that might be useful in subsequent computations. We will 
examine these two important properties in turn. 

Besides numbers. Lisp can represent characters (letters), strings of characters, 
and arbitrary symbols, where we are free to interpret these symbols as referring to 
things outside the world of mathematics. Lisp can also build nonatomic objects 
by combining several objects into a list. This capability is fundamental and well 
supported in the language; in fact, the name Lisp is short for LISt Processing. 

Here's an example of a computation on lists: 

> (append '(Pat Kim) '(Robin Sandy)) (PAT KIM ROBIN SANDY) 

This expression appends together two lists of names. The rule for evaluating this 
expression is the same as the rule for numeric calculations: apply the function (in 
this case append) to the value of the arguments. 

The unusual part is the quote mark ('), which serves to block the evaluation of the 
following expression, returning it literally. If we just had the expression (Pat Kim), 
it would be evaluated by considering Pat as a function and applying it to the value of 
the expression Ki m. This is not what we had in mind. The quote mark instructs Lisp 
to treat the list as a piece of data rather than as a function call: 

> '(Pat Kim) (PAT KIM) 

In other computer languages (and in English), quotes usually come in pairs: one to 
mark the beginning, and one to mark the end. In Lisp, a single quote is used to mark 

^This list of symbols is not a legal Lisp assignment statement, but it is a Lisp data object. 


<a id='page-7'></a>

the beginning of an expression. Since we always know how long a single expression 
is—either to the end of an atom or to the matching parenthesis of a list—we don't need 
an explicit punctuation mark to tell us where the expression ends. Quotes can be 
used on hsts, as in * (Pat Ki m), on symbols as in ' Robi n, and in fact on anything else. 
Here are some examples: 

> 'John => JOHN 

> '(John Q Public) => (JOHN Q PUBLIC) 

> '2 2 

> . => . 

> '(+ 2 2) =.> (+ 2 2) 

> (+ 2 2) => 4 

> John ^ Error: ]OHN is not a bound variable 

> (John Q Public) ^ Error: JOHN is not a function 

Note that ' 2 evaluates to 2 because it is a quoted expression, and 2 evaluates to 2 
because numbers evaluate to themselves. Same result, different reason. In contrast, 
'John evaluates to John because it is a quoted expression, but evaluating John leads 
to an error, because evaluating a symbol means getting the value of the symbol, and 
no value has been assigned to John. 

Symbolic computations can be nested and even mixed with numeric computations. 
The following expression builds a list of names in a slightly different way than 
we saw before, using the built-in function list. We then see how to find the number 
of elements in the list, using the built-in function length: 

> (append '(Pat Kim) (list '(John Q Public) 'Sandy)) 
(PAT KIM (JOHN Q PUBLIC) SANDY) 

> (length (append '(Pat Kim) (list '(John Q Public) 'Sandy))) 
4 

There are four important points to make about symbols: 

* First, it is important to remember that Lisp does not attach any external significance 
to the objects it manipulates. For example, we naturally think of (Robi. 
Sandy) asalistof two first names, and (John Q Publ ic) as a list of one person's 
first name, middle initial, and last name. Lisp has no such preconceptions. To 
Lisp, both Robi. and xyzzy are perfectly good symbols. 
* Second, to do the computations above, we had to know that append, length, 
and + are defined functions in Common Lisp. Learning a language involves 

<a id='page-8'></a>

remembering vocabulary items (or knowing where to look them up) as well 
as learning the basic rules for forming expressions and determining what they 
mean. Common Lisp provides over 700 built-in functions. At some point the 
reader should flip through a reference text to see what's there, but most of the 
important functions are presented in part I of this book. 

* Third, note that symbols in Common Lisp are not case sensitive. By that I 
mean that the inputs John, John, and jOhN all refer to the same symbol, which 
is normally printed as JOHN.^ 
* Fourth, note that a wide variety of characters are allowed in symbols: numbers, 
letters, and other punctuation marks like'+' or'!'. The exact rules for what constitutes 
a symbol are a little complicated, but the normal convention is to use 
symbols consisting mostly of letters, with words separated by a dash (-), and 
perhaps with a number at the end. Some programmers are more liberal in naming 
variables, and include characters like'? 1 $/<=>'. For example, a function to 
convert dollars to yen might be named with the symbol $- to -yen or $ ->yen in 
Lisp, while one would use something like Dol 1 arsToYen, dol 1 ars_to_yen or 
do! 2yen in Pascal or C. There are a few exceptions to these naming conventions, 
which will be dealt with as they come up. 
1.2 Variables 
We have seen some of the basics of symbolic computation. Now we move on to 
perhaps the most important characteristic of a programming language: the ability to 
define new objects in terms of others, and to name these objects for future use. Here 
symbols again play an important role—they are used to name variables. A variable 
can take on a value, which can be any Lisp object. One way to give a value to a 
variable is with setf: 

> (setf . '(John 0 Public)) => (JOHN Q PUBLIC) 

> . (JOHN Q PUBLIC) 

> (setf X 10) 10 

> (+ X x) 20 

> (+ X (length p)) => 13 

After assigning the value (John Q Rubi i c) to the variable named p, we can refer to 
the value with the name p. Similarly, after assigning a value to the variable named x, 
we can refer to both . and p. 

^The variable *pri nt - case* controls how symbols will be printed. By default, the value of 
this variable is -.upcase, but it can be changed to rdowncaseor : capitalize. 


<a id='page-9'></a>

Symbols are also used to name functions in Common Lisp. Every symbol can 
be used as the name of a variable or a function, or both, although it is rare (and 
potentially confusing) to have symbols name both. For example, append and length 
are symbols that name functions but have no values as variables, and pi does not 
name a function but is a variable whose value is 3.1415926535897936 (or thereabout). 

1.3 Special Forms 
The careful reader will note that setf violates the evaluation rule. We said earlier 
that functions like +, - and append work by first evaluating all their arguments and 
then applying the function to the result. But setf doesn't follow that rule, because 
setf is not a function at all. Rather, it is part of the basic syntax of Lisp. Besides the 
syntax of atoms and function calls. Lisp has a small number of syntactic expressions. 
They are known as special forms. They serve the same purpose as statements in other 
programming languages, and indeed have some of the same syntactic markers, such 
as i f and 1 oop. There are two main differences between Lisp's syntax and other 
languages. First, Lisp's syntactic forms are always lists in which the first element is 
one of a small number of privileged symbols, setf is one of these symbols, so (setf 
. 10) is a special form. Second, special forms are expressions that return a value. 
This is in contrast to statements in most languages, which have an effect but do not 
return a value. 

In evaluating an to expression like (setf . (+ 1 2)), we set the variable named 
by the symbol . to the value of (+12), which is 3. If setf were a normal function, 
we would evaluate both the symbol x and the expression (+1 2) and do something 
with these two values, which is not what we want at all. setf is called a special form 
because it does something special: if it did not exist, it would be impossible to write 
a function that assigns a value to a variable. The philosophy of Lisp is to provide a 
small number of special forms to do the things that could not otherwise be done, and 
then to expect the user to write everthing else as functions. 

The term special form is used confusingly to refer both to symbols like setf and 
expressions that start with them, like (setf . 3). In the book Common LISPcraft 
Wilensky resolves the ambiguity by calling setf a special function, and reserving the 
term special form for (setf . 3). This terminology implies that setf is just another 
function, but a special one in that its first argument is not evaluated. Such a view 
made sense in the days when Lisp was primarily an interpreted language. The 
modern view is that setf should not be considered some kind of abnormal function 
but rather a marker of special syntax that will be handled specially by the compiler. 
Thus, the special form (setf x (+ 2 1)) should be considered the equivalent of . = 
2 + 1 in C. When there is risk of confusion, we will call setf a special form operator 
and (setf . 3) a special form expression. 


<a id='page-10'></a>

It turns out that the quote mark is just an abbreviation for another special form. 
The expression 'x is equivalent to (quote ;c), a special form expression that evaluates 
toX. The special form operators used in this chapter are: 

defun define function 
defparameter define special variable 
set f set variable or field to new value 
let bind local variable(s) 
case choose one of several alternatives 
if do one thing or another, depending on a test 
function (#') refer to a function 
quote (') introduce constant data 

1.4 Lists 
So far we have seen two functions that operate on hsts: append and length. Since 
lists are important, let's look at some more list processing functions: 

> . => (JOHN 0 PUBLIC) 

> (first p) JOHN 

> (rest p) (Q PUBLIC) 

> (second p) ^ Q 

> (third p) => PUBLIC 

> (fourth p) ^ NIL 

> (length p) 3 

The functions first, second, third, and fourth are aptly named: first returns 
the first element of a list, second gives you the second element, and so on. The 
function rest is not as obvious; its name stands for "the rest of the list after the first 
element." The symbol nil and the form () are completely synonymous; they are 
both representations of the empty list, ni 1 is also used to denote the "false" value in 
Lisp. Thus, (fourth .) is ni 1 because there is no fourth element of p. Note that Hsts 
need not be composed only of atoms, but can contain sublists as elements: 

> (setf . '((1st element) 2 (element 3) ((4)) 5)) 
((1ST ELEMENT) 2 (ELEMENT 3) ((4)) 5) 

> (length x) 

> (first x) = (1ST ELEMENT) 


<a id='page-11'></a>

> (second x) => 2 

> (third X) => (ELEMENT 3) 

> (fourth X) ((4)) 

> (first (fourth x)) ^ (4) 

> (first (first (fourth x))) ^ 4 

> (fifth X) ^ 5 

> (first X) (1ST ELEMENT) 

> (second (first x)) => ELEMENT 

So far we have seen how to access parts of lists. It is also possible to build up new 
lists, as these examples show: 

> . (JOHN Q PUBLIC) 

> (cons 'Mr p) ^ (MR JOHN Q PUBLIC) 

> (cons (first p) (rest p)) => (JOHN Q PUBLIC) 

> (setf town (list 'Anytown 'USA)) => (ANYTOWN USA) 

> (list . Of town 'may 'have 'already 'won!) ^ 
((JOHN Q PUBLIC) OF (ANYTOWN USA) MAY HAVE ALREADY WON!) 

> (append . '(of) town '(may have already won!)) 
(JOHN Q PUBLIC OF ANYTOWN USA MAY HAVE ALREADY WON!) 

> . (JOHN Q PUBLIC) 

The function cons stands for "construct." It takes as arguments an element and 
a list,^ and constructs a new list whose first is the element and whose rest is the 
original list. 1 i st takes any number of elements as arguments and returns a new 
hst containing those elements in order. We've already seen append, which is similar 
to 1 ist; it takes as arguments any number of lists and appends them all together, 
forming one big list. Thus, the arguments to append must be lists, while the arguments 
to 11 St may be lists or atoms. It is important to note that these functions create new 
lists; they don't modify old ones. When we say (append . q), the effect is to create 
a brand new list that starts with the same elements that were in p. . itself remains 
unchanged. 

Now let's move away from abstract functions on lists, and consider a simple 
problem: given a person's name in the form of a list, how might we extract the family 
name? For (JOHN Q PUBLIC) we could Justuse the function thi rd, but that wouldn't 

^ Later we will see what happens when the second argument is not a list. 


<a id='page-12'></a>

work for someone with no middle name. There is a function called last in Common 
Lisp; perhaps that would work. We can experiment: 

> (last p) => (PUBLIC) 

> (first (last p)) PUBLIC 

It turns out that last perversely returns a list of the last element, rather than the 
last element itself.^ Thus we need to combine first and last to pick out the actual 
last element. We would like to be able to save the work we've done, and give it a 
proper description, like 1 a st - name. We could use setf to save the last name of p, but 
that wouldn't help determine any other last name. Instead we want to define a new 
function that computes the last name of any name that is represented as a list. The 
next section does just that. 

1.5 Defining New Functions 
The special form defun stands for "define function." It is used here to define a new 
function called last-name: 

(defun last-name (name) 
"Select the last name from a name represented as a list. " 
(first (last name))) 

We give our new function the name last-name. It has a parameter list consisting of a 
single parameter: (name). This means that the function takes one argument, which 
we will refer to as name. It also has a documentation string that states what the function 
does. This is not used in any computation, but documentation strings are crucial 
tools for debugging and understanding large systems. The body of the definition is 
(first (last name)), which is what we used before to pick out the last name of p. 
The difference is that here we want to pick out the last name of any name, not just of 
the particular name p. 

In general, a function definition takes the following form (where the documentation 
string is optional, and all other parts are required): 

^In ANSI Common Lisp, last is defined to return a list of the last . elements, where . 
defaults to 1. Thus (last p) = (last . 1) = (PUBLIC), and (last . 2) = (Q PUBLIC). This 
may make the definition of last seem less perverse. 


<a id='page-13'></a>

(defun function-name {parameter...) 
''documentation string'' 
function-body...) 

The function name must be a symbol, the parameters are usually symbols (with some 
complications to be explained later), and the function body consists of one or more 
expressions that are evaluated when the function is called. The last expression is 
returned as the value of the function call. 

Once we have defined last-name, we can use it just like any other Lisp function: 

> (last-name p)=i> PUBLIC 

> (last-name '(Rear Admiral Grace Murray Hopper))^ HOPPER 

> (last-name '(Rex Morgan MD)) ^ MD 

> (last-name '(Spot)) ^ SPOT 

> (last-name '(Aristotle)) ARISTOTLE 

The last three examples point out an inherent limitation of the programming enterprise. 
When we say (defun last-name...) we are not really defining what it means 
for a person to have a last name; we are just defining an operation on a representation 
of names in terms of lists. Our intuitions—that MD is a title. Spot is the first name 
of a dog, and Aristotle lived before the concept of last name was invented—are not 
represented in this operation. However, we could always change the definition of 
last-name to incorporate these problematic cases. 

We can also define the function first-name. Even though the definition is trivial 
(it is the same as the function first), it is still good practice to define first-name 
explicitly. Then we can use the function fi rst - name when we are dealing with names, 
and first when we are dealing with arbitrary lists. The computer will perform the 
same operation in each case, but we as programmers (and readers of programs) will 
be less confused. Another advanatge of defining specific functions like first-name 
is that if we decide to change the representation of names we will only have to change 
the definition of first-name. This is a much easier task than hunting through a large 
program and changing the uses of first that refer to names, while leaving other 
uses alone. 

(defun first-name (name) 
"Select the first name from a name represented as a list. " 
(first name)) 

> . (JOHN Q PUBLIC) 

> (first-name p) JOHN 

> (first-name '(Wilma Flintstone)) WILMA 


<a id='page-14'></a>

> (setf names '((John Q Public) (Malcolm X) 
(Admiral Grace Murray Hopper) (Spot) 
(Aristotle) (A A Milne) (Z . Top) 
(Sir Larry Olivier) (Miss Scarlet))) => 

((JOHN Q PUBLIC) (MALCOLM X) (ADMIRAL GRACE MURRAY HOPPER) 
(SPOT) (ARISTOTLE) (A A MILNE) (Z . TOP) (SIR LARRY OLIVIER) 
(MISS SCARLET)) 

> (first-name (first names)) JOHN 

In the last expression we used the function first to pick out the first element in 
a list of names, and then the function first-name to pick out the first name of 
that element. We could also have said (first (first names)) or even (first 
(first-name names)) and still have gotten JOHN, but we would not be accurately 
representing what is being considered a name and what is being considered a list 
of names. 

1.6 Using Functions 
One good thing about defining a list of names, as we did above, is that it makes it 
easier to test our functions. Consider the following expression, which can be used to 
test the last-name function: 

> (mapcar #'last-name names) 
(PUBLIC X HOPPER SPOT ARISTOTLE MILNE TOP OLIVIER SCARLET) 

The funny # ' notation maps from the name of a function to the function itself. This 
is analogous to ' . notation. The built-in function mapca r is passed two arguments, a 
function and a list. It returns a list built by calling the function on every element of 
the input list. In other words, the mapcar call above is equivalent to: 

(list (last-name (first names)) 
(last-name (second names)) 
(last-name (third names)) 
...) 

mapcar's name comes from the fact that it "maps" the function across each of the 
arguments. The car part of the name refers to the Lisp function car, an old name for 
first. cdr is the old name for rest. The names stand for "contents of the address 
register" and "contents of the decrement register," the instructions that were used in 
the first implementation of Lisp on the IBM 704. I'm sure you'll agree that first and 


<a id='page-15'></a>
rest are much better names, and they will be used instead of ca r and cdr whenever 
we are talking about lists. However, we will continue to use car and cdr on occasion 
when we are considering a pair of values that are not considered as a list. Beware 
that some programmers still use ca r and cdr for Usts as well. 

Here are some more examples of mapcar: 

> (mapcar '(1 2 3 4))=>(-l -2 -3 -4) 

> (mapcar #'+ '(1 2 3 4) '(10 20 30 40)) ^(11 22 33 44) 

This last example shows that mapcar can be passed three arguments, in which case the 
first argument should be a binary function, which will be applied to corresponding 
elements of the other two Usts. In general, mapcar expects an n-ary function as its 
first argument, followed by . lists. It first applies the function to the argument list 
obtained by collecting the first element of each list. Then it applies the function to the 
second element of each list, and so on, until one of the lists is exhausted. It returns a 
list of all the function values it has computed. 

Now that we understand mapcar, let's use it to test the first-name function: 

> (mapcar #'first-name names) 

(JOHN MALCOLM ADMIRAL SPOT ARISTOTLE A . SIR MISS) 

We might be disappointed with these results. Suppose we wanted a version of 

first-name which ignored titles like Admiral and Miss, and got to the "real" first 

name. We could proceed as follows: 

(defparameter nitles * 
'(Mr Mrs Miss Ms Sir Madam Dr Admiral Major General) 
"A list of titles that can appear at the start of a name.") 

We've introduced another new special form, defparameter, which defines a parameter—
a variable that does not change over the course of a computation, but that 
might change when we think of new things to add (like the French Mme or the military 
Lt.). The def parameter form both gives a value to the variable and makes it possible 
to use the variable in subsequent function definitions. In this example we have 
exercised the option of providing a documentation string that describes the variable. 
It is a widely used convention among Lisp programmers to mark special variables by 
spelling their names with asterisks on either end. This is just a convention; in Lisp, 
the asterisk is just another character that has no particular meaning. 

We next give a new definition for first-name, which supersedes the previous 
definition.^ This definition says that if the first word of the name is a member of the 

^Just as we can change the value of a variable, we can also change the value of a function 


<a id='page-16'></a>

list of titles, then we want to ignore that word and return the first-name of the rest 
of the words in the name. Otherwise, we use the first word, just as before. Another 
built-in function, member, tests to see if its first argument is an element of the list 
passed as the second argument. 

The special form i f has the form ( i f test then-part else-part). There are many 
special forms for performing conditional tests in Lisp; i f is the most appropriate for 
this example. An i f form is evaluated by first evaluating the test expression. If it is 
true, the then-part is evaluated and returned as the value of the i f form; otherwise 
the else-part is evaluated and returned. While some languages insist that the value of 
a conditional test must be either true or f al se. Lisp is much more forgiving. The test 
may legally evaluate to any value at all. Only the value nil is considered false; all 
other values are considered true. In the definition of first - name below, the function 
member will return a non-nil (hence true) value if the first element of the name is in the 
list of titles, and will return .i 1 (hence false) if it is not. Although all non-nil values 
are considered true, by convention the constant t is usually used to represent truth. 

(defun first-name (name) 

"Select the first name from a name represented as a list. " 

(if (member (first name) *titles*) 

(first-name (rest name)) 

(first name))) 

When we map the new fi rst-name over the list of names, the results are more 
encouraging. In addition, the function gets the "right" result for '(Madam Major 
General Paul a Jones) by dropping off titles one at a time. 

> (mapcar #'first-name names) 
(JOHN MALCOLM GRACE SPOT ARISTOTLE A . LARRY SCARLET) 

> (first-name '(Madam Major General Paula Jones)) 
PAULA 

We can see how this works by tracing the execution of first-name, and seeing the 
values passed to and returned from the function. The special forms trace and 
untrace are used for this purpose. 

> (trace first-name) 
(FIRST-NAME) 

in Lisp. It is not necessary to recompile everything when a change is made, as it would be in 
other languages. 


<a id='page-17'></a>
> (first-name '(John Q Public)) 
(1 ENTER FIRST-NAME: (JOHN Q PUBLIC)) 
(1 EXIT FIRST-NAME: JOHN) 
JOHN 

When first - name is called, the definition is entered with the single argument, name, 
taking on the value (JOHN Q PUBLIC). The value returned is JOHN. Trace prints two 
lines indicating entry and exit from the function, and then Lisp, as usual, prints the 
final result, JOHN. 

The next example is more complicated. The function first-name is used four 
times. First, it is entered with name bound to (Madam Major General Paula Jones). 
The first element of this list is Madam, and since this is a member of the list of titles, 
the result is computed by calling first-name again on the rest of the name—(Major 
General Paula Jones). This process repeats two more times, and we finally enter 
first - name with name bound to (Paul a Jones). Since Pa ul a is not a title, it becomes 
the result of this call to first - name, and thus the result of all four calls, as trace shows. 
Once we are happy with the workings of first - name, the special form unt race turns 
off tracing. 

> (first-name '(Madam Major General Paula Jones)) => 
(1 ENTER FIRST-NAME: (MADAM MAJOR GENERAL PAULA JONES)) 
(2 ENTER FIRST-NAME: (MAJOR GENERAL PAULA JONES)) 

(3 ENTER FIRST-NAME: (GENERAL PAULA JONES)) 
(4 ENTER FIRST-NAME: (PAULA JONES)) 
(4 EXIT FIRST-NAME: PAULA) 

(3 EXIT FIRST-NAME: PAULA) 

(2 EXIT FIRST-NAME: PAULA) 
(1 EXIT FIRST-NAME: PAULA) 
PAULA 

> (untrace first-name) (FIRST-NAME) 

> (first-name '(Mr Blue Jeans)) BLUE 

The function first-name is said to be recursive because its definition includes a call 
to itself. Programmers who are new to the concept of recursion sometimes find it 
mysterious. But recursive functions are really no different from nonrecursive ones. 
Any function is required to return the correct value for the given input(s). Another 
way to look at this requirement is to break it into two parts: a function must return 
a value, and it must not return any incorrect values. This two-part requirement is 
equivalent to the first one, but it makes it easier to think about and design function 
definitions. 

Next I show an abstract description of the first-name problem, to emphasize 
the design of the function and the fact that recursive solutions are not tied to Lisp in 
anyway: 


<a id='page-18'></a>

function first-name(name): 

i f the first element of name is a title 

then do something complicated to get the first-name 

else return the first element of the name 

This breaks up the problem into two cases. In the second case, we return an answer, 
and it is in fact the correct answer. We have not yet specified what to do in the first 
case. But we do know that it has something to do with the rest of the name after the 
first element, and that what we want is to extract the first name out of those elements. 
The leap of faith is to go ahead and use first-name, even though it has not been fully 
defined yet: 

function first-name(name): 

i f thefirstelement of name is a title 
then return the fi rst-name of the rest of the name 
el se return the first element of the name 

Now the first case in fi rst-name is recursive, and the second case remains unchanged. 
We already agreed that the second case returns the correct answer, and the 
first case only returns what first-name returns. So first-name as a whole can only 
return correct answers. Thus, we're halfway to showing that the function is correct; 
the other half is to show that it eventually returns some answer. But every recursive 
call chops off the first element and looks at the rest, so for an n-element list there 
can be at most . recursive calls. This completes the demonstration that the function 
is correct. Programmers who learn to think this way find recursion to be a valuable 
tool rather than a confusing mystery. 

1.7 Higher-Order Functions 
Functions in Lisp can not only be "called," or applied to arguments, they can also be 
manipulated just like any other kind of object. A function that takes another function 
as an argument is called a higher-orderfunction, ma pea r is an example. To demonstrate 
the higher-order-function style of programming, we will define a new function called 
mappend. It takes two arguments, a function and a list, mappend maps the function 
over each element of the list and appends together all the results. The first definition 
follows immediately from the description and the fact that the function appl y can be 
used to apply a function to a list of arguments. 


<a id='page-19'></a>

(defun mappend (fn the-list) 
"Apply fn to each element of list and append the results. " 
(apply #'append (mapcar fn the-list))) 

Now we experiment a little to see how apply and mappend work. The first example 
applies the addition function to a list of four numbers. 

> (apply #'+ '(1 2 3 4))^10 

The next example applies append to a list of two arguments, where each argument is 
a list. If the arguments were not lists, it would be an error. 

> (apply #'append '((1 2 3) (a b c)))=^(l 2 3 A . C) 

Now we define a new function, sel f-and-doubl e, and apply it to a variety of arguments. 


> (defun self-and-double (x) (list . (+ . .))) 

> (self-and-double 3) {3 6) 

> (apply #'self-and-double '(3))=^(3 6) 

If we had tried to apply sel f-and-doubl e to a list of more than one argument, or to a 
list that did not contain a number, it would be an error, just as it would be an error to 
evaluate (self-and-double 3 4) or (self-and-double 'Kim). Now let's return to 
the mapping functions: 

> (mapcar #'self-and-double '(1 10 300))=>((1 2) (10 20) (300 600)) 

> (mappend #'self-and-double '(1 10 300))=. (1 2 10 20 300 600) 

When mapcar is passed a function and a list of three arguments, it always returns a 
list of three values. Each value is the result of calling the function on the respective 
argument. In contrast, when mappend is called, it returns one big list, which is equal 
to all the values that mapca r would generate appended together. It would be an error 
to call mappend with a function that didn't return lists, because append expects to see 
lists as its arguments. 

Now consider the following problem: given a list of elements, return a list consisting 
of all the numbers in the original list and the negation of those numbers. For 
example, given the list (testing 12 3 test), return (1 -12-2 3 -3). This 
problem can be solved very easily using mappend as a component: 


<a id='page-20'></a>

(defun numbers-and-negations (input) 
"Given a list, return only the numbers and their negations." 
(mappend #'number-and-negation input)) 

(defun number-and-negation (x) 
"If . is a number, return a list of . and -x." 
(if (numberp x) 

(list . (- .)) 
nil)) 

> (numbers-and-negations '(testing 12 3 test)) =^(1-12-2 3 -3) 

The alternate definition of mappend shown in the following doesn't make use of 
ma pea r; instead it builds up the list one element at a time: 

(defun mappend (fn the-list) 
"Apply fn to each element of list and append the results." 
(if (null the-list) 

nil 
(append (funcall fn (first the-list)) 
(mappend fn (rest the-list))))) 

funcall is similar to apply; it too takes a function as its first argument and applies the 
function to a list of arguments, but in the case of funcall, the arguments are listed 
separately: 

> (funcall #'+ 2 3) =i> 5 

> (apply #'+ '(2 3)) 5 

> (funcall #'+ '(2 3) )=> Error: (2 3) is not a number. 

These are equivalent to (+ 2 3), (+ 2 3),and(+ '(2 3)), respectively. 

So far, every function we have used has been either predefined in Common Lisp 
or introduced with a defun, which pairs a function with a name. It is also possible to 
introduce a function without giving it a name, using the special syntax 1 ambda. 

The name lambda comes from the mathematician Alonzo Church's notation for 
functions (Church 1941). Lisp usually prefers expressive names over terse Greek 
letters, but lambda is an exception. A better name would be make -function. Lambda 
derives from the notation in Russell and Whitehead's Principia Mathematica, which 
used a caret over bound variables: x{x -hx). Church wanted a one-dimensional 
string, so he moved the caret in front: ^x{x-\-x). The caret looked funny with nothing 
below it, so Church switched to the closest thing, an uppercase lambda, \x{x -f x). 
The . was easily confused with other symbols, so eventually the lowercase lambda 
was substituted: \x{x -hx). John McCarthy was a student of Church's at Princeton, 
so when McCarthy invented Lisp in 1958, he adopted the lambda notation. There 


<a id='page-21'></a>
were no Greek letters on the keypunches of that era, so McCarthy used (1 ambda (x) 
(+ . .)), and it has survived to this day. In general, the form of a lambda expression is 

(lambda (parameters...) body...) 

A lambda expression is just a nonatomic name for a function, just as append is an 
atomic name for a built-in function. As such, it is appropriate for use in the first 
position of a function call, but if we want to get at the actual function, rather than its 
name, we still have to use the # ' notation. For example: 

> ((lambda (x) (+ . 2)) 4) => 6 

> (funcall #'(lambda (x) (+ . 2)) 4) => 6 

To understand the distinction we have to be clear on how expressions are evaluated 
in Lisp. The normal rule for evaluation states that symbols are evaluated by looking 
up the value of the variable that the symbol refers to. So the x in (+ . 2) is evaluated 
by looking up the value of the variable named x. A list is evaluated in one of two 
ways. If the first element of the list is a special form operator, then the list is evaluated 
according to the syntax rule for that special form. Otherwise, the Hst represents a 
function call. The first element is evaluated in a unique way, as a function. This 
means it can either be a symbol or a lambda expression. In either case, the function 
named by the first element is applied to the values of the remaining elements in the 
list. These values are determined by the normal evaluation rules. If we want to refer 
to a function in a position other than the first element of a function call, we have 
to use the #' notation. Otherwise, the expressions will be evaluated by the normal 
evaluation rule, and will not be treated as functions. For example: 

> append ^ Error: APPEND is not a bound variable 

> (lambda (x) i+ . Z)) Error: LAMBDA is not a function 

Here are some more examples of the correct use of functions: 

> (mapcar #*(lambda (x) (+ . .)) 
'(12 3 4 5)) ^ 
(2468 10) 

> (mappend #'(lambda (1) (list 1 (reverse 1))) 
'((1 2 3) (a b c))) => 
((1 2 3) (3 2 1) (A . C) (C . A)) 

Programmers who are used to other languages sometimes fail to see the point of 
lambda expressions. There are two reasons why lambda expressions are very useful. 


<a id='page-22'></a>

First, it can be messy to clutter up a program with superfluous names. Just as it 
is clearer to write (a+b)*(c+cl) rather than to invent variable names like tempi and 
temp2 to hold a+b and c+d, so it can be clearer to define a function as a lambda 
expression rather than inventing a name for it. 

Second, and more importantly, lambda expressions make it possible to create 
new functions at run time. This is a powerful technique that is not possible in 
most programming languages. These run-time functions, known as closures, will be 
covered in section 3.16. 

1.8 Other Data Types 
So far we have seen just four kinds of Lisp objects: numbers, symbols, lists, and 
functions. Lisp actually defines about 25 different types of objects: vectors, arrays, 
structures, characters, streams, hash tables, and others. At this point we will introduce 
one more, the string. As you can see in the following, strings, like numbers, 
evaluate to themselves. Strings are used mainly for printing out messages, while 
symbols are used for their relationships to other objects, and to name variables. The 
printed representation of a string has a double quote mark (") at each end. 

> "a string" =4> "a string" 

> (length "a string") =i>8 

> (length "")=^0 

1.9 Summary: The Lisp Evaluation Rule 
We can now summarize the evaluation rule for Lisp. 

* Every expression is either a list or an atom. 
* Every list to be evaluated is either a special form expression or a function application. 
* A specialform expression is defined to be a lis t whose first element is a special form 
operator. The expression is evaluated according to the operator's idiosyncratic 
evaluation rule. For example, the evaluation rule for setf is to evaluate the 
second argument according to the normal evaluation rule, set the first argument 
to that value, and return the value as the result. The rule for defun is to define 
a new function, and return the name of the function. The rule for quote 
is to return the first argument unevaluated. The notation 'x is actually an 

<a id='page-23'></a>
abbreviation for the special form expression (quote x). Similarly, the notation 
# '/is an abbreviation for the special form expression (function f). 

'John = (quote John) JOHN 
(setf . 'John) => JOHN 

(defun twice (x) (+ . x)) => TWICE 

(if (= 2 3) (error) (+ 5 6)) => 11 

Afunction application is evaluated by first evaluating the arguments (the rest of 
the list) and then finding the function named by the first element of the list and 
applying it to the list of evaluated arguments. 

(+2 3) =^5 

(- (+ 90 9) (+ 50 5 (length '(Pat Kim)))) => 42 

Note that if ' (Pat Kim) did not have the quote, it would be treated as a function 
application of the function pat to the value of the variable ki m. 

Every atom is either a symbol or a nonsymbol 

A symbol evaluates to the most recent value that has been assigned to the 
variable named by that symbol. Symbols are composed of letters, and possibly 
digits and, rarely, punctuation characters. To avoid confusion, we will use 
symbols composed mostly of the letters a-z and the character, with a few 
exceptions.^ 

names 

. 
*print-pretty* 

* A nonsymbol atom evaluates to itself. For now, numbers and strings are the 
only such non-symbol atoms we know of. Numbers are composed of digits, 
and possibly a decimal point and sign. There are also provisions for scientific 
notation, rational and complex numbers, and numbers with different bases, 
but we won't describe the details here. Strings are delimited by double quote 
marks on both sides. 
^For example, symbols that denote so-called special variables usually begin and end in 
asterisks. Also, note that I did not hesitate to use the symbol won! on [page 11](chapter1.md#page-11). 


<a id='page-24'></a>

42 42 

-273.15 -273.15 

"a string" "a string" 

There are some minor details of Common Lisp that complicate the evaluation 
rules, but this definition will suffice for now. 

One complication that causes confusion for beginning Lispers is the difference 
between reading and evaluating an expression. Beginners often imagine that when 
they type an expression, such as 

> (+ (* 3 4) (* 5 6)) 

the Lisp system first reads the (+, then fetches the addition function, then reads (* 

34) and computes 12, then reads (* 5 6) and computes 30, and finally computes 
42. In fact, what actually happens is that the system first reads the entire expression, 
the list (+ (* 3 4) (* 5 6)). Only after it has been read does the system begin 
to evaluate it. This evaluation can be done by an interpreter that looks at the list 
directly, or it can be done by a compiler that translates the list into machine language 
instructions and then executes those instructions. 
We can see now that it was a little imprecise to say, "Numbers are composed 
of digits, and possibly a decimal point and sign." It would be more precise to say 
that the printed representation of a number, as expected by the function read and 
as produced by the function print, is composed of digits, and possibly a decimal 
point and sign. The internal representation of a number varies from one computer 
to another, but you can be sure that it will be a bit pattern in a particular memory 
location, and it will no longer contain the original characters used to represent the 
number in decimal notation. Similarly, it is the printed representation of a string 
that is surrounded by double quote marks; the internal representation is a memory 
location marking the beginning of a vector of characters. 

Beginners who fail to grasp the distinction between reading and evaluating may 
have a good model of what expressions evaluate to, but they usually have a terrible 
model of the efficiency of evaluating expressions. One student used only one-letter 
variable names, because he felt that it would be faster for the computer to look up 
a one-letter name than a multiletter name. While it may be true that shorter names 
can save a microsecond at read time, this makes no difference at all at evaluation 
time. Every variable, regardless of its name, is just a memory location, and the time 
to access the location does not depend on the name of the variable. 


<a id='page-25'></a>
1.10 What Makes Lisp Different? 
What is it that sets Lisp apart from other languages? Why is it a good language for 
AI applications? There are at least eight important factors: 

* Built-in Support for Lists 
* Automatic Storage Management 
* Dynamic Typing 
* First-Class Functions 
* Uniform Syntax 
* Interactive Environment 
* Extensibility 
* History 
In sum, these factors allow a programmer to delay making decisions. In the example 
dealing with names, we were able to use the built-in list functions to construct and 
manipulate names without making a lot of explicit decisions about their representation. 
If we decided to change the representation, it would be easy to go back and 
alter parts of the program, leaving other parts unchanged. 

This ability to delay decisions—or more accurately, to make temporary, nonbinding 
decisions—is usually a good thing, because it means that irrelevant details can be 
ignored. There are also some negative points of delaying decisions. First, the less we 
tell the compiler, the greater the chance that it may have to produce inefficient code. 
Second, the less we tell the compiler, the less chance it has of noticing inconsistencies 
and warning us. Errors may not be detected until the program is run. Let's consider 
each factor in more depth, weighing the advantages and disadvantages: 

* Built-in Support for Lists. The list is a very versatile data structure, and while lists 
can be implemented in any language. Lisp makes it easy to use them. Many 
AI applications involve lists of constantly changing size, making fixed-length 
data structures like vectors harder to use. 
Early versions of Lisp used lists as their only aggregate data structure. Common 
Lisp provides other types as well, because lists are not always the most efficient 
choice. 

Automatic Storage Management. The Lisp programmer needn't keep track of 
memory allocation; it is all done automatically. This frees the programmer of a 
lot of effort, and makes it easy to use the functional style of programming. Other 


<a id='page-26'></a>

languages present programmers with a choice. Variables can be allocated on 
the stack, meaning that they are created when a procedure is entered, and 
disappear when the procedure is done. This is an efficient use of storage, but 
it rules out functions that return complex values. The other choice is for the 
programmer to explicitly allocate and free storage. This makes the functional 
style possible but can lead to errors. 

For example, consider the trivial problem of computing the expression . . (b + 
c), where a, 6, and c are numbers. The code is trivial in any language; here it is 
in Pascal and in Lisp: 

/* Pascal */ Lisp 

a * (b + c) (* a (+ b c)) 

The only difference is that Pascal uses infix notation and Lisp uses prefix. Now 
consider computing . . (b -f c) when a, 6, and c are matrices. Assume we have 
procedures for matrix multiplication and addition. In Lisp the form is exactly 
the same; only the names of the functions are changed. In Pascal we have the 
choice of approaches mentioned before. We could declare temporary variables 
to hold intermediate results on the stack, and replace the functional expression 
with a series of procedure calls: 

/* Pascal */ ;;; Lisp 

var temp, result: matrix; 

add(b,c,temp); (mult a (add b c)) 

mult(a,temp,result); 

return(result); 

The other choice is to write Pascal functions that allocate new matrices on the 
heap. Then one can write nice functional expressions like mul t (a, add (b, c)) 
even in Pascal. However, in practice it rarely works this nicely, because of the 
need to manage storage explicitly: 

/* Pascal */ ;;; Lisp 

var a,b,c,x,y: matrix; 


<a id='page-27'></a>

X := adcl(b,c); (mult a (add b c)) 

y := mult(a,x); 

free(x); 

return(y); 

In general, deciding which structures to free is a difficult task for the Pascal 
programmer. If the programmer misses some, then the program may run out 
of memory. Worse, if the programmer frees a structure that is still being used, 
then strange errors can occur when that piece of memory is reallocated. Lisp 
automatically allocates and frees structures, so these two types of errors can 

never occur. 

Dynamic Typing. Lisp programmers don't have to provide type declarations, 
because the language keeps track of the type of each object at run time, rather 
than figuring out all types at compile time. This makes Lisp programs shorter 
and hence faster to develop, and it also means that functions can often be 
extended to work for objects to which they were not originally intended to 
apply. In Pascal, we can write a procedure to sort an array of 100 integers, but 
we can't use that same procedure to sort 200 integers, or 100 strings. In Lisp, 
one sort fits all. 

One way to appreciate this kind of flexibility is to see how hard it is to achieve 
in other languages. It is impossible in Pascal; in fact, the language Modula was 
invented primarily to fix this problem in Pascal. The language Ada was designed 
to allow flexible generic functions, and a book by Musser and Stepanov 
(1989) describes an Ada package that gives some of the functionality of Common 
Lisp's sequence functions. But the Ada solution is less than ideal: it 
takes a 264-page book to duplicate only part of the functionality of the 20-page 
chapter 14 from Steele (1990), and Musser and Stepanov went through five Ada 
compilers before they found one that would correctly compile their package. 
Also, their package is considerably less powerful, since it does not handle vectors 
or optional keyword parameters. In Common Lisp, all this functionality 
comes for free, and it is easy to add more. 

On the other hand, dynamic typing means that some errors will go undetected 
until run time. The great advantage of strongly typed languages is that they are 
able to give error messages at compile time. The great frustration with strongly 
typed languages is that they are only able to warn about a small class of errors. 
They can tell you that you are mistakenly passing a string to a function that 
expects an integer, but they can't tell you that you are passing an odd number 
to a function that expects an even number. 

First-Class Functions. A first-class object is one that can be used anywhere and 
can be manipulated in the same ways as any other kind of object. In Pascal or C, 


<a id='page-28'></a>

for example, functions can be passed as arguments to other functions, but they 
are not first-class, because it is not possible to create new functions while the 
program is running, nor is it possible to create an anonymous function without 
giving it a name. In Lisp we can do both those things using 1 ambda. This is 
explained in section 3.16, [page 92](chapter3.md#page-92). 

* Uniform Syntax. The syntax of Lisp programs is simple. This makes the language 
easy to learn, and very little time is wasted correcting typos. In addition, 
it is easy to write programs that manipulate other programs or define whole 
new languages—a very powerful technique. The simple syntax also makes it 
easy for text editing programs to parse Lisp. Your editor program should be 
able to indent expressions automatically and to show matching parentheses. 
This is harder to do for languages with complex syntax. 
On the other hand, some people object to all the parentheses. There are two 

answers to this objection. First, consider the alternative: in a language with 

"conventional" syntax. Lisp's parentheses pairs would be replaced either by an 

implicit operator precedence rule (in the case of arithmetic and logical expres


sions) or by a begin/end pair (in the case of control structures). But neither 

of these is necessarily an advantage. Implicit precedence is notoriously error-

prone, and begin/end pairs clutter up the page without adding any content. 

Many languages are moving away from begi n/end: C uses { and }, which are 

equivalent to parentheses, and several modern functional languages (such as 

Haskell) use horizontal blank space, with no explicit grouping at all. 

Second, many Lisp programmers have considered the alternative. There have 
been a number of preprocessors that translate from "conventional" syntax into 
Lisp. None of these has caught on. It is not that Lisp programmers find it 
tolerable to use all those parentheses, rather, they find it advantageous. With a 
little experience, you may too. 

It is also important that the syntax of Lisp data is the same as the syntax of 
programs. Obviously, this makes it easy to convert data to program. Less 
obvious is the time saved by having universal functions to handle input and 
output. The Lisp functions read and pri nt will automatically handle any list, 
structure, string, or number. This makes it trivial to test individual functions 
while developing your program. In a traditional language like C or Pascal, you 
would have to write special-purpose functions to read and print each data type 
you wanted to debug, as well as a special-purpose driver to call the routines. 
Because this is time-consuming and error-prone, the temptation is to avoid 
testing altogether. Thus, Lisp encourages better-tested programs, and makes 
it easier to develop them faster. 

* Interactive Environment. Traditionally, a programmer would write a complete 
program, compile it, correct any errors detected by the compiler, and then 

<a id='page-29'></a>
run and debug it. This is known as the batch mode of interaction. For long 
programs, waiting for the compiler occupied a large portion of the debugging 
time. In Lisp one normally writes a few small functions at a time, getting 
feedback from the Lisp system after evaluating each one. This is knovm as 
an interactive environment. When it comes time to make a change, only the 
changed functions need to be recompiled, so the wait is much shorter. In 
addition, the Lisp programmer can debug by typing in arbitrary expressions 
at any time. This is a big improvement over editing the program to introduce 
print statements and recompiling. 

Notice that the distinction between interactive and a batch languages is separate 
from the distinction between interpreted and compiled languages. It has often 
been stated, incorrectly, that Lisp has an advantage by virtue of being an 
interpreted language. Actually, experienced Common Lisp programmers tend 
to use the compiler almost exclusively. The important point is interaction, not 
interpretation. 

The idea of an interactive environment is such a good one that even traditional 
languages like C and Pascal are starting to offer interactive versions, so this is 
not an exclusive advantage of Lisp. However, Lisp still provides much better 
access to the interactive features. A C interpreter may allow the progranuner 
to type in an expression and have it evaluated immediately, but it will not allow 
the programmer to write a program that, say, goes through the symbol table 
and finds all the user-defined functions and prints information on them. In 
C-even interpreted C-the symbol table is just a Cheshire-cat-like invention 
of the interpreter's imagination that disappears when the program is run. In 
Lisp, the symbol table is a first-class object^ that can be accessed and modified 
with functions like read, intern and do-symbols. 

Common Lisp offers an unusually rich set of useful tools, including over 700 
built-in functions (ANSI Conunon Lisp has over 900). Thus, writing a new 
program involves more gathering of existing pieces of code and less writing of 
new code from scratch. In addition to the standard functions. Common Lisp 
implementations usually provide extensions for interacting with the editor, 
debugger, and window system. 

Extensibility. When Lisp was invented in 1958, nobody could have foreseen the 
advances in programming theory and language design that have taken place in 
the last thirty years. Other early languages have been discairded, replaced by 
ones based on newer ideas. However, Lisp has been able to survive, because 
it has been able to adapt. Because Lisp is extensible, it has been changed to 
incorporate the newest features as they become popular. 

^Actually, there can be several symbol tables. They are known as packages in Common 
Lisp. 


<a id='page-30'></a>

The easiest way to extend the language is with macros. When so-called structured 
programming constructs such as case and if-then-else arose, they were 
incorporated into Lisp as macros. But the flexibility of Lisp goes beyond 
adding individual constructs. Brand new styles of programming can easily be 
implemented. Many AI applications are based on the idea of rule-based programming. 
Another new style is object-oriented programming, which has been 
incorporated with the Common Lisp Object System (CLOS),^ a set of macros, 
functions, and data types that have been integrated into ANSI Common Lisp. 

To show how far Lisp has come, here's the only sample program given in the 
Lisp/MTS Programmer's Guide (Hafner and Wilcox 1974): 

(PROG (LIST DEPTH TEMP RESTLIST) 
(SETQ RESTLIST (LIST (CONS (READ) 0)) ) 
A (COND 
((NOT RESTLIST) (RETURN 'DONE)) 
(T (SETQ LIST (UNCONS (UNCONS RESTLIST 

RESTLIST ) DEPTH)) 
(COND ((ATOM LIST) 
(MAPC 'PRINl (LIST '"ATOM:" LIST '"." 'DEPTH DEPTH)) 
(TERPRD) 
(T (SETQ TEMP (UNCONS LIST LIST)) 
(COND (LIST 
(SETQ RESTLIST (CONS(CONS LIST DEPTH) RESTLIST)))) 
(SETQ RESTLIST (CONS (CONS TEMP 

(ADDl DEPTH)) RESTLIST)) 
)))) 
(GO A)) 

Note the use of the now-deprecated goto (GO) statement, and the lack of consistent 
indentation conventions. The manual also gives a recursive version of the same 
program: 

(PROG NIL ( 
(LABEL ATOMPRINT (LAMBDA (RESTLIST) 
(COND ((NOT RESTLIST) (RETURN 'DONE)) 
((ATOM (CAAR RESTLIST)) (MAPC 'PRINl 

(LIST '"ATOM:" (CAAR RESTLIST) 

'"," 'DEPTH (CDAR RESTLIST))) 
(TERPRD 
(ATOMPRINT (CDR RESTLIST))) 
( . (ATOMPRINT (GRAFT 
(LIST (CONS (CAAAR RESTLIST) (ADDl (CDAR RESTLIST)))) 
(AND (CDAAR RESTLIST) (LIST (CONS (CDAAR RESTLIST) 

^Pronounced "see-loss." An alternate pronunciation, "klaus," seems to be losing favor. 


<a id='page-31'></a>
(CDAR RESTLIST)))) 
(COR RESTLIST))))))) 
(LIST (CONS (READ) 0)))) 

Both versions are very difficult to read. With our modern insight (and text editors 

that automatically indent), a much simpler program is possible: 

(defun atomprint (exp &optional (depth 0)) 
"Print each atom in exp. along with its depth of nesting." 
(if (atom exp) 

(format t ""SATOM: ~a, DEPTH "d" exp depth) 

(dolist (element exp) 
(atomprint element (+ depth 1))))) 

1.11 Exercises 
&#9635; Exercise 1.1 [m] Define a version of last-name that handles "Rex Morgan MD," 
"Morton Downey, Jr.," and whatever other cases you can think of. 

&#9635; Exercise 1.2 [m] Write a function to exponentiate, or raise a number to an integer 
power. For example: (power 3 2) = 3^ = 9. 

&#9635; Exercise 1.3 [m] Write a function that counts the number of atoms in an expression. 
For example: (count-atoms '(a (b) c)) = 3. Notice that there is something of an 
ambiguity in this: should (a nil c) count as three atoms, or as two, because it is 
equivalent to (a () c)? 

&#9635; Exercise 1.4 [m] Write a function that counts the number of times an expression 
occurs anywhere within another expression. Example: (count-anywhere 'a *(a 
((a) b) a)) 3. 

&#9635; Exercise 1.5 [m] Write a function to compute the dot product of two sequences 
of numbers, represented as lists. The dot product is computed by multiplying 
corresponding elements and then adding up the resulting products. Example: 

(dot-product ' (10 20) ' (3 4)) = 10 . 3 + 20 . 4 = 110 


<a id='page-32'></a>

1.12 Answers 
Answer 1.2 

(defun power (x n) 
"Power raises . to the nth power. . must be an integer >= 0. 
This executes in log . time, because of the check for even n. 

(cond ((= . 0) 1) 
((evenp n) (expt (power . (/ . 2)) 2)) 
(t (* . (power . (-. 1)))))) 

Answer 1.3 

(defun count-atoms (exp) 
"Return the total number of non-nil atoms in the expression." 
(cond ((null exp) 0) 

((atom exp) 1) 

(t (+ (count-atoms (first exp)) 
(count-atoms (rest exp)))))) 

(defun count-all-atoms (exp &optional (if-null 1)) 
"Return the total number of atoms in the expression, 
counting nil as an atom only in non-tail position." 
(cond ((null exp) if-null) 

((atom exp) 1) 

(t (+ (count-all-atoms (first exp) 1) 
(count-all-atoms (rest exp) 0))))) 

Answer 1.4 

(defun count-anywhere (item tree) 
"Count the times item appears anywhere within tree." 
(cond ((eql item tree) 1) 

((atom tree) 0) 
(t (+ (count-anywhere item (first tree)) 
(count-anywhere item (rest tree)))))) 


<a id='page-33'></a>
Answer 1.5 Here are three versions: 

(defun dot-product (a b) 
"Compute the mathematical dot product of two vectors." 
(if (or (null a) (null b)) 

0 
(+ (* (first a) (first b)) 
(dot-product (rest a) (rest b))))) 

(defun dot-product (a b) 
"Compute the mathematical dot product of two vectors." 
(let ((sum 0)) 

(dotimes (i (length a)) 
(incf sum (* (elt a i) (elt b i)))) 
sum)) 

(defun dot-product (a b) 
"Compute the mathematical dot product of two vectors." 
(apply #'+ (mapcar #'* a b))) 


## Chapter 2
<a id='page-34'></a>

### A Simple Lisp Program 

> *Cerium quod factum.*  
> (One is certain of only what one builds.) 
> 
> -Giovanni Battista Vico (1668-1744)  
> Italian royal historiographer 

You will never become proficient in a foreign language by studying vocabulary lists. 
Rather, you must hear and speak (or read and write) the language to gain proficiency. 
The same is true for learning computer languages. 

This chapter shows how to combine the basic functions and special forms of Lisp into a 
complete program. If you can learn how to do that, then acquiring the remaining vocabulary of 
Lisp (as outlined in chapter 3) will be easy. 


<a id='page-35'></a>
### 2.1 A Grammar for a Subset of English 
The program we will develop in this chapter generates random English sentences. 
Here is a simple grammar for a tiny portion of English: 

> *Sentence &rArr; Noun-Phrase + Verb-Phrase  
Noun-Phrase &rArr; Article + Noun  
Verb-Phrase &rArr; Verb + Noun-Phrase  
Article &rArr; the, a, ...  
Noun &rArr; man, ball, woman, table...  
Verb &rArr; hit, took, saw, liked...*

To be technical, this description is called a *context-free phrase-structure grammar,* and 
the underlying paradigm is called *generative syntax.* The idea is that anywhere we 
want a sentence, we can generate a noun phrase followed by a verb phrase. Anywhere 
a noun phrase has been specified, we generate instead an article followed by a noun. 
Anywhere an article has been specified, we generate either "the," "a," or some other 
article. The formalism is "context-free" because the rules apply anywhere regardless 
of the surrounding words, and the approach is "generative" because the rules as a 
whole define the complete set of sentences in a language (and by contrast the set of 
nonsentences as well). In the following we show the derivation of a single sentence 
using the rules: 


* To get a *Sentence,* append a *Noun-Phrase* and a *Verb-Phrase* 
  * To get a *Noun-Phrase*, append an *Article* and a *Noun* 
    * Choose *"the"* for the *Article* 
    * Choose *"man"* for the *Noun* 
  * The resulting *Noun-Phrase* is "the man" 
  * To get a *Verb-Phrase,* append a *Verb* and a *Noun-Phrase* 
    * Choose *"hit"* for the *Verb* 
    * To get a *Noun-Phrase*, append an *Article* and a *Noun* 
      * Choose *"the"* for the *Article* 
      * Choose *"ball"* for the *Noun* 
    * The resulting *Noun-Phrase* is "the ball" 
  * The resulting *Verb-Phrase* is "hit the ball" 
* The resulting Sentence is "The man hit the ball" 

### 2.2 A Straightforward Solution 
We will develop a program that generates random sentences from a phrase-structure 
grammar. The most straightforward approach is to represent each grammar rule by 
a separate Lisp function: 


<a id='page-36'></a>

```lisp
(defun sentence ()    (append (noun-phrase) (verb-phrase))) 
(defun noun-phrase () (append (Article) (Noun))) 
(defun verb-phrase () (append (Verb) (noun-phrase))) 
(defun Article ()     (one-of '(the a))) 
(defun Noun ()        (one-of '(man ball woman table)) ) 
(defun Verb ()        (one-of '(hit took saw liked)) ) 
```

Each of these function definitions has an empty parameter list, `()`. That means the 
functions take no arguments. This is unusual because, strictly speaking, a function 
with no arguments would always return the same thing, so we would use a constant 
instead. However, these functions make use of the `random` function (as we will see 
shortly), and thus can return different results even with no arguments. Thus, they 
are not functions in the mathematical sense, but they are still called functions in Lisp, 
because they return a value. 

All that remains now is to define the function `one-of`. It takes a list of possible 
choices as an argument, chooses one of these at random, and returns a one-element 
list of the element chosen. This last part is so that all functions in the grammar will 
return a list of words. That way, we can freely apply append to any category. 

```lisp
(defun one-of (set) 
  "Pick one element of set, and make a list of it." 
  (list (random-elt set))) 

(defun random-elt (choices) 
  "Choose an element from a list at random." 
  (elt choices (random (length choices)))) 
```

There are two new functions here, `elt` and `random`, `elt` picks an element out of a list. 
The first argument is the list, and the second is the position in the list. The confusing 
part is that the positions start at 0, so `(elt choices 0)` is the first element of the list, 
and `(elt choices 1)` is the second. Think of the position numbers as telling you 
how far away you are from the front. The expression `(random n)` returns an integer 
from 0 to n-1, so that `(random 4)` would return either 0, 1, 2, or 3. 

Now we can test the program by generating a few random sentences, along with 
a noun phrase and a verb phrase: 


<a id='page-37'></a>

```lisp
> (sentence) => (THE WOMAN HIT THE BALL) 

> (sentence) => (THE WOMAN HIT THE MAN) 

> (sentence) =>(THE BALL SAW THE WOMAN) 

> (sentence) => (THE BALL SAW THE TABLE) 

> (noun-phrase) => (THE MAN) 

> (verb-phrase) => (LIKED THE WOMAN) 

> (trace sentence noun-phrase verb-phrase article noun verb) => 
(SENTENCE NOUN-PHRASE VERB-PHRASE ARTICLE NOUN VERB) 

> (sentence) => 
(1 ENTER SENTENCE) 
  (1 ENTER NOUN-PHRASE) 
    (1 ENTER ARTICLE) 
    (1 EXIT ARTICLE: (THE)) 
    (1 ENTER NOUN) 
    (1 EXIT NOUN: (MAN)) 
  (1 EXIT NOUN-PHRASE: (THE MAN)) 
  (1 ENTER VERB-PHRASE) 
    (1 ENTER VERB) 
    (1 EXIT VERB: (HIT)) 
    (1 ENTER NOUN-PHRASE) 
      (1 ENTER ARTICLE) 
      (1 EXIT ARTICLE: (THE)) 
      (1 ENTER NOUN) 
      (1 EXIT NOUN: (BALL) 
    (1 EXIT NOUN-PHRASE: (THE BALL) 
  (1 EXIT VERB-PHRASE: (HIT THE BALL) 
(1 EXIT SENTENCE: (THE MAN HIT THE BALL) 
(THE MAN HIT THE BALL) 
```

The program works fine, and the trace looks just like the sample derivation above, 
but the Lisp definitions are a bit harder to read than the original grammar rules. 
This problem will be compounded as we consider more complex rules. Suppose we 
wanted to allow noun phrases to be modified by an indefinite number of adjectives 
and an indefinite number of prepositional phrases. In grammatical notation, we 
might have the following rules: 

> *Noun-Phrase &rArr; Article + Adj\* + Noun + PP\*  
> Adj\* &rArr; 0&#x0338;, Adj + Adj\*  
> PP\* &rArr; 0&#x0338;, PP + PP\*  
> PP &rArr; Prep + Noun-Phrase  
> Adj &rArr; big, little, blue, green, ...  
> Prep &rArr; to, in, by, with, ...*


In this notation, 0&#x0338; indicates a choice of nothing at all, a comma indicates a choice of 
several alternatives, and the asterisk is nothing special—as in Lisp, it's just part of the 
name of a symbol. However, the convention used here is that names ending in an 
asterisk denote zero or more repetitions of the underlying name. That is, *PP*\* denotes 
zero or more repetitions of *PP.* This is known as "Kleene star" notation (pronounced 

<a id='page-38'></a>
"clean-E") after the mathematician Stephen Cole Kleene.[TK - fn1] 
The problem is that the rules for Adj * and PP * contain choices that we would have 
to represent as some kind of conditional in Lisp. For example: 

```lisp
(defun Adj* () 
  (if (= (random 2) 0) 
      nil 
      (append (Adj) (Adj*)))) 

(defun PP* () 
  (if (random-elt '(t nil)) 
      (append (PP) (PP*)) 
      nil)) 

(defun noun-phrase () (append (Article) (Adj*) (Noun) (PP*))) 
(defun PP () (append (Prep) (noun-phrase))) 
(defun Adj () (one-of '(big little blue green adiabatic))) 
(defun Prep () (one-of '(to in by with on))) 
```

I've chosen two different implementations for `Adj*` and `PP*`; either approach would 
work in either function. We have to be careful, though; here are two approaches that 
would not work: 

```lisp
(defun Adj* () 
  "Warning - incorrect definition of Adjectives." 
  (one-of '(nil (append (Adj) (Adj*))))) 

(defun Adj* () 
  "Warning - incorrect definition of Adjectives." 
  (one-of (list nil (append (Adj) (Adj*))))) 
```

The first definition is wrong because it could return the literal expression `((append (Adj) (Adj *)))` 
rather than a list of words as expected. The second definition would 
cause infinite recursion, because computing the value of `(Adj*)` always involves a 
recursive call to `(Adj*)`. The point is that what started out as simple functions are 
now becoming quite complex. To understand them, we need to know many Lisp 
conventions—`defun`, `()`, `case`, `if`, `quote`, and the rules for order of evaluation—when 
ideally the implementation of a grammar rule should use only *linguistic* conventions. 
If we wanted to develop a larger grammar, the problem could get worse, because the 
rule-writer might have to depend more and more on Lisp. 

[TK, fn1] We will soon see "Kleene plus" notation, wherein *PP+* denotes one or more repetitions 
of *PP.* 


<a id='page-39'></a>
### 2.3 A Rule-Based Solution 
An alternative implementation of this program v^ould concentrate on making it easy 
to write grammar rules and would worry later about how they will be processed. 
Let's look again at the original grammar rules: 

> *Sentence &rArr; Noun-Phrase + Verb-Phrase  
Noun-Phrase &rArr; Article + Noun  
Verb-Phrase &rArr; Verb + Noun-Phrase  
Article &rArr; the, a, ...  
Noun &rArr; man, ball, woman, table...  
Verb &rArr; hit, took, saw, liked...*

Each rule consists of an arrow with a symbol on the left-hand side and something on 
the right-hand side. The complication is that there can be two kinds of right-hand 
sides: a concatenated list of symbols, as in *"Noun-Phrase &rArr; Article+Noun,"* or a list of 
alternate words, as in *"Noun => man, ball, ..."* We can account for these possibilities 
by deciding that every rule will have a list of possibilities on the right-hand side, and 
that a concatenated list, *for example "Article+Noun,"* will be represented as a Lisp list, 
*for example* "`(Article Noun)`". The list of rules can then be represented as follows: 

```lisp
(defparameter *simple-grammar* 
  '((sentence -> (noun-phrase verb-phrase)) 
    (noun-phrase -> (Article Noun)) 
    (verb-phrase -> (Verb noun-phrase)) 
    (Article -> the a) 
    (Noun -> man ball woman table) 
    (Verb -> hit took saw liked)) 
  "A grammar for a trivial subset of English.") 

(defvar *grammar* *simple-grammar* 
  "The grammar used by generate. Initially, this is 
  *simple-grammar*, but we can switch to other grammars.") 
```

Note that the Lisp version of the rules closely mimics the original version. In particular, 
I include the symbol "`->`", even though it serves no real purpose; it is purely 
decorative. 

The special forms `defvar` and `defparameter` both introduce special variables 
and assign a value to them; the difference is that a *variable,* like `*grammar*`, is 
routinely changed during the course of running the program. A *parameter,* like 
`*simple-grammar*`, on the other hand, will normally stay constant. A change to a 
parameter is considered a change to the program, not a change *by* the program. 

Once the list of rules has been defined, it can be used to find the possible rewrites 
of a given category symbol. The function `assoc` is designed for just this sort of task. 


<a id='page-40'></a>

It takes two arguments, a "key" and a list of lists, and returns the first element of the 
list of lists that starts with the key. If there is none, it returns `nil`. Here is an example: 

```lisp
> (assoc 'noun *grammar*) (NOUN -> MAN BALL WOMAN TABLE) 
```

Although rules are quite simply implemented as lists, it is a good idea to impose a 
layer of abstraction by defining functions to operate on the rules. We will need three 
functions: one to get the right-hand side of a rule, one for the left-hand side, and one 
to look up all the possible rewrites (right-hand sides) for a category. 

```lisp
(defun rule-lhs (rule) 
  "The left-hand side of a rule." 
  (first rule)) 

(defun rule-rhs (rule) 
  "The right-hand side of a rule." 
  (rest (rest rule))) 

(defun rewrites (category) 
  "Return a list of the possible rewrites for this category." 
  (rule-rhs (assoc category *grammar*))) 
```

Defining these functions will make it easier to read the programs that use them, 
and it also makes changing the representation of rules easier, should we ever decide 
to do so. 

We are now ready to address the main problem: defining a function that will 
generate sentences (or noun phrases, or any other category). We will call this function 
`generate`. It will have to contend with three cases: (1) In the simplest case, `generate` 
is passed a symbol that has a set of rewrite rules associated with it. We choose one of 
those at random, and then generate from that. (2) If the symbol has no possible rewrite 
rules, it must be a terminal symbol—a word, rather than a grammatical category—and 
we want to leave it alone. Actually, we return the list of the input word, because, as 
in the previous program, we want all results to be lists of words. (3) In some cases, 
when the symbol has rewrites, we will pick one that is a list of symbols, and try to 
generate from that. Thus, `generate` must also accept a list as input, in which case 
it should generate each element of the list, and then append them all together. In 
the following, the first clause in `generate` handles this case, while the second clause 
handles (1) and the third handles (2). Note that we used the `mappend` function from 
section 1.7 ([page 18](chapter1.md#page-18)). 


<a id='page-41'></a>

```lisp
(defun generate (phrase) 
  "Generate a random sentence or phrase" 
  (cond ((listp phrase) 
        (mappend #'generate phrase)) 
        ((rewrites phrase) 
         (generate (random-elt (rewrites phrase)))) 
        (t (list phrase)))) 
```

Like many of the programs in this book, this function is short, but dense with 
information: the craft of programming includes knowing what *not* to write, as well 
as what to write. 

This style of programming is called *data-driven* programming, because the data 
(the list of rewrites associated with a category) drives what the program does next. It 
is a natural and easy-to-use style in Lisp, leading to concise and extensible programs, 
because it is always possible to add a new piece of data with a new association without 
having to modify the original program. 

Here are some examples of `generate` in use: 

```lisp
> (generate 'sentence) => (THE TABLE SAW THE BALL) 

> (generate 'sentence) => (THE WOMAN HIT A TABLE) 

> (generate 'noun-phrase) => (THE MAN) 

> (generate 'verb-phrase) (TOOK A TABLE) 
```

There are many possible ways to write `generate`. The following version uses `if` 
instead of `cond`: 

```lisp
(defun generate (phrase) 
  "Generate a random sentence or phrase" 
  (if (listp phrase) 
      (mappend #'generate phrase) 
      (let ((choices (rewrites phrase))) 
        (if (null choices) 
            (list phrase) 
            (generate (random-elt choices)))))) 
```

This version uses the special form `let`, which introduces a new variable (in this case, 
`choices`) and also binds the variable to a value. In this case, introducing the variable 
saves us from calling the function `rewrites` twice, as was done in the `cond` version 
of `generate`. The general form of a `let` form is: 

> `(let` ((var value)...)  
> &nbsp;&nbsp; body-containing-vars)*

`let` is the most common way of introducing variables that are not parameters of 
functions. One must resist the temptation to use a variable without introducing it: 


<a id='page-42'></a>

```lisp
(defun generate (phrase) 
  (setf choices ...)         ;; wrong! 
  ... choices ...) 
```

This is wrong because the symbol `choices` now refers to a special or global variable, 
one that may be shared or changed by other functions. Thus, the function `generate` 
is not reliable, because there is no guarantee that `choices` will retain the same value 
from the time it is set to the time it is referenced again. With `let` we introduce a brand 
new variable that nobody else can access; therefore it is guaranteed to maintain the 
proper value. 

&#9635; Exercise 2.1 [m] Write a version of `generate` that uses `cond` but avoids calling 
`rewrites` twice. 

&#9635; Exercise 2.2 [m] Write a version of `generate` that explicitly differentiates between 
terminal symbols (those with no rewrite rules) and nonterminal symbols. 

### 2.4 Two Paths to Follow 
The two versions of the preceding program represent two alternate approaches that 
come up time and time again in developing programs: (1) Use the most straightforward 
mapping of the problem description directly into Lisp code. (2) Use the most 
natural notation available to solve the problem, and then worry about writing an 
interpreter for that notation. 

Approach (2) involves an extra step, and thus is more work for small problems. 
However, programs that use this approach are often easier to modify and expand. 
This is especially true in a domain where there is a lot of data to account for. The 
grammar of natural language is one such domain—in fact, most AI problems fit this 
description. The idea behind approach (2) is to work with the problem as much as 
possible in its own terms, and to minimize the part of the solution that is written 
directly in Lisp. 

Fortunately, it is very easy in Lisp to design new notations—in effect, new programming 
languages. Thus, Lisp encourages the construction of more robust programs. 
Throughout this book, we will be aware of the two approaches. The reader may 
notice that in most cases, we choose the second. 


<a id='page-43'></a>
### 2.5 Changing the Grammar without Changing the Program 
We show the utility of approach (2) by defining a new grammar that includes adjectives, 
prepositional phrases, proper names, and pronouns. We can then apply the 
`generate` function without modification to this new grammar. 

```lisp
(defparameter *bigger-grammar* 
  '((sentence -> (noun-phrase verb-phrase)) 
    (noun-phrase -> (Article Adj* Noun PP*) (Name) (Pronoun)) 
    (verb-phrase -> (Verb noun-phrase PP*)) 
    (PP* -> () (PP PP*)) 
    (Adj* -> () (Adj Adj*)) 
    (PP -> (Prep noun-phrase)) 
    (Prep -> to in by with on) 
    (Adj -> big little blue green adiabatic) 
    (Article -> the a) 
    (Name -> Pat Kim Lee Terry Robin) 
    (Noun -> man ball woman table) 
    (Verb -> hit took saw liked) 
    (Pronoun -> he she it these those that))) 

(setf *grammar* *bigger-grammar*) 

> (generate 'sentence) 
(A TABLE ON A TABLE IN THE BLUE ADIABATIC MAN SAW ROBIN 
 WITH A LITTLE WOMAN) 

> (generate 'sentence) 
(TERRY SAW A ADIABATIC TABLE ON THE GREEN BALL BY THAT WITH KIM 
 IN THESE BY A GREEN WOMAN BY A LITTLE ADIABATIC TABLE IN ROBIN 
 ON LEE) 

> (generate 'sentence) 
(THE GREEN TABLE HIT IT WITH HE) 
```

Notice the problem with case agreement for pronouns: the program generated "with 
he," although "with him" is the proper grammatical form. Also, it is clear that the 
program does not distinguish sensible from silly output. 

### 2.6 Using the Same Data for Several Programs 
Another advantage of representing information in a declarative form-as rules or 
facts rather than as Lisp functions-is that it can be easier to use the information for 
multiple purposes. Suppose we wanted a function that would generate not just the 

<a id='page-44'></a>
list of words in a sentence but a representation of the complete syntax of a sentence. 
For example, instead of the list `(a woman took a ball)`, we want to get the nested list: 

```lisp
(SENTENCE (NOUN-PHRASE (ARTICLE A) (NOUN WOMAN)) 
          (VERB-PHRASE (VERB TOOK) 
                       (NOUN-PHRASE (ARTICLE A) (NOUN BALL)))) 
```

This corresponds to the tree that linguists draw as in figure 2.1. 

```
TK: diagram
sentence 

art noun verb art noun 
I I I I I 
a woman took a ball 
```

Figure 2.1: Sentence Parse Tree 

Using the "straightforward functions" approach we would be stuck; we'd have to 
rewrite every function to generate the additional structure. With the "new notation" 
approach we could keep the grammar as it is and just write one new function: a 
version of `generate` that produces nested lists. The two changes are to `cons` the 
category onto the front of each rewrite, and then not to append together the results 
but rather just list them with `mapcar`: 

```lisp
(defun generate-tree (phrase) 
  "Generate a random sentence or phrase, 
  with a complete parse tree." 
  (cond ((listp phrase) 
         (mapcar #'generate-tree phrase)) 
        ((rewrites phrase) 
         (cons phrase 
               (generate-tree (random-elt (rewrites phrase))))) 
        (t (list phrase)))) 
```

Here are some examples: 


<a id='page-45'></a>

```lisp
> (generate-tree 'Sentence) 
(SENTENCE (NOUN-PHRASE (ARTICLE A) 
                       (ADJ*) 
                       (NOUN WOMAN) 
                       (PP*)) 
      (VERB-PHRASE (VERB HIT) 
                       (NOUN-PHRASE (PRONOUN HE)) 
                       (PP*))) 

> (generate-tree 'Sentence) 
(SENTENCE (NOUN-PHRASE (ARTICLE A) 
                       (NOUN WOMAN)) 
          (VERB-PHRASE (VERB TOOK) 
                       (NOUN-PHRASE (ARTICLE A) (NOUN BALL)))) 
```

As another example of the one-data/multiple-program approach, we can develop a 
function to generate all possible rewrites of a phrase. The function `generate-all`  
returns a list of phrases rather than just one, and we define an auxiliary function, 
`combine-all`, to manage the combination of results. Also, there are four cases instead 
of three, because we have to check for nil explicitly. Still, the complete program is 
quite simple: 

```lisp
(defun generate-all (phrase) 
  "Generate a list of all possible expansions of this phrase." 
  (cond ((null phrase) (list nil)) 
        ((listp phrase) 
         (combine-all (generate-all (first phrase)) 
                      (generate-all (rest phrase)))) 
        ((rewrites phrase) 
         (mappend #'generate-all (rewrites phrase))) 
        (t (list (list phrase))))) 

(defun combine-all (xlist ylist) 
  "Return a list of lists formed by appending a y to an x. 
  E.g., (combine-all '((a) (b)) '((1) (2))) 
  -> ((A 1) (B 1) (A 2) (B 2))." 
  (mappend #'(lambda (y) 
               (mapcar #'(lambda (x) (append . y)) xlist)) 
           ylist)) 
```

We can now use `generate-all` to test our original little grammar. Note that a serious 
drawback of `generate-all` is that it can't deal with recursive grammar rules like 
`Adj* => Adj + Adj*` that appear in `*bigger-grammar*`, since these lead to an infinite 
number of outputs. But it works fine for finite languages, like the language generated 
by `*simple-grammar*`: 


<a id='page-46'></a>

```lisp
> (generate-all 'Article) 

((THE) (A)) 

> (generate-all 'Noun) 

((MAN) (BALL) (WOMAN) (TABLE)) 

> (generate-all 'noun-phrase) 
((A MAN) (A BALL) (A WOMAN) (A TABLE) 
 (THE MAN) (THE BALL) (THE WOMAN) (THE TABLE)) 

> (length (generate-all 'sentence)) 
256 
```

There are 256 sentences because every sentence in this language has the form Article-
Noun-Verb-Article-Noun, and there are two articles, four nouns and four verbs 
(2 &times; 4 &times; 4 &times; 2 &times; 4 = 256). 

### 2.7 Exercises 
&#9635; Exercise 2.3 [h] Write a trivial grammar for some other language. This can be a 
natural language other than English, or perhaps a subset of a computer language. 

&#9635; Exercise 2.4 [m] One way of describing `combine-all` is that it calculates the cross-product 
of the function a ppend on the argument lists. Write the higher-order function 
`cross-product`, and define `combine-all` in terms of it. \
The moral is to make your code as general as possible, because you never know what 
you may want to do with it next. 

### 2.8 Answers 
#### Answer 2.1 
```lisp
  (defun generate (phrase) 
  "Generate a random sentence or phrase" 
  (let ((choices nil)) 
    (cond ((listp phrase) 
        (mappend #'generate phrase)) 
       ((setf choices (rewrites phrase)) 
        (generate (random-elt choices))) 
       (t (list phrase))))) 
```


<a id='page-47'></a>
#### Answer 2.2 

```lisp
(defun generate (phrase) 
  "Generate a random sentence or phrase" 
  (cond ((listp phrase) 
         (mappend #'generate phrase)) 
        ((non-terminal-p phrase) 
         (generate (random-elt (rewrites phrase)))) 
        (t (list phrase)))) 

(defun non-terminal-p (category) 
  "True if this is a category in the grammar." 
  (not (null (rewrites category)))) 
```

#### Answer 2.4 
```lisp
(defun cross-product (fn xlist ylist) 
  "Return a list of all (fn . y) values." 
  (mappend #'(lambda (y) 
               (mapcar #'(lambda (x) (funcall fn x y)) 
                       xlist)) 
           ylist)) 

(defun combine-all (xlist ylist) 
  "Return a list of lists formed by appending a y to an x" 
  (cross-product #'append xlist ylist)) 
```

Now we can use the `cross-product` in other ways as well: 

```
> (cross-product #'+ '(1 2 3) '(10 20 30)) 
(11 12 13 
 21 22 23 
 31 32 33) 

> (cross-product #'list '(a b c d e f g h) 
                        '(1 2 3 4 5 6 7 8)) 
((A 1) (B 1) (C 1) (D 1) (E 1) (F 1) (G 1) (H 1) 
 (A 2) (B 2) (C 2) (D 2) (E 2) (F 2) (G 2) (H 2) 
 (A 3) (B 3) (C 3) (D 3) (E 3) (F 3) (G 3) (H 3) 
 (A 4) (B 4) (C 4) (D 4) (E 4) (F 4) (G 4) (H 4) 
 (A 5) (B 5) (C 5) (D 5) (E 5) (F 5) (G 5) (H 5) 
 (A 6) (B 6) (C 6) (D 6) (E 6) (F 6) (G 6) (H 6) 
 (A 7) (B 7) (C 7) (D 7) (E 7) (F 7) (G 7) (H 7) 
 (A 8) (B 8) (C 8) (D 8) (E 8) (F 8) (G 8) (H 8)) 
```


## Chapter 3
<a id='page-48'></a>

Overview of Lisp 

No doubt about it. Common Lisp is a big language. 

—Guy L. Steele, Jr. 
Foreword to Koschman 1990 

I 1 his chapter briefly covers the most important special forms and functions in Lisp. It 
can be safely skipped or skimmed by the experienced Common Lisp programmer 

but is required reading for the novice Lisp progranuner, or one who is new to the 
Common Lisp dialect. 

r. 

This chapter can be used as a reference source, but the definitive reference is Steele's Common 
Lisp the Language, 2d edition, which should be consulted whenever there is any confusion. Since 
that book is 25 times longer than this chapter, it is clear that we can only touch on the important 
highlights here. More detailed coverage is given later in this book as each feature is used in a 
real program. 


<a id='page-49'></a>
3.1 A Guide to Lisp Style 
The beginning Common Lisp programmer is often overwhelmed by the number of 
options that the language provides. In this chapter we show fourteen different ways 
to find the length of a list. How is the programmer to choose between them? One 
answer is by reading examples of good programs—as illustrated in this book—and 
copying that style. In general, there are six maxims that every programmer should 
follow: 

* Be specific. 
* Use abstractions. 
* Be concise. 
* Use the provided tools. 
* Don't be obscure. 
* Be consistent. 
These require some explanation. 

Using the most specific form possible makes it easier for your reader to understand 
your intent. For example, the conditional special form when is more specific than i f. 
The reader who sees a when knows to look for only one thing: the clause to consider 
when the test is true. The reader who sees an i f can rightfully expect two clauses: 
one for when the test is true, and one for when it is false. Even though it is possible 
to use i f when there is only one clause, it is preferable to use when, because when is 
more specific. 

One important way of being specific is using abstractions. Lisp provides very 
general data structures, such as lists and arrays. These can be used to implement 
specific data structures that your program will use, but you should not make the 
mistake of invoking primitive functions directly. If you define a list of names: 

(defvar *names* '((Robert E. Lee) ...)) 

then you should also define functions to get at the components of each name. To get 
at Lee,use (last-name (first *names*)),not (caddar *names*). 

Often the maxims are in concord. For example, if your code is trying to find an 
element in a list, you should use f 1 nd (or maybe f 1 nd-1 f), not 1 oop or do. f i nd is 
more specific than the general constructs 1 oop or do, it is an abstraction, it is more 
concise, it is a built-in tool, and it is simple to understand. 


<a id='page-50'></a>

Sometimes, however, the maxims are in confUct, and experience will tell you 
which one to prefer. Consider the following two ways of placing a new key/value 
pair on an association list:^ 

(push (cons key val) a-list) 
(setf a-list (aeons key val a-list)) 

The first is more concise. But the second is more specific, as it uses the aeons 
function, which is designed specifically for association lists. The decision between 
them probably hinges on obscurity: those who find aeons to be a familiar function 
would prefer the second, and those who find it obscure would prefer the first. 

A similar choice arises in the question of setting a variable to a value. Some prefer 
(setq X val) because it is most specific; others use (setf . val), feeling that it is 
more consistent to use a single form, setf, for all updating. Whichever choice you 
make on such issues, remember the sixth maxim: be consistent. 

3.2 Special Forms 
As noted in chapter 1, "special form" is the term used to refer both to Common Lisp's 
syntactic constructs and the reserved words that mark these constructs. The most 
commonly used special forms are: 

definitions conditional variables iteration other 
defun and let do declare 
defstruct case let* do* function 
defvar cond pop dolist progn 
defparameter if push dotimes quote 
defconstant or setf loop return 
defmacro unless incf trace 
labels when decf untrace 

To be precise, only declare, function. If, labels, let, let*, progn and quote 
are true special forms. The others are actually defined as macros that expand into 
calls to more primitive special forms and functions. There is no real difference to the 
programmer, and Common Lisp implementations are free to implement macros as 
special forms and vice versa, so for simplicity we will continue to use "special form" 
as a blanket term for both true special forms and built-in macros. 

^Association lists are covered in section 3.6. 


<a id='page-51'></a>
Special Forms for Definitions 

In this section we survey the special forms that can be used to introduce new global 
functions, macros, variables, and structures. We have already seen the defun form 
for defining functions; the def macro form is similar and is covered on [page 66](chapter3.md#page-66). 

(defun function-name (parameter...) " optional documentation" body...) 

(defmacro macro-name (parameter...) "optional documentation" body...) 

There are three forms for introducing special variables, defvar defines a special 
variable and can optionally be used to supply an initial value and a documentation 
string. The initial value is evaluated and assigned only if the variable does not yet 
have any value, def pa rameter is similar, except that the value is required, and it will 
be used to change any existing value, def constant is used to declare that a symbol 
will always stand for a particular value. 

(defvar vanable-name initial-value "optional documentation") 
(defparameter vanable-name value "optional documentation") 
(def constant variable-name value "optional documentation") 

All the def - forms define global objects. It is also possible to define local variables 
with let, and to define local functions with label s, as we shall see. 

Most programming languages provide a way to group related data together into 
a structure. Common Lisp is no exception. The def struct special form defines a 
structure type (known as a record type in Pascal) and automatically defines functions 
to get at components of the structure. The general syntax is: 

(def struct structure-name "optional documentation" slot...) 

As an example, we could define a structure for names: 

(defstruct name 
first 
(middle nil) 
last) 

This automatically defines the constructor function make-name, the recognizer predicate 
name-p, and the accessor functions name-first, name-middle and name-last. 
The (middle nil) means that each new name built by make-name will have a middle 
name of ni 1 by default. Here we create, access, and modify a structure: 


<a id='page-52'></a>

> (setf b (make-name :first 'Barney :last 'Rubble)) => 
#S(NAME :FIRST BARNEY :LAST RUBBLE) 

> (name-first b) ^ BARNEY 

> (name-middle b) NIL 

> (name-last b) ^ RUBBLE 

> (name-p b) =. . 

> (name-p 'Barney) =. NIL ; only the results of make-name are names 

> (setf (name-middle b) 'Q) => Q 

> b #S(NAME :FIRST BARNEY .-MIDDLE Q :LAST RUBBLE) 

The printed representation of a structure starts with a #S and is followed by a list 
consisting of the type of the structure and alternating pairs of slot names and values. 
Do not let this representation fool you: it is a convenient way of printing the structure, 
but it is not an accurate picture of the way structures are represented internally. 
Structures are actually implemented much like vectors. For the name structure, the 
type would be in the zero element of the vector, the first name in the first element, 
middle in the second, and last in the third. This means structures are more efficient 
than lists: they take up less space, and any element can be accessed in a single step. 
In a list, it takes . steps to access the nth element. 

There are options that give more control over the structure itself and the individual 
slots. They will be covered later as they come up. 

Special Forms for Conditionals 

We have seen the special form i f, which has the form (i f test then-part else-part), 
where either the then-part or the else-part is the value, depending on the success of the 
test. Remember that only . i 1 counts as false; all other values are considered true for 
the purpose of conditionals. However, the constant t is the conventional value used 
to denote truth (unless there is a good reason for using some other value). 

There are actually quite a few special forms for doing conditional evaluation. 
Technically, i f is defined as a special form, while the other conditionals are macros, 
so in some sense 1 f is supposed to be the most basic. Some programmers prefer to 
use i f for most of their conditionals; others prefer cond because it has been around 
the longest and is versatile (if not particularly pretty). Finally, some programmers opt 
for a style more like English prose, and freely use when, unl ess, 1 f, and all the others. 

The following table shows how each conditional can be expressed in terms of 
1 f and cond. Actually, these translations are not quite right, because or, case, and 
cond take care not to evaluate any expression more than once, while the translations 
with i f can lead to multiple evaluation of some expressions. The table also has 


<a id='page-53'></a>
translations to cond. The syntax of cond is a series of cond-clauses, each consisting of 
a test expression followed by any number of result expressions: 

(cond {testresult...) 
{test result...) 

...) 

cond goes through the cond-clauses one at a time, evaluating each test expression. 
As soon as a test expression evaluates non-nil, the result expressions for that clause 
are each evaluated, and the last expression in the clause is the value of the whole 
cond. In particular, if a cond-clause consists of just a test and no result expressions, 
then the value of the cond is the test expression itself, if it is non-nil. If all of the test 
expressions evaluate to nil, then nil is returned as the value of the cond. A common 
idiom is to make the last cond-clause be (t result...). 

The forms when and unl ess operate like a single cond clause. Both forms consist 
of a test followed by any number of consequents, which are evaluated if the test is 
satisfied-that is, if the test is true for when or false for unl ess. 

The and form tests whether every one of a list of conditions is true, and or tests 
whether any one is true. Both evaluate the arguments left to right, and stop as soon 
as the final result can be determined. Here is a table of equivalences: 

conditional if form cond form 
(when test ah c) (if test (progn a be)) (cond {testaba)) 
(unless testxy) (if {nottest) (progn xy)) (cond {{not test) xy)) 
(and abc) (if a (if b c)) (cond(fl (cond {be)))) 
(or ahc) (if a a (if b b c)) (cond (a) {b) (c)) 
(case a {b c) (t x)) (if (eql a 'b) c x) (cond ((eql a 'b)c) {tx)) 

It is considered poor style to use and and or for anything other than testing a 
logical condition, when, unl ess, and 1 f can all be used for taking conditional action. 
For example: 

(and (> . 100) 
(princ "N is large.")) ; Bad style! 

(or (<= . 100) 
(princ "N is large.")) ; Even worse style! 

(cond ((> . 100) ; OK. but not MY preference 
(princ "N is large.")) 

(when (> . 100) 
(princ "N is large.")) ; Good style. 

When the main purpose is to return a value rather than take action, cond and i f 
(with explicit . i 1 in theelsecase)are preferred overwhenandunl ess, which implicitly 


<a id='page-54'></a>

return nil in the else case, when and unl ess are preferred when there is only one 
possibility, i f (or, for some people, cond) when there are two, and cond when there 
are more than two: 

(defun tax-bracket (income) 

"Determine what percent tax should be paid for this income." 

(cond ((< income 10000.00) 0.00) 

((< income 30000.00) 0.20) 
((< income 50000.00) 0.25) 
((< income 70000.00) 0.30) 
(t 0.35))) 

If there are several tests comparing an expression to constants, then case is appropriate. 
A case form looks like: 

(case expression 
(matchresult..)...) 

The expression is evaluated and compared to each successive match. As soon as one 
is eql, the result expressions are evaluated and the last one is returned. Note that the 
match expressions are not evaluated. If a match expression is a list, then case tests if 
the expression is eql to any member of the list. If a match expression is the symbol 
otherwi se (or the symbol t), then it matches anything. (It only makes sense for this 
otherwl se clause to be the last one.) 

There is also another special form, typecase, which compares the type of an 
expression against several possibilities and, like case, chooses the first clause that 
matches. In addition, the special forms ecase and etypecase are just like case and 
typecase except that they signal an error if there is no match. You can think of the e 
as standing for either "exhaustive" or "error." The forms cease and etypecase also 
signal errors, but they can be continuable errors (as opposed to fatal errors): the user 
is offered the chance to change the expression to something that satisfies one of the 
matches. Here are some examples of case forms and their cond equivalents: 

(case . (cond 
(1 10) ((eql . 1) 10) 
(2 20)) ((eql . 2) 20)) 
(typecase . (cond 
(number (abs x)) ((typep . 'number) (abs x)) 
(list (length x))) ((typep . 'list ) (length x))) 
(ecase . (cond 
(1 10) ((eql . 1) 10) 
(2 20)) ((eql . 2) 20) 
(t (error "no valid case"))) 


<a id='page-55'></a>
(etypecase . (cond 
(number (abs .)) ((typep . 'number) (abs x)) 
(list (length x))) ((typep . 'list ) (length x)) 
(t (error "no valid typecase"))) 

Special Forms for Dealing with Variables and Places 

The special form setf is used to assign a new value to a variable or place, much as an 
assignment statement with = or := is used in other languages. A place, or generalized 
variable is a name for a location that can have a value stored in it. Here is a table of 
corresponding assignment forms in Lisp and Pascal: 

Lisp /* Pascal */ 
(setf . 0) . := 0; 
(setf (aref A i j) 0) A[i,j] := 0; 
(setf (rest list ) nil) list\res t := nil ; 
(setf (name-middle b) 'Q) b\middle := "Q"; 

setf can be used to set a component of a structure as well as to set a variable. In 
languages like Pascal, the expressions that can appear on the left-hand side of an 
assignment statement are limited by the syntax of the language. In Lisp, the user can 
extend the expressions that are allowed in a s etf form using the special forms defs et f 
or define-setf-method. These are introduced on pages [514](chapter15.md#page-514) and [884](chapter25.md#page-884) respectively. 

There are also some built-in functions that modify places. For example, (rpl a cd 
list nil) has the same effect as (setf (rest list) nil), except that it returns 
list instead of ni 1. Most Common Lisp programmers prefer to use the setf forms 
rather than the specialized functions. 

If you only want to set a variable, the special form setq can be used instead. In 
this book I choose to use setf throughout, opting for consistency over specificity. 

The discussion in this section makes it seem that variables (and slots of structures) 
are assigned new values all the time. Actually, many Lisp programs do no 
assignments whatsoever. It is very common to use Lisp in a functional style where 
new variables may be introduced, but once a new variable is established, it never 
changes. One way to introduce a new variable is as a parameter of a function. It 
is also possible to introduce local variables using the special form let. Following 
are the general let form, along with an example. Each variable is bound to the 
corresponding value, and then the body is evaluated: 


<a id='page-56'></a>

(let((variablevalue)..,) (let ((x 40) 
body...) (y (+ 1 1))) 
(+ X y)) 42 

Defining a local variable with a let form is really no different from defining parameters 
to an anonymous function. The former is equivalent to: 

((lambdei(variable..,) ((lambda (x y) 
body...) (+ X y)) 
value..,) 40 

(+ 1 D) 

First, all the values are evaluated. Then they are bound to the variables (the parameters 
of the lambda expression), and finally the body is evaluated, using those 
bindings. 

The special form let* is appropriate when you want to use one of the newly 
introduced variables in a subsequent value computation. For example: 

(let* ((x 6) 
(y (* . .))) 
(+ . y)) 42 

We could not have used let here, because then the variable . would be unbound 

during the computation of y's value. 

&#9635; Exercise 3.1 [m] Show a lambda expression that is equivalent to the above let* 
expression. You may need more than one lambda. 

Because lists are so important to Lisp, there are special forms for adding and 
deleting elements from the front of a list—in other words, for treating a list as a stack. 
If 1 i st is the name of a location that holds a list, then (push A: 1 i st) will change 1 i st 
to have . as its first element, and (pop 1 i st) will return the first element and, as 
a side-effect, change 1 i st to no longer contain the first element, push and pop are 
equivalent to the following expressions: 

(push . list) = (setf list (cons . list)) 

(pop list) = (let ((result (first list))) 
(setf list (rest list)) 
result) 

Just as a Hst can be used to accumulate elements, a running sum can be used to 
accumulate numbers. Lisp provides two more special forms, 1 ncf and decf, that can 
be used to increment or decrement a sum. For both forms the first argument must 


<a id='page-57'></a>
be a location (a variable or other setf-able form) and the second argument, which 
is optional, is the number to increment or decrement by. For those who know C, 
(incf x) is equivalent to -H-X, and (incf . 2) is equivalent to x+=2. In Lisp the 
equivalence is: 

(incf x) = (incf . 1) = (setf . (+ . D) 
(decf x) = (decf . 1) = (setf . (- . D) 

When the location is a complex form rather than a variable. Lisp is careful to expand 
into code that does not evaluate any subform more than once. This holds for push, 
pop, 1 ncf, and decf. In the following example, we have a list of players and want 
to decide which player has the highest score, and thus has won the game. The 
structure pi ayer has slots for the player's score and number of wins, and the function 
determi ne -wi nner increments the winning player's w1 ns field. The expansion of the 
i ncf form binds a temporary variable so that the sort is not done twice. 

(defstruct player (score 0) (wins 0)) 

(defun determine-winner (players) 

"Increment the WINS for the player with highest score." 

(incf (player-wins (first (sort players #*> 

:key #'player-score))))) 

(defun determine-winner (players) 

"Increment the WINS for the player with highest score." 

(let ((temp (first (sort players #'> :key #'player-score)))) 

(setf (player-wins temp) (+ (player-wins temp) 1)))) 

Functions and Special Forms for Repetition 

Many languages have a small number of reserved words for forming iterative loops. 
For example, Pascal has whi 1 e, repeat, and for statements. In contrast, Conunon 
Lisp has an almost bewildering range of possibilities, as summarized below: 

dolist loop over elements of a list 
dot1mes loop over successive integers 
do, do* general loop, sparse syntax 
loop general loop, verbose syntax 
mapc. mapcar loop over elements of lists(s) 
some, every loop over list until condition 
find, reduce, efc. more specific looping functions 
recursion general repetition 


<a id='page-58'></a>

To explain each possibiUty, we will present versions of the function length, which 
returns the number of elements in a list. First, the special form dol i st can be used 
to iterate over the elements of a list. The syntax is: 

(dol i st (variable list optional-result) body...) 

This means that the body is executed once for each element of the list, with variable 
bound to the first element, then the second element, and so on. At the end, 
dol i st evaluates and returns the optional-result expression, or nil if there is no result 
expression. 

Below is a version of length usingdol i st. The let form introduces anew variable, 
1 en, which is initially bound to zero. The dol i st form then executes the body once 
for each element of the list, with the body incrementing 1 en by one each time. This 
use is unusual in that the loop iteration variable, el ement, is not used in the body. 

(defun length1 (list ) 
(let (den 0)) start with LEN=0 
(dolist (element list ) and on each iteration 
(incf len)) increment LEN by 1 
len)) and return LEN 

It is also possible to use the optional result of dol i st, as shown below. While many 
programmers use this style, I find that it is too easy to lose track of the result, and so 
I prefer to place the result last explictly. 

(defun length1.1 (list) ; alternate version: 
(let (den 0)) ; (not my preference) 
(dolist (element list len) ; uses len as result here 
(incf len)))) 

The function mapc performs much the same operation as the special form dol i st. In 
the simplest case, mapc takes two arguments, the first a function, the second a list. It 
applies the function to each element of the list. Here is length using mapc: 

(defun lengthZ (list) 
(let (den 0)) ; start with LEN=0 
(mapc #'dambda (element) ; and on each iteration 
(incf len)) ; increment LEN by 1 
list) 
len)) ; and return LEN 

There are seven different mapping functions, of which the most useful are mapc and 
mapca r. mapca r executes the same function calls as mapc, but then returns the results 


<a id='page-59'></a>
in a list. 

There is also a dot i mes form, which has the syntax: 

(dot i mes (variable number optional-result) body,..) 
and executes the body with variable bound first to zero, then one, all the way up to 
number-1 (for a total of number times). Of course, dot i mes is not appropriate for 
implementing length, since we don't know the number of iterations ahead of time. 
There are two very general looping forms, do and 1 oop. The syntax of do is as 
follows: 

(do ((variable initial next)...) 
(exit-test result) 
body...) 

Each variable is initially bound to the initial value. If exit-test is true, then result is returned. 
Otherwise, the body is executed and each variable is set to the corresponding 
next value and exit-test is tried again. The loop repeats until exit-test is true. If a next 
value is omitted, then the corresponding variable is not updated each time through 
the loop. Rather, it is treated as if it had been bound with a let form. 

Here is length implemented withdo,usingtwo variables, 1 en to count the number 
of elements, and 1 to go down the list. This is often referred to as cdr-ing down a list, 
because on each operation we apply the function cdr to the list. (Actually, here we 
have used the more mnemonic name rest instead of cdr.) Note that the do loop has 
no body! All the computation is done in the variable initialization and stepping, and 
in the end test. 

(defun lengths (list) 
(do (den 0 (+ len D) ; start with LEN=0. increment 
(1 list (rest 1))) ; ... on each iteration 
((null 1) len))) ; (until the end of the list) 

I find the do form a little confusing, because it does not clearly say that we are looping 
through a list. To see that it is indeed iterating over the list requires looking at both 
the variable 1 and the end test. Worse, there is no variable that stands for the current 
element of the Ust; we would need to say (first 1 ) to get at it. Both dol i st and 
mapc take care of stepping, end testing, and variable naming automatically. They are 
examples of the "be specific" principle. Because it is so unspecific, do will not be 
used much in this book. However, many good programmers use it, so it is important 
to know how to read do loops, even if you decide never to write one. 

The syntax of 1 oop is an entire language by itself, and a decidedly non-Lisp-like 
language it is. Rather than list all the possibilities for 1 oop, we will just give examples 


<a id='page-60'></a>

here, and refer the reader to Common Lisp the Language, 2d edition, or chapter 24.5 for 
more details. Here are three versions of length using 1 oop: 

(defun length4 (list) 
(loop for element in list ; go through each element 
count t)) ; counting each one 

(defun lengths (11st) 
(loop for element in list ; go through each element 
summing 1)) ; adding 1 each time 

(defun lengthe (list) 

(loop with len = 0 ; start with LEN=0 
until (null list) ; and (until end of list) 
for element = (pop list) ; on each iteration 
do (incf len) ; increment LEN by 1 
finally (return len))) ; and return LEN 

Every programmer learns that there are certain kinds of loops that are used again 
and again. These are often called programming idioms or cliches. An example is going 
through the elements of a list or array and doing some operation to each element. 
In most languages, these idioms do not have an explicit syntactic marker. Instead, 
they are implemented with a general loop construct, and it is up to the reader of the 
program to recognize what the programmer is doing. 

Lisp is unusual in that it provides ways to explicitly encapsulate such idioms, and 
refer to them with explicit syntactic and functional forms, dol 1 st and dotimes are 
two examples of this-they both follow the "be specific" principle. Most programmers 
prefer to use a dol i st rather than an equivalent do, because it cries out "this loop 
iterates over the elements of a list." Of course, the corresponding do form also says 
the same thing—but it takes more work for the reader to discover this. 

In addition to special forms like dol 1 st and dotimes, there are quite a few functions 
that are designed to handle common idioms. Two examples are count-If, 
which counts the number of elements of a sequence that satisfy a predicate, and 
position-If, which returns the index of an element satisfying a predicate. Both 
can be used to implement length. In length7 below, count -1f gives the number of 
elements in 11 st that satisfy the predicate true. Since true is defined to be always 
true, this gives the length of the list. 

(defun length? (list) 
(count-if #*true list)) 

(defun true (x) t) 

In lengthS, the function position -1 f finds the position of an element that satisfies 
the predicate true, starting from the end of the list. This will be the very last element 


<a id='page-61'></a>
of the list, and since indexing is zero-based, we add one to get the length. Admittedly, 
this is not the most straightforward implementation of length. 

(defun lengths (list) 

(if (null list) 
0 
(+ 1 (position-if #*true list :from-end t)))) 

A partial table of functions that implement looping idioms is given below. These 
functions are designed to be flexible enough to handle almost all operations on 
sequences. The flexibility comes in three forms. First, functions like mapcar can 
apply to an arbitrary number of lists, not just one: 

> (mapcar '(1 2 3)) => (-1 -2 -3) 
> (mapcar #'+ '(1 2) '(10 20)) (11 22) 
> (mapcar #'+ '(1 2) '(10 20) '(100 200)) => (111 222) 

Second, many of the functions accept keywords that allow the user to vary the test 
for comparing elements, or to only consider part of the sequence. 

> (remove 1 '(1 2 3 2 1 0 -1)) =4^ (2 3 2 0 -1) 

> (remove 1 '(1 2 3 2 1 0 -1) :key #'abs) ^(2320) 

> (remove 1 '(1 2 3 2 1 0 -1) :test #'<) =>(110 -1) 

> (remove 1 '(1 2 3 2 1 0 -1) rstart 4) (1 2 3 2 0 -1) 

Third, some have corresponding functions ending in -if or -if-not that take a 
predicate rather than an element to match against: 

> (remove-if #Oddp '(1 2 3 2 1 0 -1)) =^(2 2 0) 

> (remove-if-not #'oddp '(123210 -1)) =^(131 -1) 

> (find-if #'evenp '(123210 -1)) 2 

The following two tables assume these two values: 

(setf . '(a b c)) 

(setf y '(1 2 3)) 

The first table lists functions that work on any number of lists but do not accept 
keywords: 


<a id='page-62'></a>

(every #Oddp y) =..i 1 test if every element satisfies a predicate 
(some #Oddp y) => t test if some element satisfies predicate 
(mapcar y) =^(-1 -2 -3) apply function to each element and return result 
(mapc #'print y) prints 12 3 perform operation on each element 

The second table lists functions that have -if and -if-not versions and also 
accept keyword arguments: 

(member 2 y) =^(2 3) see if element is in list 
(count 'b x) =>1 count the number of matching elements 
(delete 1 y) =>(2 3) omit matching elements 
(find 2 y) ^2 find first element that matches 
(position 'a x) =^0 find index of element in sequence 
(reduce #'+ y) apply function to succesive elements 
(remove 2 y) =>(1 3) like del ete, but makes a new copy 
(substitute 4 2 y) =^(14 3) replace elements with new ones 

Repetition through Recursion 

Lisp has gained a reputation as a "recursive" language, meaning that Lisp encourages 
programmers to write functions that call themselves. As we have seen above, there is 
a dizzying number of functions and special forms for writing loops in Common Lisp, 
but it is also true that many programs handle repetition through recursion rather 
than with a syntactic loop. 

One simple definition of length is "the empty list has length 0, and any other list 
has a length which is one more than the length of the rest of the list (after the first 
element)." This translates directly into a recursive function: 

(defun length9 (list) 

(if (null list) 
0 
(+ 1 (length9 (rest list))))) 

This version of length arises naturally from the recursive definition of a list: "a list 
is either the empty list or an element consed onto another list." In general, most 
recursive functions derive from the recursive nature of the data they are operating 
on. Some kinds of data, like binary trees, are hard to deal with in anything but a 
recursive fashion. Others, like Hsts and integers, can be defined either recursively 
(leading to recursive functions) or as a sequence (leading to iterative functions). In 
this book, I tend to use the "list-as-sequence" view rather than the "list-as-first-and-
rest" view. The reason is that defining a hst as a first and a rest is an arbitrary and 
artificial distinction that is based on the implementation of lists that Lisp happens to 
use. But there are many other ways to decompose a list. We could break it into the last 


<a id='page-63'></a>
element and all-but-the-last elements, for example, or the first half and the second 

half. The "list-as-sequence" view makes no such artificial distinction. It treats all 

elements identically. 

One objection to the use of recursive functions is that they are inefficient, because 
the compiler has to allocate memory for each recursive call. This may be true for the 
function length9, but it is not necessarily true for all recursive calls. Consider the 
following definition: 

(defun length1O (list) 
(length1O-aux list 0)) 

(defun length1O-aux (sublist len-so-far) 

(if (null sublist) 
len-so-far 
(length1O-aux (rest sublist) (+ 1 len-so-far)))) 

length1O uses length1O - aux as an auxiliary function, passing it 0 as the length of the 
list so far. 1 engt hlO - a ux then goes down the list to the end, adding 1 for each element. 
The invariant relation is that the length of the sublist plus 1 en- so - fa r always equals 
the length of the original list. Thus, when the sublist is nil, then 1 en-so-f ar is the 
length of the original list. Variables like 1 en- so - fa r that keep track of partial results 
are called accumulators. Other examples of functions that use accumulators include 
f 1 a tten - a 11 on [page 329](chapter10.md#page-329); one- un known on page [page 237](chapter7.md#page-237); the Prolog predicates discussed
on [page 686](chapter20.md#page-686); and anonymous-variables-in on pages [page 400](chapter12.md#page-400) and [page 433](chapter12.md#page-433), which uses two 
accumulators. 

The important difference between length9 and length1O is when the addition 
is done. In length9, the function calls itself, then returns, and then adds 1. In 
length1O-aux, the function adds 1, then calls itself, then returns. There are no 
pending operations to do after the recursive call returns, so the compiler is free to 
release any memory allocated for the original call before making the recursive call. 
length1O-aux is called a tail-recursive function, because the recursive call appears as 
the last thing the function does (the tail). Many compilers will optimize tail-recursive 
calls, although not all do. (Chapter 22 treats tail-recursion in more detail, and points 
out that Scheme compilers guarantee that tail-recursive calls will be optimized.) 

Some find it ugly to introduce length 10 - a ux. For them, there are two alternatives. 

First, we could combine length1O and length1O-aux into a single function with an 

optional parameter: 

(defun length11 (list &optional (len-so-far 0)) 

(if (null list) 
len-so-far 
(length11 (rest list) (+ 1 len-so-far)))) 


<a id='page-64'></a>

Second, we could introduce a local function inside the definition of the main function. 
This is done with the special form 1 abel s: 

(defun length12 (the-list) 
(labels 
((length13 (list len-so-far) 

(if (null list) 
len-so-far 
(length1S (rest list) (+ 1 len-so-far))))) 

(length1S the-list 0))) 

In general, a 1 abel s form (or the similar flet form) can be used to introduce one or 
more local functions. It has the following syntax: 

(labels 

((function-name {parameter...)function-body)...) 
body-of-labels) 

Other Special Forms 

A few more special forms do not fit neatly into any category. We have already seen 
the two special forms for creating constants and functions, quote and function. 
These are so common that they have abbreviations: 'x for (quote x) and #'f for 
(function f). 

The special form progn can be used to evaluate a sequence of forms and return 
the value of the last one: 

(progn (setf . 0) (setf . (+ . D) .) 1 

progn is the equivalent of a begin.. .end block in other languages, but it is used 
very infrequently in Lisp. There are two reasons for this. First, programs written 
in a functional style never need a sequence of actions, because they don't have side 
effects. Second, even when side effects are used, many special forms allow for a 
body which is a sequence—an implicit progn. I can only think of three places where 
a progn is justified. First, to implement side effects in a branch of a two-branched 
conditional, one could use either an i f with a progn, or a cond: 

(if (> X 100) (cond ((> . 100) 
(progn (print "too big") (print "too big") 
(setf X 100)) (setf . 100)) 

X) (t X)) 

<a id='page-65'></a>
If the conditional had only one branch, then when or unl ess should be used, since 
they allow an implicit progn. If there are more than two branches, then cond should 
be used. 

Second, progn is sometimes needed in macros that expand into more than one 
top-level form, as in the defun* macro on [page 326](chapter10.md#page-326), section 10.3. Third, a progn is 
sometimes needed in an unwi nd- protect, an advanced macro. An example of this is 
the wi th- resource macro on [page 338](chapter10.md#page-338), section 10.4. 

The forms trace and untrace are used to control debugging information about 
entry and exit to a function: 

> (trace length9) (LENGTH9) 

> (length9 '(a b c)) 
(1 ENTER LENGTH9: (ABO ) 
(2 ENTER LENGTH9: (BO ) 

(3 ENTER LENGTH9: (O) 
(4 ENTER LENGTH9: NIL) 
(4 EXIT LENGTH9: 0) 

(3 EXIT LENGTH9: 1) 

(2 EXIT LENGTH9: 2) 
(1 EXIT LENGTH9: 3) 
3 

> (untrace length9) => (LENGTH9) 

> (length9 '(a b c)) => 3 

Finally, the special form return can be used to break out of a block of code. Blocks are 
set up by the special form bl ock, or by the looping forms (do, do*, dol i st, dot i mes, or 
loop). For example, the following function computes the product of a list of numbers, 
but if any number is zero, then the whole product must be zero, so we immediately 
return zero from the dol i st loop. Note that this returns from the dol i st only, not 
from the function itself (although in this case, the value returned by dol i st becomes 
the value returned by the function, because it is the last expression in the function). I 
have used uppercase letters in RETURN to emphasize the fact that it is an unusual step 
to exit from a loop. 

(defun product (numbers) 
"Multiply all the numbers together to compute their product." 
(let ((prod D) 

(dolist (n numbers prod) 

(if (= . 0) 
(RETURN 0) 
(setf prod (* . prod)))))) 


<a id='page-66'></a>

Macros 

The preceding discussion has been somewhat cavalier with the term "special form." 
Actually, some of these special forms are really macros, forms that the compiler 
expands into some other code. Common Lisp provides a number of built-in macros 
and allows the user to extend the language by defining new macros. (There is no way 
for the user to define new special forms, however.) 

Macros are defined with the special form def ma c ro. Suppose we wanted to define 
a macro, whi 1 e, that would act like the whi 1 e loop statement of Pascal. Writing a 
macro is a four-step process: 

* Decide if the macro is really necessary. 
* Write down the syntax of the macro. 
* Figure out what the macro should expand into. 
* Use def macro to implement the syntax/expansion correspondence. 
The first step in writing a macro is to recognize that every time you write one, 
you are defining a new language that is just like Lisp except for your new macro. 
The programmer who thinks that way will rightfully be extremely frugal in defining 
macros. (Besides, when someone asks, "What did you get done today?" it sounds 
more impressive to say "I defined a new language and wrote a compiler for it" than 
to say "I just hacked up a couple of macros.") Introducing a macro puts much more 
memory strain on the reader of your program than does introducing a function, 
variable or data type, so it should not be taken lightly. Introduce macros only when 
there is a clear need, and when the macro fits in well with your existing system. As 

C.A.R. Hoare put it, "One thing the language designer should not do is to include 
untried ideas of his own." 
The next step is to decide what code the macro should expand into. It is a good 
idea to follow established Lisp conventions for macro syntax whenever possible. 
Look at the looping macros (dolist, dot i mes, do-symbols), the defining macros 
(defun, defvar, defparameter, defstruct), or the the I/O macros (with-open-file, 
with-open-stream, with-input-from-string), for example. If you follow the naming 
and syntax conventions for one of these instead of inventing your own conventions, 
you'll be doing the reader of your program a favor. For whi 1 e, a good syntax is: 

(while test body...) 

The third step is to write the code that you want a macro call to expand into: 


<a id='page-67'></a>
(loop 
(unless test (return nil)) 
body) 

The final step is to write the definition of the macro, using defmacro. A defmacro 
form is similar to a defun in that it has a parameter list, optional documentation 
string, and body. There are a few differences in what is allowed in the parameter list, 
which will be covered later. Here is a definition of the macro whi 1 e, which takes a 
test and a body, and builds up the 1 oop code shown previously: 

(defmacro while (test &rest body) 
"Repeat body while test is true." 
(list* .... 

(list 'unless test '(return nil)) 
body)) 

(The function 1 i st* is like 11 st, except that the last argument is appended onto the 
end of the list of the other arguments.) We can see what this macro expands into by 
using macroexpand, and see how it runs by typing in an example: 

> (macroexpand-1 '(while (< i 10) 
(print (* i i)) 
(setf i (+ i 1)))) ^ 

(LOOP (UNLESS (<I 10) (RETURN NIL)) 
(PRINT (* I I)) 
(SETF I (+ I 1))) 

> (setf i 7) => 7 

> (while (< i 10) 
(print (* i i)) 
(setf i (+ i 1))) => 

49 
64 
81 
NIL 

Section 24.6 ([page 853](chapter24.md#page-853)) describes a more complicated macro and some details on the 
pitfalls of writing complicated macros ([page 855](chapter24.md#page-855)). 

Backquote Notation 

The hardest part about defining whi 1 e is building the code that is the expansion of 
the macro. It would be nice if there was a more immediate way of building code. 
The following version of while following attempts to do just that. It defines the local 


<a id='page-68'></a>

variable code to be a template for the code we want, and then substitutes the real 
values of the variables test and body for the placeholders in the code. This is done 
with the function subst; (subst new old tree) substitutes new for each occurrence of 
old anywhere within tree. 

(defmacro while (test &rest body) 

"Repeat body while test is true." 

(let ((code '(loop (unless test (return nil)) . body))) 

(subst test 'test (subst body 'body code)))) 

The need to build up code (and noncode data) from components is so frequent that 
there is a special notation for it, the backquote notation. The backquote character 
"'" is similar to the quote character " . A backquote indicates that what follows is 
mostly a literal expression but may contain some components that are to be evaluated. 
Anything marked by a leading comma"," is evaluated and inserted into the structure, 
and anything marked with a leading " ,@" must evaluate to a Hst that is spliced into 
the structure: each element of the list is inserted, without the top-level parentheses. 
The notation is covered in more detail in section 23.5. Here we use the combination 
of backquote and comma to rewrite whi 1 e: 

(defmacro while (test &rest body) 

"Repeat body while test is true." 

'(loop (unless .test (return nil)) 

.body)) 

Here are some more examples of backquote. Note that at the end of a list,", @" has the 
same effect as "." followed by ",". In the middle of a list, only ", @" is a possibility. 

> (setf testl '(a test)) => (A TEST) 

> '(this is .testl) => (THIS IS (A TEST)) 

> '(this is .testl) =i> (THIS IS A TEST) 

> '(this is . .testl) (THIS IS A TEST) 

> '(this is .testl -- this is only .testl) 
(THIS IS A TEST THIS IS ONLY A TEST) 

This completes the section on special forms and macros. The remaining sections of 
this chapter give an overview of the important built-in functions in Common Lisp. 


<a id='page-69'></a>
3.3 Functions on Lists 

For the sake of example, assume we have the following assignments: 

(setf . '(a b c)) 
(setf y '(1 2 3)) 

The most important functions on lists are summarized here. The more complicated 
ones are explained more thoroughly when they are used. 

(first x) a first element of a list 

(second x) =>b second element of a list 

(third x) third element of a list 

(nth 0 x) => a nth element of a list, 0-based 

(rest x) => (b c) all but the first element 

(car x) => a another name for the first element of a list 

(cdr x) =>(b c) another name for all but the first element 

(last x) =i>(c) last cons cell in a list 

(length x) =^3 number of elements in a list 

(reverse x) =>(c b a) puts list in reverse order 

(cons 0 y) =>(0 1 2 3) add to front of list 

(append . y) =i>(a b c 1 2 3) append together elements 

(list . y) =>i{d b c) (1 2 3)) make a new list 

(list* 1 2 .) =>(1 2 a b c) append last argument to others 

(null nil) =>J predicate is true of the empty list 

(null x) =>nil ... and false for everything else 

distp x) =>T predicate is true of any list, including . i1 

distp 3) => nil ... and is false for nonlists 

(consp x) =>t predicate is true of non-nil lists 

(consp nil) =>nil ... and false for atoms, including . i1 

(equal . .) =^t true for lists that look the same 

(equal . y) nil ... and false for lists that look different 

(sort y #'>) =^(3 2 1) sort a list according to a comparison function 

(subseq . 1 2) => (B) subsequence with given start and end points 

We said that (cons a b) builds a longer list by adding element a to the front of list 
b, but what if b is not a list? This is not an error; the result is an object . such that 
(firstjc) =^a, (restjc) b, and where ;c prints as ia . b). This is known as dotted 
pair notation. If i? is a list, then the usual list notation is used for output rather than 
the dotted pair notation. But either notation can be used for input. 

So far we have been thinking of lists as sequences, using phrases like "a list of 
three elements." The list is a convenient abstraction, but the actual implementation 
of lists relies on lower-level building blocks called cons cells. A cons cell is a data 
structure with two fields: a first and a rest. What we have been calling "a list of 
three elements" can also be seen as a single cons cell, whose first field points to 


<a id='page-70'></a>

the first element and whose rest field points to another cons cell that is a cons cell 
representing a Ust of two elements. This second cons cell has a rest field that is a 
third cons cell, one whose rest field is nil. All proper lists have a last cons cell whose 
rest field is nil. Figure 3.1 shows the cons cell notation for the three-element list (one 
two three), as well as for the result of (cons One 'two). 

(ONE TWO THREE) (ONE . TWO) 

ONE TWO THREE ONE TWO 

Figure 3.1: Cons Cell Diagrams 

&#9635; Exercise 3.2 [s] The function cons can be seen as a special case of one of the other 
functions listed previously. Which one? 

&#9635; Exercise 3.3 [m] Write a function that will print an expression in dotted pair notation. 
Use the built-in function princ to print each component of the expression. 

&#9635; Exercise 3.4 [m] Write a function that, like the regular print function, will print an 
expression in dotted pair notation when necessary but will use normal list notation 
when possible. 

3.4 Equality and Internal Representation 
In Lisp there are five major equality predicates, because not all objects are created 
equally equal. The numeric equality predicate, =, tests if two numbers are the same. 
It is an error to apply = to non-numbers. The other equality predicates operate 
on any kind of object, but to understand the difference between them, we need to 
understand some of the internals of Lisp. 

When Lisp reads a symbol in two different places, the result is guaranteed to be 
the exact same symbol. The Lisp system maintains a symbol table that the function 
read uses to map between characters and symbols. But when a list is read (or built) 


<a id='page-71'></a>
in two different places, the results are not identically the same, even though the 
corresponding elements may be. This is because read calls cons to build up the list, 
and each call to cons returns a new cons cell. Figure 3.2 shows two lists, x and y, 
which are both equal to (one two), but which are composed of different cons cells, 
and hence are not identical. Figure 3.3 shows that the expression (rest x) does not 
generate new cons cells, but rather shares structure with x, and that the expression 
(cons ' zero x) generates exactly one new cons cell, whose rest is x. 

(setf X '(one two)) 

ONE TWO 

(setf y '(one two)) 

Figure 3.2: Equal But Nonidentical Lists 

(cons 'zero x) . (restx) 

1 
1 

ZERO ONE TWO 

Figure 3.3: Parts of Lists 


<a id='page-72'></a>

When two mathematically equal numbers are read (or computed) in two places, 
they may or may not be the same, depending on what the designers of your implementation 
felt was more efficient. In most systems, two equal fixnums will be identical, 
but equal numbers of other types will not (except possibly short floats). Common 
Lisp provides four equality predicates of increasing generality. All four begin with 
the letters eq, with more letters meaning the predicate considers more objects to be 
equal. The simplest predicate is eq, which tests for the exact same object. Next, 
eql tests for objects that are either eq or are equivalent numbers, equal tests for 
objects that are either eql or are lists or strings with eql elements. Finally, equal . 
is like equal except it also matches upper- and lowercase characters and numbers 
of different types. The following table summarizes the results of applying each of 
the four predicates to various values of . and y. The ? value means that the result 
depends on your implementation: two integers that are eql may or may not be eq. 

X eq eql equal equal .

y 
'x 'X . . . . 
. . . . .

? 

'(.) '(.) nil nil . . 

'"xy" '"xy" nil nil . . 

"'Xy" '".." nil nil nil . 

'0 ... nil nil nil . 
. . nil nil nil nil 
In addition, there are specialized equaUty predicates such as =, tree -equal, 
char-equal, and string-equal, which compare numbers, trees, characters, and 
strings, respectively. 

3.5 Functions on Sequences 
Common Lisp is in a transitional position halfway between the Lisps of the past 
and the Lisps of the future. Nowhere is that more apparent than in the sequence 
functions. The earliest Lisps dealt only with symbols, numbers, and lists, and 
provided Hst functions like append and length. More modern Lisps added support 
for vectors, strings, and other data types, and introduced the term sequence to refer 
to both vectors and lists. (A vector is a one-dimensional array. It can be represented 
more compactly than a list, because there is no need to store the rest pointers. It 
is also more efficient to get at the nth element of a vector, because there is no need 
to follow a chain of pointers.) Modern Lisps also support strings that are vectors of 
characters, and hence also a subtype of sequence. 

With the new data types came the problem of naming functions that operated 
on them. In some cases. Common Lisp chose to extend an old function: length can 


<a id='page-73'></a>
apply to vectors as well as lists. In other cases, the old names were reserved for the 
list functions, and new names were invented for generic sequence functions. For 
example, append and mapcar only work on lists, but concatenate and map work on 
any kind of sequence. In still other cases, new functions were invented for specific 
data types. For example, there are seven functions to pick the nth element out of a 
sequence. The most general is e 11, which works on any kind of sequence, but there are 
specific functions for lists, arrays, strings, bit vectors, simple bit vectors, and simple 
vectors. Confusingly, nth is the only one that takes the index as the first argument: 

(nth . list) 
ieM sequence n) 
{aref array n) 
{char string n) 
(bit bit vector n) 
(sb i t simple-hit vector .) 
(sV ref simple-vector .) 

The most important sequence functions are listed elsewhere in this chapter, depending 
on their particular purpose. 

3.6 Functions for Maintaining Tables 
Lisp lists can be used to represent a one-dimensional sequence of objects. Because 
they are so versatile, they have been put to other purposes, such as representing 
tables of information. The association list is a type of list used to implement tables. 
An association list is a list of dotted pairs, where each pair consists of a key and a value. 
Together, the list of pairs form a table: given a key, we can retrieve the corresponding 
value from the table, or verify that there is no such key stored in the table. Here's 
an example for looking up the names of states by their two-letter abbreviation. The 
function a s s oc is used. It returns the key/value pair (if there is one). To get the value, 
we just take the cdr of the result returned by assoc. 

(setf state-table 
'((AL . Alabama) (AK . Alaska) (AZ . Arizona) (AR . Arkansas))) 

> (assoc 'AK state-table) => (AK . ALASKA) 

> (cdr (assoc 'AK state-table)) => ALASKA 

> (assoc 'TX state-table) => NIL 

If we want to search the table by value rather than by key, we can use rassoc: 

> (rassoc 'Arizona table) (AZ . ARIZONA) 


<a id='page-74'></a>

> (car (rassoc 'Arizona table)) => AZ 

Managing a table with assoc is simple, but there is one drawback: we have to search 
through the whole list one element at a time. If the list is very long, this may take 
a while. 

Another way to manage tables is with hash tables. These are designed to handle 
large amounts of data efficiently but have a degree of overhead that can make 
them inappropriate for small tables. The function gethash works much like get—it 
takes two arguments, a key and a table. The table itself is initialized with a call to 
make-hash-tab! e and modified with a setf of gethash: 

(setf table (make-hash-table)) 

(setf (gethash 'AL table) 'Alabama) 
(setf (gethash 'AK table) 'Alaska) 
(setf (gethash 'AZ table) 'Arizona) 
(setf (gethash 'AR table) 'Arkansas) 

Here we retrieve values from the table: 

> (gethash 'AK table) => ALASKA 
> (gethash 'TX table) => NIL 

The function remhash removes a key/value pair from a hash table, cl rhash removes 
all pairs, and maphash can be used to map over the key/value pairs. The keys to hash 
tables are not restricted; they can be any Lisp object. There are many more details 
on the implementation of hash tables in Common Lisp, and an extensive Uterature 
on their theory. 

A third way to represent table is with property lists. A property list is a Hst of 
alternating key/value pairs. Property lists (sometimes called p-lists or plists) and 
association lists (sometimes called a-lists or alists) are similar: 

a-list; iikeyi . vah) {keyi . vali) ... {keyn . vain)) 

p-list: {key I val\ key 2 vah ... key . vain) 

Given this representation, there is little to choose between a-Hsts and p-lists. They 
are slightly different permutations of the same information. The difference is in how 
they are normally used. Every symbol has a property list associated with it. That 
means we can associate a property/value pair directly with a symbol. Most programs 
use only a few different properties but have many instances of property/value pairs 
for each property. Thus, each symbol's p-list wiH likely be short. In our example, 
we are only interested in one property: the state associated with each abbreviation. 


<a id='page-75'></a>
That means that the property lists will be very short indeed: one property for each 
abbreviation, instead of a list of 50 pairs in the association list implementation. 

Property values are retrieved with the function get, which takes two arguments: 
the first is a symbol for which we are seeking information, and the second is the 
property of that symbol that we are interested in. get returns the value of that 
property, if one has been stored. Property/value pairs can be stored under a symbol 
with a setf form. A table would be built as follows: 

(setf (get 'AL 'state) 'Alabama) 

(setf (get 'AK 'state) 'Alaska) 
(setf (get 'AZ 'state) 'Arizona) 
(setf (get 'AR 'state) 'Arkansas) 

Now we can retrieve values with get: 

> (get 'AK 'state) => ALASKA 
> (get 'TX 'state) => NIL 

This will be faster because we can go immediately from a symbol to its lone property 
value, regardless of the number of symbols that have properties. However, if a given 
symbol has more than one property, then we still have to search linearly through the 
property list. As Abraham Lincoln might have said, you can make some of the table 
lookups faster some of the time, but you can't make all the table lookups faster all 
of the time. Notice that there is no equivalent of rassoc using property lists; if you 
want to get from a state to its abbreviation, you could store the abbreviation under a 
property of the state, but that would be a separate setf form, as in: 

(setf (get 'Arizona 'abbrev) *AZ) 

In fact, when source, property, and value are all symbols, there are quite a few 
possibilities for how to use properties. We could have mimicked the a-list approach, 
and Usted all the properties under a single symbol, using setf on the function 
symbol - pi i st (which gives a symbol's complete property list): 

(setf (symbol-piist 'state-table) 
'(AL Alabama AK Alaska AZ Arizona AR Arkansas)) 

> (get 'state-table 'AK) => ALASKA 

> (get 'state-table 'Alaska) => NIL 

Property lists have a long history in Lisp, but they are falling out of favor as new 
alternatives such as hash tables are introduced. There are two main reasons why 
property lists are avoided. First, because symbols and their property lists are global. 


<a id='page-76'></a>

it is easy to get conflicts when trying to put together two programs that use property 
lists. If two programs use the same property for different purposes, they cannot be 
used together. Even if two programs use different properties on the same symbols, 
they will slow each other down. Second, property lists are messy. There is no way to 
remove quickly every element of a table implemented with property Hsts. In contrast, 
this can be done trivially with cl rhash on hash tables, or by setting an association 
Hst to nil. 

3.7 Functions on Trees 
Many Common Lisp functions treat the expression ((a b) ((c)) (d e))as a 
sequence of three elements, but there are a few functions that treat it as a tree with 
five non-null leaves. The function copy - tree creates a copy of a tree, and tree - equa 1 
tests if two trees are equal by traversing cons cells, but not other complex data like 
vectors or strings. In that respect, tree-equal is similar to equal, but tree-equal is 
more powerful because it allows a : test keyword: 

> (setf tree '((a b) ((c)) (d e))) 

> (tree-equal tree (copy-tree tree)) . 

(defun same-shape-tree (a b) 
"Are two trees the same except for the leaves?" 
(tree-equal a b :test #*true)) 

(defun true (&rest ignore) t) 

> (same-shape-tree tree '((1 2) ((3)) (4 5))) ^ . 

> (same-shape-tree tree '((1 2) (3) (4 5))) => NIL 

Figure3.4shows thetree ((a b) ((c)) (d e)) as a cons ceU diagram. 

There are also two functions for substituting a new expression for an old one 
anywhere within a tree, subst substitutes a single value for another, while sub! i s 
takes a list of substitutions in the form of an association Hst of (old . new) pairs. 
Note that the order of old and new in the a-Hst for subl i s is reversed from the order 
of arguments to subst. The name subl i s is uncharacteristically short and confusing; 
a better name would be subst -1 i St. 

> (subst 'new 'old '(old ((very old))) ^ (NEW ((VERY NEW))) 

> (sublis '((old . new)) '(old ((very old))))=^ (NEW ((VERY NEW))) 

> (subst 'new 'old Old) => 'NEW 


<a id='page-77'></a>
(defun english->french (words) 

(sublis '((are . va) (book . libre) (friend . ami) 
(hello . bonjour) (how . comment) (my . mon) 
(red . rouge) (you . tu)) 

words)) 

> (english->french '(hello my friend - how are you today?)) 
(BONJOUR MON AMI - COMMENT VA TU TODAY?) 

((ab) ((c)) (de)) 

Figure 3.4: Cons Cell Diagram of a Tree 


<a id='page-78'></a>

3.8 Functions on Numbers 
The most commonly used functions on numbers are listed here. There are quite a 
few other numeric functions that have been omitted. 

(+ 4 2) =>6 add 
(- 4 2) =^Z subtract 
(* 4 2) ^8 multiply 
(/ 4 2) =>2 divide 
(> 100 99) greater than (also >=, greater than or equal to) 
(= 100 100) equal (also /=, not equal) 
(< 99 100) less than (also <=, less than or equal to) 
(random 100) =^42 random integer from 0 to 99 
(expt 4 2) =i>16 exponentiation (also exp, and 1 eg) 
(sin pi) ^0.0 sine function (also cos, tan, etc.) 
(asin 0) =>0.0 arcsine or sin~^ function (also acos, atan, etc.) 
(min 2 3 4) =>2 minimum (also max) 
(abs -3) =>3 absolute value 
(sqrt 4) square root 
(round 4.1) round off (also truncate, f 1 cor, cei 1 i ng) 
(rem 11 5) remainder (also mod) 

3.9 Functions on Sets 
One of the important uses of lists is to represent sets. Common Lisp provides 
functions that treat lists in just that way. For example, to see what elements the sets 
r = {a, 6, c,d} and s = {c, d, e} have in common, we could use: 

> (setf . '(a b c d)) (A . C D) 
> (setf s '(c d e))=. (C D E) 
> (intersection r s) = > (C D) 

This implementation returned (C D) as the answer, but another might return (DC). 

They are equivalent sets, so either is valid, and your program should not depend on 

the order of elements in the result. Here are the main functions on sets: 

(intersection r s) => (c d) find common elements of two sets 
(union r s) (a b c d e) find all elements in either of two sets 
(set-difference r s) =>(a b) find elements in one but not other set 
(member *d r) ^(d) check if an element is a member of a set 
(subsetp s r) =>nil see if all elements of one set are in another 
(adjoin 'b s) =^(b c d e) add an element to a set 
(adjoin 'c s) =>{c d e) ... but don't add duplicates 


<a id='page-79'></a>
It is also possible to represent a set with a sequence of bits, given a particular 
universe of discourse. For example, if every set we are interested in must be a subset 
of(a b c d e), then we can use the bit sequence 111 10 to represent (a b cd), 00000 
to represent the empty set, and 11001 to represent (a b e). The bit sequence can be 
represented in Common Lisp as a bit vector, or as an integer in binary notation. For 
example, (a be) would be the bit vector #* 11001 or the integer 25, which can also 
be written as #bllOOL 

The advantage of using bit sequences is that it takes less space to encode a set, 
assuming a small universe. Computation will be faster, because the computer's 
underlying instruction set will typically process 32 elements at a time. 

Common Lisp provides a full complement of functions on both bit vectors and 
integers. The following table lists some, their correspondence to the list functions. 

lists integers bit vectors 
intersection logand bit-and 
union logior bit-ior 
set-difference logandc2 bit-andc2 
member logbitp bit 
length logcount 
For example, 

(intersection '(a bed) '(a b e)) (A B) 
(bit-and #*11110 #*11001) #*11000 
(logand #bllllO #bll001) 24 = #bll000 

3.10 Destructive Functions 
In mathematics, a function is something that computes an output value given some 
input arguments. Functions do not "do" anything, they just compute results. For 
example, if I tell you that . = 4 and y = 5 and ask you to apply the function "plus" to 
X and y, I expect you to tell me 9. IfI then ask, "Now what is the value of x?" it would 
be surprising if . had changed. In mathematics, applying an operator to . can have 
no effect on the value of x. 

In Lisp, some functions are able to take effect beyond just computing the result. 
These "functions" are not functions in the mathematical sense,^ and in other languages 
they are known as "procedures." Of course, most of the Lisp functions are true 
mathematical functions, but the few that are not can cause great problems. They can 

^In mathematics, a function must associate a unique output value with each input value. 


<a id='page-80'></a>

also be quite useful in certain situations. For both reasons, they are worth knowing 
about. 
Consider the following: 

> (setf X '(a b c)) (A . C) 
> (setf y '(1 2 3)) => (1 2 3) 
> (append . y) => (A .C 1 2 3) 

append is a pure function, so after evaluating the call to append, we can rightfully 
expect that . and y retain their values. Now consider this: 

> (nconc X y) (A .C 1 2 3) 
> . => (A .C 1 2 3) 
> y (1 2 3) 

The function nconc computes the same result as append, but it has the side effect 
of altering its first argument. It is called a destructive function, because it destroys 
existing structures, replacing them with new ones. This means that there is quite 
a conceptual load on the programmer who dares to use nconc. He or she must be 
aware that the first argument may be altered, and plan accordingly. This is far more 
complicated than the case with nondestructive functions, where the programmer 
need worry only about the results of a function call. 

The advantage of nconc is that it doesn't use any storage. While append must 
make a complete copy of x and then have that copy end with y, nconc does not need 
to copy anything. Instead, it just changes the rest field of the last element of x to 
point to y. So use destructive functions when you need to conserve storage, but be 
aware of the consequences. 

Besides nconc, many of the destructive functions have names that start with 
n, including nreverse, nintersection, nunion, nset-difference, and nsubst. An 
important exception is del ete, which is the name used for the destructive version of 
remove. Of course, the setf special form can also be used to alter structures, but it 
is the destructive functions that are most dangerous, because it is easier to overlook 
their effects. 

&#9635; Exercise 3.5 [h] (Exercise in altering structure.) Write a program that will play the 
role of the guesser in the game Twenty Questions. The user of the program will have 
in mind any type of thing. The program will ask questions of the user, which must 
be answered yes or no, or "it" when the program has guessed it. If the program runs 
out of guesses, it gives up and asks the user what "it" was. At first the program will 
not play well, but each time it plays, it will remember the user's replies and use them 
for subsequent guesses. 


<a id='page-81'></a>
3.11 Overview of Data Types 
This chapter has been organized around functions, with similar functions grouped 
together. But there is another way of organizing the Common Lisp world: by considering 
the different data types. This is useful for two reasons. First, it gives an 
alternative way of seeing the variety of available functionality. Second, the data types 
themselves are objects in the Common Lisp language, and as we shall see, there are 
functions that manipulate data types. These are useful mainly for testing objects (as 
with the typecase macro) and for making declarations. 

Here is a table of the most commonly used data types: 

Type Example Explanation 
character #\c A single letter, number, or punctuation mark. 
number 42 The most common numbers are floats and integers. 
float 3.14159 A number with a decimal point. 
integer 42 A whole number, of either fixed or indefinite size: 
fixnum 123 An integer that fits in a single word of storage. 
bignum 123456789 An integer of unbounded size. 
function #'sin A function can be applied to an argument list. 
symbol sin Symbols can name fns and vars, and are themselves objects. 
null nil The object ni 1 is the only object of type null. 
keyword :key Keywords are a subtype of symbol. 
sequence (a b c) Sequences include lists and vectors. 
list (a b c) A list is either a cons or nul 1. 
vector #(a b c) A vector is a subtype of sequence. 
cons (a b c) A cons is a non-nil list. 
atom t An atom is anything that is not a cons. 
string "abc" A string is a type of vector of characters. 
array #lA(a b c) Arrays include vectors and higher-dimensional arrays. 
structure #S(type ... ) Structures are defined by defstruct. 
hash-table Hash tables are created by make-hash-tabl e. 

Almost every data type has a recognizer predicate—a function that returns true 
for only elements of that type. In general, a predicate is a function that always 
returns one of two values: true or false. In Lisp, the false value is ni 1 , and every 
other value is considered true, although the most common true value is t. In most 
cases, the recognizer predicate's name is composed of the type name followed by 

p:characterp recognizes characters, numberp recognizes numbers, and so on. For 
example, (numberp 3) returns t because 3 is a number, but (numberp "x") returns 
.i 1 because "." is a string, not a number. 
Unfortunately, Common Lisp is not completely regular. There are no recognizers 
for fixnums, bignums, sequences, and structures. Two recognizers, nul 1 and atom, 
do not end in p. Also note that there is a hyphen before the . in hash-table-p, 
because the type has a hyphen in it. In addition, all the recognizers generated by 
defstruct have a hyphen before the p. 


<a id='page-82'></a>

The function type - of returns the type of its argument, and typep tests if an object 
is of a specified type. The function subtypep tests if one type can be determined to 
be a subtype of another. For example: 

> (type-of 123) ^ FIXNUM 

> (typep 123 'fixnum) . 

> (typep 123 'number) . 

> (typep 123 'integer) => . 

> (typep 123.0 'integer) ^ NIL 

> (subtypep 'fixnum 'number) => . 

The hierarchy of types is rather complicated in Common Lisp. As the prior example 
shows, there are many different numeric types, and a number like 123 is considered 
to be of type fixnum, integer, and number. We will see later that it is also of type 
rational andt. 

The type hierarchy forms a graph, not just a tree. For example, a vector is both 
a sequence and an array, although neither array nor sequence are subtypes of each 
other. Similarly, nul 1 is a subtype of both symbol and 1 i st. 

The following table shows a number of more specialized data types that are not 
used as often: 

Type Example Explanation 

t 42 Every object is of type t. 

nil No object is of type nil. 

complex #C(0 1) Imaginary numbers. 

bit 0 Zero or one. 

rational 2/3 Rationals include integers and ratios. 

ratio 2/3 Exact fractional numbers. 

simple-array #lA(x y) An array that is not displaced or adjustable. 
readtable A mapping from characters to their meanings to read. 

package A collection of symbols that form a module. 

pathname #P'7usr/spool/mail" A file or directory name. 

stream A pointer to an open file; used for reading or printing. 
random-state A state used as a seed by random. 

In addition, there are even more specialized types, such as s ho r t -f 1 oa t, comp i 1 ed f 
uncti on, and bi t-vector. It is also possible to construct more exact types, such as 
(vector (integer 0 3) 100), which represents a vector of 100 elements, each of 
which is an integer from 0 to 3, inclusive. Section 10.1 gives more information on 
types and their use. 

While almost every type has a predicate, it is also true that there are predicates 
that are not type recognizers but rather recognize some more general condition. For 


<a id='page-83'></a>
example, oddp is true only of odd integers, and stri ng-greaterp is true if one string 
is alphabetically greater than another. 

3.12 Input/Output 
Input in Lisp is incredibly easy because a complete lexical and syntactic parser is 
available to the user. The parser is called read. It is used to read and return a single 
Lisp expression. If you can design your application so that it reads Lisp expressions, 
then your input worries are over. Note that the expression parsed by read need not 
be a legal evaluable Lisp expression. That is, you can read ("hello" cons zzz) just 
as well as (+ 2 2). In cases where Lisp expressions are not adequate, the function 
read-char reads a single character, and read-1 i ne reads everything up to the next 
newline and returns it as a string. 

To read from the terminal, the functions read, read-char, or read-line (with 
no arguments) return an expression, a character, and a string up to the end of line, 
respectively. It is also possible to read from a file. The function open or the macro 
with-open-stream can be used to open a file and associate it with a stream, Lisp's 
name for a descriptor of an input/output source. All three read functions take three 
optional arguments. The first is the stream to read from. The second, if true, causes 
an error to be signaled at end of file. If the second argument is nil, then the third 
argument indicates the value to return at end of file. 

Output in Lisp is similar to output in other languages, such as C. There are a 
few low-level functions to do specific kinds of output, and there is a very general 
function to do formatted output. The function print prints any object on a new line, 
with a space following it. pri nl will print any object without the new line and space. 
For both functions, the object is printed in a form that could be processed by read. 
Forexample, the string "hello there" would print as "hello there". Thefunction 
.r i.c is used to print in a human-readable format. The string in question would print 
as hel1 o there with pri nc—the quote marks are not printed. This means that read 
cannot recover the original form; read would interpret it as two symbols, not one 
string. The function wri te accepts eleven different keyword arguments that control 
whether it acts like pri nl or pri .c, among other things. 

The output functions also take a stream as an optional argument. In the following, 
we create the file "test.text" and print two expressions to it. Then we open the 
file for reading, and try to read back the first expression, a single character, and then 
two more expressions. Note that the read-char returns the character #\G, so the 
following read reads the characters OODBYE and turns them into a symbol. The final 
read hits the end of file, and so returns the specified value, eof. 


<a id='page-84'></a>

> (with-open-file (stream "test.text" idirectlon :output) 
(print '(hello there) stream) 
(princ 'goodbye stream)) 

GOODBYE ; and creates the file test.text 

> (with-open-file (stream "test.text" idirection .-input) 
(list (read stream) (read-char stream) (read stream) 
(read stream nil 'eof))) ^ 
((HELLO THERE) #\G OODBYE EOF) 

The function terpri stands for "terminate print line," and it skips to the next line. 
The function fresh -1 i ne also skips to the next line, unless it can be determined that 
the output is already at the start of a line. 

Common Lisp also provides a very general function for doing formatted output, 
called format. The first argument to format is always the stream to print to; use 
t to print to the terminal. The second argument is the format string. It is printed 
out verbatim, except for format directives, which begin with the character " ~". These 
directives tell how to print out the remaining arguments. Users of C's pri ntf function 
or FORTRAN'S format statement should be familiar with this idea. Here's 
an example: 

> (format t "hello, world") 
hello, world 
NIL 

Things get interesting when we put in additional arguments and include format 
directives: 

> (format t "~ra plus -^s is ~f" "two" "two" 4) 
two plus "two" is 4.0 
NIL 

Thedirective "~&" moves to a fresh line, "~a" printsthenextargumentas pri no would, 
" ~ s" prints the next argument as . r i .1 would, and " ~ f" prints a number in floatingpoint 
format. If the argument is not a number, then princ is used, format always 
returns nil. There are 26 different format directives. Here's a more complex example: 

> (let ((numbers '(12 3 4 5))) 
(format t "~&~{~r~" plus "} is ~@r" 

numbers (apply #'+ numbers))) 
one plus two plus three plus four plus five is XV 
NIL 

The directive "~r" prints the next argument, which should be a number, in English, 


<a id='page-85'></a>
and " ~@." prints a number as a roman numeral. The compound directive " ~{..."}" 
takes the next argument, which must be a list, and formats each element of the list 
according to the format string inside the braces. Finally, the directive exits 
from the enclosing "''i..."}" loop if there are no more arguments. You can see that 
format, like 1 oop, comprises almost an entire programming language, which, also 
like 1 oop, is not a very Lisplike language. 

3.13 Debugging Tools 
In many languages, there are two strategies for debugging: (1) edit the program to 
insert print statements, recompile, and try again, or (2) use a debugging program to 
investigate (and perhaps alter) the internal state of the running program. 

Common Lisp admits both these strategies, but it also offers a third: (3) add 
annotations that are not part of the program but have the effect of automatically 
altering the running program. The advantage of the third strategy is that once 
you are done you don't have to go back and undo the changes you would have 
introduced in the first strategy. In addition, Common Lisp provides functions that 
display information about the program. You need not rely solely on looking at the 
source code. 

We have already seen how trace and untrace can be used to provide debugging 
information ([page 65](chapter3.md#page-65)). Another useful tool is st e p, which can be used to halt execution 
before each subform is evaluated. The form (step expression) will evaluate and return 
expression, but pauses at certain points to allow the user to inspect the computation, 
and possibly change things before proceeding to the next step. The commands 
available to the user are implementation-dependent, but typing a ? should give you 
a list of commands. As an example, here we step through an expression twice, the 
first time giving commands to stop at each subevaluation, and the second time giving 
commands to skip to the next function call. In this implementation, the commands 
are control characters, so they do not show up in the output. All output, including 
the symbols <= and => are printed by the stepper itself; I have added no annotation. 

> (step (+ 3 4 (* 5 6 (/ 7 8)))) 

<i= (+ 3 4 (* 5 6 (/ 7 8))) 

<i= 4 =i> 4 
<^ (* 5 6 (/ 7 8)) 
<^ 5 ^ 5 

<^ (/ 7 8) 
7 7 
8 => 8 

^ (/ 7 8) 7/8 


<a id='page-86'></a>

^ (* 5 6 (/ 7 8)) 105/4 
<^ (+ 3 4 (* 5 6 (/ 7 8))) ^ 133/4 
133/4 

> (step (+ 3 4 (* 5 6 (/ 7 8)))) 

^ (+ 3 4 (* 5 6 (/ 7 8))) 
/: 7 8 => 7/8 
*: 5 6 7/8 105/4 
+: 3 4 105/4 133/4 

(+ 3 4 (* 5 6 (/ 7 8))) => 133/4 
133/4 

The functions descri be, i nspect, documentati on, and apropos provide information 
about the state of the current program, apropos prints information about all symbols 
whose name matches the argument: 

> (apropos 'string ) 
MAKE-STRING function (LENGTH &KEY INITIAL-ELEMENT) 
PRINl-TO-STRING function (OBJECT) 
PRINC-TO-STRING function (OBJECT) 
STRING function (X) 

Once you know what obj ect you are interested in, des c r i be can give more information 
on it: 

> (describe 'make-string) 
Symbol MAKE-STRING is in LISP package. 
The function definition is #<FUNCTION MAKE-STRING -42524322>: 

NAME: MAKE-STRING 
ARGLIST: (LENGTH &KEY INITIAL-ELEMENT) 
DOCUMENTATION: "Creates and returns a string of LENGTH elements, 

all set to INITIAL-ELEMENT." 
DEFINITION: (LAMBDA (LENGTH &KEY INITIAL-ELEMENT) 
(MAKE-ARRAY LENGTH :ELEMENT-TYPE 'CHARACTER 
:INITIAL-ELEMENT (OR INITIAL-ELEMENT 

#\SPACE))) 
MAKE-STRING has property INLINE: INLINE 
MAKE-STRING has property :SOURCE-FILE: #P"SYS:KERNEL; STRINGS" 

> (describe 1234.56) 
1234.56 is a single-precision floating-point number. 
Sign 0, exponent #o211. 23-bit fraction #06450754 

If all you want is a symbol's documentation string, the function documentati on will 
do the trick: 


<a id='page-87'></a>

> (documentation 'first 'function) => "Return the first element of LIST.' 
> (documentation 'pi 'variable) => "pi" 

If you want to look at and possibly alter components of a complex structure, 
then i nspect is the tool. In some implementations it invokes a fancy, window-based 
browser. 

Common Lisp also provides a debugger that is entered automatically when an 
error is signalled, either by an inadvertant error or by deliberate action on the part 
of the program. The details of the debugger vary between implementations, but 
there are standard ways of entering it. The function break enters the debugger 
after printing an optional message. It is intended as the primary method for setting 
debugging break points, break is intended only for debugging purposes; when a 
program is deemed to be working, all calls to break should be removed. However, 
it is still a good idea to check for unusual conditions with error, cerror, assert, or 
check -type, which will be described in the following section. 

3.14 Antibugging Tools 
It is a good idea to include antibugging checks in your code, in addition to doing normal 
debugging. Antibugging code checks for errors and possibly takes corrective action. 

The functions error and cerror are used to signal an error condition. These are 
intended to remain in the program even after it has been debugged. The function 
error takes a format string and optional arguments. It signals a fatal error; that is, it 
stops the program and does not offer the user any way of restarting it. For example: 

(defun average (numbers) 

(if (null numbers) 
(error "Average of the empty list is undefined.") 
(/ (reduce #'+ numbers) 

(length numbers)))) 

In many cases, a fatal error is a little drastic. The function cerror stands for continuable 
error, cerror takes two format strings; the first prints a message indicating 
what happens if we continue, and the second prints the error message itself, cerror 
does not actually take any action to repair the error, it just allows the user to signal 
that continuing is alright. In the following implementation, the user continues by 
typing : conti nue. In ANSI Common Lisp, there are additional ways of specifying 
options for continuing. 


<a id='page-88'></a>

(defun average (numbers) 
(if (null numbers) 
(progn 
(cerror "Use 0 as the average." 
"Average of the empty list is undefined.") 
0) 
(/ (reduce #'+ numbers) 
(length numbers)))) 

> (average '()) 
Error: Average of the empty list is undefined. 
Error signaled by function AVERAGE. 
If continued: Use 0 as the average. 
> :continue 
0 

In this example, adding error checking nearly doubled the length of the code. This 
is not unusual; there is a big difference between code that works on the expected 
input and code that covers all possible errors. Common Lisp tries to make it easier 
to do error checking by providing a few special forms. The form ecase stands for 
"exhaustive case" or "error case." It is like a normal case form, except that if none 
of the cases are satisfied, an error message is generated. The form cease stands for 
"continuable case." It is like ecase, except that the error is continuable. The system 
will ask for a new value for the test object until the user supplies one that matches 
one of the programmed cases. 

To make it easier to include error checks without inflating the length of the code 
too much. Common Lisp provides the special forms check-type and assert. As 
the name implies, check-type is used to check the type of an argument. It signals a 
continuable error if the argument has the wrong type. For example: 

(defun sqr (x) 
"Multiply . by itself." 
(check-type . number) 

(* X X)) 

If s qr is called with a non-number argument, an appropriate error message is printed: 

> (sqr "hello") 
Error: the argument X was "hello", which is not a NUMBER. 
If continued: replace X with new value 
> :continue 4 
16 

assert is more general than check-type. In the simplest form, assert tests an 


<a id='page-89'></a>
expression and signals an error if it is false. For example: 

(defun sqr (x) 
"Multiply X by itself." 
(assert (numberp x)) 

(* X X)) 

There is no possibility of continuing from this kind of assertion. It is also possible to 
give assert a list of places that can be modified in an attempt to make the assertion 
true. In this example, the variable . is the only thing that can be changed: 

(defun sqr (x) 
"Multiply X by itself." 
(assert (numberp x) (x)) 

(* X X)) 

If the assertion is violated, an error message will be printed and the user will be given 
the option of continuing by altering x. If . is given a value that satisfies the assertion, 
then the program continues, assert always returns nil. 

Finally, the user who wants more control over the error message can provide 
a format control string and optional arguments. So the most complex syntax for 
assert is: 

(assert test-form (place...) format-ctl-string format-arg...) 

Here is another example. The assertion tests that the temperature of the bear's 
porridge is neither too hot nor too cold. 

(defun eat-porridge (bear) 

(assert (< too-cold (temperature (bear-porridge bear)) too-hot) 
(bear (bear-porridge bear)) 
"~a's porridge is not just right: ~a" 
bear (hotness (bear-porridge bear))) 

(eat (bear-porridge bear))) 

In the interaction below, the assertion failed, and the programmer's error message 
was printed, along with two possibilities for continuing. The user selected one, typed 
in a call to make - por r i dge for the new value, and the function succesfully continued. 


<a id='page-90'></a>

> (eat-porridge momma-bear) 
Error: #<MOMMA BEAR>*s porridge is not just right: 39 
Restart actions (select using :continue): 

0: Supply a new value for BEAR 
1: Supply a new value for (BEAR-PORRIDGE BEAR) 
> :continue 1 
Form to evaluate and use to replace (BEAR-PORRIDGE BEAR): 
(make-porridge :temperature just-right) 
nil 
It may seem like wasted effort to spend time writing assertions that (if all goes well) 
will never be used. However, for all but the perfect programmer, bugs do occur, and 
the time spent antibugging will more than pay for itself in saving debugging time. 

Whenever you develop a complex data structure, such as some kind of data base, 
it is a good idea to develop a corresponding consistency checker. A consistency 
checker is a function that will look over a data structure and test for all possible 
errors. When a new error is discovered, a check for it should be incorporated into 
the consistency checker. Calling the consistency checker is the fastest way to help 
isolate bugs in the data structiu-e. 

In addition, it is a good idea to keep a list of difficult test cases on hand. That 
way, when the program is changed, it will be easy to see if the change reintroduces 
a bug that had been previously removed. This is called regression testing, and Waters 
(1991) presents an interesting tool for maintaining a suite of regression tests. But it 
is simple enough to maintain an informal test suite with a function that calls assert 
on a series of examples: 

(defun test-ex () 
"Test the program EX on a series of examples." 
(i nit-ex) ; Initialize the EX program first, 
(assert (equal (ex 3 4) 5)) 
(assert (equal (ex 5 0) 0)) 
(assert (equal (ex *x 0) 0))) 

Timing Tools 

A program is not complete just because it gives the right output. It must also deliver 
the output in a timely fashion. The form (t i me expression) can be used to see how 
long it takes to execute expression. Some implementations also print statistics on the 
amount of storage required. For example: 

> (defun f (n) (dotimes (i n) nil)) => F 


<a id='page-91'></a>
> (time (f 10000)) => NIL 
Evaluation of (F 10000) took 4.347272 Seconds of elapsed time, 
including 0.0 seconds of paging time for 0 faults, Consed 27 words. 

> (compile 'f) => F 

> (time (f 10000)) NIL 
Evaluation of (F 10000) took 0.011518 Seconds of elapsed time, 
including 0.0 seconds of paging time for 0 faults, Consed 0 words. 

This shows that the compiled version is over 300 times faster and uses less storage 
to boot. Most serious Common Lisp programmers work exclusively with compiled 
functions. However, it is usually a bad idea to worry too much about efficiency details 
while starting to develop a program. It is better to design a flexible program, get it to 
work, and then modify the most frequently used parts to be more efficient. In other 
words, separate the development stage from the fine-tuning stage. Chapters 9 and 
10 give more details on efficiency consideration, and chapter 25 gives more advice 
on debugging and antibugging techniques. 

3.15 Evaluation 
There are three functions for doing evaluation in Lisp: funcall, apply, and eval. 
funcall is used to apply a function to individual arguments, while apply is used 
to apply a function to a list of arguments. Actually, apply can be given one or 
more individual arguments before the final argument, which is always a Ust. eval 
is passed a single argument, which should be an entire form-a function or special 
form followed by its arguments, or perhaps an atom. The following five forms are 
equivalent: 

> (+ 1 2 3 4) 10 
> (funcall #'+12 3 4) ^ 10 
> (apply #'+ '(1 2 3 4))=^ 10 
> (apply #.+ 1 2 '(3 4)) => 10 
> (eval '(+12 3 4)) => 10 

In the past, eval was seen as the key to Lisp's flexibility. In modern Lisps with lexical 
scoping, such as Common Lisp, eval is used less often (in fact, in Scheme there is 
no eval at all). Instead, programmers are expected to use 1 ambda to create a new 
function, and then apply or funcall the function. In general, if you find yourself 
using eval, you are probably doing the wrong thing. 


<a id='page-92'></a>

3.16 Closures 
What does it mean to create a new function? Certainly every time a function (or #') 
special form is evaluated, a function is returned. But in the examples we have seen 
and in the following one, it is always the same function that is returned. 

> (mapcar #'(1ambda (x) (+ . .)) '(1 3 10)) =4>(2 6 20) 

Every time we evaluate the # * (1 ambda ...) form, it returns the function that doubles 
its argument. However, in the general case, a function consists of the body of the 
function coupled with any free lexical vanables that the function references. Such a 
pairing is called a lexical closure, or just a closure, because the lexical variables are 
enclosed within the function. Consider this example: 

(defun adder (c) 
"Return a function that adds c to its argument." 
#'(lambda (x) (+ . c))) 

> (mapcar (adder 3) '(1 3 10)) =^(4 6 13) 

> (mapcar (adder 10) '(1 3 10)) ^ (11 13 20) 

Each time we call adder with a different value for c, it creates a different function, 
the function that adds c to its argument. Since each call to adder creates a new local 
variable named c, each function returned by adder is a unique function. 

Here is another example. The function bank-account returns a closure that can 
be used as a representation of a bank account. The closure captures the local variable 
balance. The body of the closure provides code to access and modify the local 
variable. 

(defun bank-account (balance) 
"Open a bank account starting with the given balance." 
#'(lambda (action amount) 

(case action 
(deposit (setf balance (->' balance amount))) 
(withdraw (setf balance (- balance amount)))))) 

In the following, two calls to bank-account create two different closures, each with 
a separate value for the lexical variable bal a nee. The subsequent calls to the two 
closures change their respective balances, but there is no confusion between the two 
accounts. 

> (setf my-account (bank-account 500.00)) => #<CLOSURE 52330407> 


<a id='page-93'></a>
> (setf your-account (bank-account 250.00)) ^ #<CLOSURE 52331203> 

> (funcall my-account 'withdraw 75.00) 425.0 

> (funcall your-account 'deposit 250.00) ^ 500.0 

> (funcall your-account 'withdraw 100.00) 400.0 

> (funcall my-account 'withdraw 25.00) => 400.0 

This style of programming will be considered in more detail in chapter 13. 

3.17 Special Variables 
Common Lisp provides for two kinds of variables: lexical and special variables. For 
the beginner, it is tempting to equate the special variables in Common Lisp with 
global variables in other languages. Unfortunately, this is not quite correct and can 
lead to problems. It is best to understand Common Lisp variables on their own terms. 

By default. Common Lisp variables are lexical variables. Lexical variables are 
introduced by some syntactic construct like let or defun and get their name from the 
fact that they may only be referred to by code that appears lexically within the body 
of the syntactic construct. The body is called the scope of the variable. 

So far, there is no difference between Common Lisp and other languages. The 
interesting part is when we consider the extent, or lifetime, of a variable. In other 
languages, the extent is the same as the scope: a new local variable is created when a 
block is entered, and the variable goes away when the block is exited. But because it 
is possible to create new functions—closures—in Lisp, it is therefore possible for code 
that references a variable to live on after the scope of the variable has been exited. 
Consider again the bank-account function, which creates a closure representing a 
bank account: 

(defun bank-account (balance) 

"Open a bank account starting with the given balance." 

#'(lambda (action amount) 

(case action 

(deposit (setf balance (+ balance amount))) 

(withdraw (setf balance (- balance amount)))))) 

The function introduces the lexical variable bal anee. The scope of bal anee is the 
body of the function, and therefore references to bal anee can occur only within this 
scope. What happens when ba. k -a ccount is called and exited? Once the body of the 
function has been left, no other code can refer to that instance of bal anee. The scope 
has been exited, but the extent of bal anee lives on. We can call the closure, and it 


<a id='page-94'></a>

can reference bal anee, because the code that created the closure appeared lexically 
within the scope of bal anee. 

In summary. Common Lisp lexical variables are different because they can be 
captured inside closures and referred to even after the flow of control has left their 
scope. 

Now we will consider special variables. A variable is made special by a def va r or 
defparameter form. For example, if we say 

(defvar *counter* 0) 

then we can refer to the special variable ^counter* anywhere in our program. This 
is just like a familiar global variable. The tricky part is that the global binding of 
*counter* can be shadowed by a local binding for that variable. In most languages, 
the local binding would introduce a local lexical variable, but in Common Lisp, special 
variables can be bound both locally and globally. Here is an example: 

(defun report () 
(format t "Counter = '^d " *counter*)) 

> (report) 
Counter = 0 
NIL 

> (let ((*counter* 100)) 

(report)) 
Counter = 100 
NIL 

> (report) 
Counter = 0 
NIL 

There are three calls to report here. In the first and third, report prints the global 
value of the special variable ^counter*. In the second call, the let form introduces 
a new binding for the special variable ^counter*, which is again printed by report. 
Once the scope of the let is exited, the new binding is disestablished, so the final 
call to report uses the global value again. 

In summary. Common Lisp special variables are different because they have 
global scope but admit the possibility of local (dynamic) shadowing. Remember: 
A lexical variable has lexical scope and indefinite extent. A special variable has 
indefinite scope and dynamic extent. 

The function call (symbol - value var), where var evaluates to a symbol, can be 
used to get at the current value of a special variable. To set a special variable, the 
following two forms are completely equivalent: 


<a id='page-95'></a>
(setf (symbol-valuePflr) t7fl/Me) 

(set var value) 

where both var and value are evaluated. There are no corresponding forms for 
accessing and setting lexical variables. Special variables set up a mapping between 
symbols and values that is accessible to the running program. This is unlike lexical 
variables (and all variables in traditional languages) where symbols (identifiers) 
have significance only while the program is being compiled. Once the program is 
running, the identifiers have been compiled away and cannot be used to access the 
variables; only code that appears within the scope of a lexical variable can reference 
that variable. 

&#9635; Exercise 3.6 [s] Given the following initialization for the lexical variable a and the 
special variable *b*, what will be the value of the let form? 

(setf a 'global-a) 
(defvar *b* 'global-b) 

(defun fn () *b*) 

(let ((a 'local-a) 
(*b* 'local-b)) 
(list a *b* (fn) (symbol-value 'a) (symbol-value'*b*))) 

3.18 Multiple Values 
Throughout this book we have spoken of "the value returned by a function." Historically, 
Lisp was designed so that every function returns a value, even those functions 
that are more like procedures than like functions. But sometimes we want a single 
function to return more than one piece of information. Of course, we can do that by 
making up a list or structure to hold the information, but then we have to go to the 
trouble of defining the structure, building an instance each time, and then taking that 
instance apart to look at the pieces. Consider the function round. One way it can be 
used is to round off a floating-point number to the nearest integer. So (round 5.1) is 

5. Sometimes, though not always, the programmer is also interested in the fractional 
part. The function round serves both interested and disinterested programmers by 
returning two values: the rounded integer and the remaining fraction: 
> (round 5.1) 5 .1 

There are two values after the => because round returns two values. Most of the time. 


<a id='page-96'></a>

multiple values are ignored, and only the first value is used. So (* 2 (round 5.1)) 
is 10, just as if round had only returned a single value. If you want to get at multiple 
values, you have to use a special form, such as mul ti pi e-val ue-bi nd: 

(defun show-both (x) 
(multiple-value-bind (int rem) 
(round x) 
(format t "~f = ~d + ~f" . int rem))) 

> (show-both 5.1) 
5.1 = 5 + 0.1 

You can write functions of your own that return multiple values using the function 
val ues, which returns its arguments as multiple values: 

> (values 1 2 3) =i> 1 2 3 

Multiple values are a good solution because they are unobtrusive until they are 
needed. Most of the time when we are using round, we are only interested in the 
integer value. If round did not use multiple values, if it packaged the two values up 
into a list or structure, then it would be harder to use in the normal cases. 

It is also possible to return no values from a function with (values). This is 
sometimes used by procedures that are called for effect, such as printing. For 
example, descri be is defined to print information and then return no values: 

> (describe '.) 
Symbol X is in the USER package. 
It has no value, definition or properties. 

However, when (val ues) or any other expression returning no values is nested in 
a context where a value is expected, it still obeys the Lisp rule of one-value-per-
expression and returns nil. In the following example, descri be returns no values, 
but then 1 i st in effect asks for the first value and gets nil. 

> (list (describe 'x)) 
Symbol X is in AI LP package. 
It has no value, definition or properties. 
(NIL) 


<a id='page-97'></a>
3.19 More about Parameters 
Common Lisp provides the user with a lot of flexibility in specifying the parameters 
to a function, and hence the arguments that the function accepts. Following is a 
program that gives practice in arithmetic. It asks the user a series of . problems, 
where each problem tests the arithmetic operator op (which can be +, -, *, or /, or 
perhaps another binary operator). The arguments to the operator will be random 
integers from 0 to range. Here is the program: 

(defun math-quiz (op range n) 
"Ask the user a series of math problems." 
(dotimes (i .) 

(problem (random range) op (random range)))) 

(defun problem (x op y) 
"Ask a math problem, read a reply, and say if it is correct." 
(format t "~&How much is ~d ~a ~d?" . op y) 
(if (eql (read) (funcall op . y)) 

(princ "Correct!") 

(princ "Sorry, that's not right."))) 

and here is an example of its use: 

> (math-quiz '+ 100 2) 

How much is 32 + 60? 92 

Correct! 

How much is 91 + 19? 100 

Sorry, that's not right. 

One problem with the function math-qui . is that it requires the user to type three 
arguments: the operator, a range, and the number of iterations. The user must 
remember the order of the arguments, and remember to quote the operator. This is 
quite a lot to expect from a user who presumably is just learning to add! 

Common Lisp provides two ways of dealing with this problem. First, a programmer 
can specify that certain arguments are optional, and provide default values for 
those arguments. For example, in math- qui . we can arrange to make be the default 
operator, 100 be the default number range, and 10 be the default number of examples 
with the following definition: 


<a id='page-98'></a>

(defun math-quiz (&optional (op ''.-) (range 100) (n 10)) 

"Ask the user a series of math problems." 

(dotimes (i n) 

(problem (random range) op (random range)))) 

Now (math-quiz) means the same as (math-quiz '+ 100 10). If an optional 
parameter appears alone without a default value, then the default is ni 1. Optional 
parameters are handy; however, what if the user is happy with the operator and 
range but wants to change the number of iterations? Optional parameters are still 
position-dependent, so the only solution is to type in all three arguments: (ma th - qui. 

100 5). 

Common Lisp also allows for parameters that are position-independent. These 
keyword parameters are explicitly named in the function call. They are useful when 
there are a number of parameters that normally take default values but occasionally 
need specific values. For example, we could have defined math- qui . as: 

(defun math-quiz (&key (op '+) (range 100) (n 10)) 

"Ask the user a series of math problems." 

(dotimes (i n) 

(problem (random range) op (random range)))) 

Now (math-quiz :n 5) and (math-quiz :op '+ :n 5 -.range 100) mean the same. 
Keyword arguments are specified by the parameter name preceded by a colon, and 
followed by the value. The keyword/value pairs can come in any order. 

A symbol starting with a colon is called a keyword, and can be used anywhere, 
not just in argument lists. The term keyword is used differently in Lisp than in many 
other languages. For example, in Pascal, keywords (or reserved words) are syntactic 
symbols, like if, el se, begin, and end. In Lisp we call such symbols special form 
operators or just special forms. Lisp keywords are symbols that happen to reside in 
the keyword package."^ They have no special syntactic meaning, although they do 
have the unusual property of being self-evaluating: they are constants that evaluate 
to themselves, unlike other symbols, which evaluate to whatever value was stored in 
the variable named by the symbol. Keywords also happen to be used in specifying 
&key argument lists, but that is by virtue of their value, not by virtue of some syntax 
rule. It is important to remember that keywords are used in the function call, but 
normal nonkeyword symbols are used as parameters in the function definition. 

Just to make things a little more confusing, the symbols &opti onal, &rest, and 
&key are called lambda-list keywords, for historical reasons. Unlike the colon in real 
keywords, the & in lambda-list keywords has no special significance. Consider these 
annotated examples: 

Apackage is a symbol table: a mapping between strings and the symbols they name. 


<a id='page-99'></a>
> :xyz => :XYZ ;keywords are self-evaluating 

> &optional => ; lambda-list keywords are normal symbols 

Error: the symbol &optional has no value 

> '&optional &OPTIONAL 

> (defun f (&xyz) (+ &xyz &xyz)) F ;& has no significance 

> (f 3) =. 6 

> (defun f (:xyz) (+ :xyz :xyz)) ^ 

Error: the keyword :xyz appears in a variable list. 

Keywords are constants, and so cannot be used as names of variables. 

> (defun g (&key . y) (list . y)) G 

> (let ((keys *(:x :y :z))) ;keyword args can be computed 
ig (second keys) 1 (first keys) 2)) => (2 1) 

Many of the functions presented in this chapter take keyword arguments that make 
them more versatile. For example, remember the function f i nd, which can be used 
to look for a particular element in a sequence: 

> (find 3 *(1 2 3 4 -5 6.0)) => 3 

It turns out that find takes several optional keyword arguments. For example, 
suppose we tried to find 6 in this sequence: 

> (find 6 '(1 2 3 4 -5 6.0)) nil 

This fails because f i nd tests for equality with eql, and 6 is not eql to 6.0. However, 
6 is equal . to 6.0, so we could use the : test keyword: 

> (find 6 '(1 2 3 4 -5 6.0) :test #'equalp) ^ 6.0 

In fact, we can specify any binary predicate for the : test keyword; it doesn't have to 
be an equality predicate. For example, we could find the first number that 4 is less 
than: 

> (find 4 '(1 2 3 4 -5 6.0) :test #*<) 6.0 

Now suppose we don't care about the sign of the numbers; if we look for 5, we want 
to find the - 5. We can handle this with the key keyword to take the absolute value of 
each element of the list with the abs function: 


<a id='page-100'></a>

> (find 5 '(1 2 3 4 -5 6.0) ikey #'abs) -5 

Keyword parameters significantly extend the usefulness of built-in functions, and 
they can do the same for functions you define. Among the built-in functions, the most 
common keywords fall into two main groups: :tes t,:tes t - not and : key, which are 
used for matching functions, and : start, :end, and :from-end, which are used on 
sequence functions. Some functions accept both sets of keywords. {Common Lisp the 
Language, 2d edition, discourages the use of :test -not ke3words, although they are 
still a part of the language.) 

The matching functions include sub! i s, posi ti on, subst, uni on, i ntersecti on, 
set -difference, remove, remove-if, subsetp, assoc, find, and member. By default, 
each tests if some item is eql to one or more of a series of other objects. This test can 
be changed by supplying some other predicate as the argument to : test, or it can be 
reversed by specifying :tes t - not. In addition, the comparison can be made against 
some part of the object rather than the whole object by specifying a selector function 
as the : key argument. 

The sequence functions include remove, remove-if, position, and find. The 
most common type of sequence is the list, but strings and vectors can also be used as 
sequences. A sequence function performs some action repeatedly for some elements 
of a sequence. The default is to go through the sequence from beginning to end, but 
the reverse order can be specified with : from-end t, and a subsequence can be 
specifed by supplying a number for the : sta rt or : end keyword. The first element 
of a sequence is numbered 0, not 1, so be careful. 

As an example of keyword parameters, suppose we wanted to write sequence 
functions that are similar to find and find-if, except that they return a list of all 
matching elements rather than just the first matching element. We will call the 
new functions f i nd-a 11 and f i nd-a. - i f. Another way to look at these functions 
is as variations of remove. Instead of removing items that match, they keep all the 
items that match, and remove the ones that don't. Viewed this way, we can see 
that the function f i nd-a 11 - i f is actually the same function as remove- i f -not. It is 
sometimes useful to have two names for the same function viewed in different ways 
(like not and nul 1). The new name could be defined with a defun, but it is easier to 
just copy over the definition: 

(setf (symbol-function 'find-all-if) #'remove-if-not) 

Unfortunately, there is no built-in function that corresponds exactly to f i nd-a 11, so 
we will have to define it. Fortunately, remove can do most of the work. All we have 
to do is arrange to pass remove the complement of the : test predicate. For example, 
finding all elements that are equal to 1 in a list is equivalent to removing elements 
that are not equal to 1: 


<a id='page-101'></a>
> (setf nums '(1 2 3 2 D) (1 2 3 2 1) 

> (find-all 1 nums :test #'=) = (remove 1 nums rtest #V=) (1 1) 

Now what we need is a higher-order function that returns the complement of a 
function. In other words, given =, we want to return /=. This function is called 
compl ement in ANSI Common Lisp, but it was not defined in earlier versions, so it is 
given here: 

(defun complement (fn) 

"If FN returns y, then (complement FN) returns (not y). " 
This function is built-in in ANSI Common Lisp, 
but is defined here for those with non-ANSI compilers. 

#*(lambda (&rest args) (not (apply fn args)))) 

When find-all is called with a given :test predicate, all we have to do is call 
remove with the complement as the :test predicate. This is true even when the 
: test function is not specified, and therefore defaults to eql. We should also test 
for when the user specifies the : test-not predicate, which is used to specify that 
the match succeeds when the predicate is false. It is an error to specify both a : test 
and : test-not argument to the same call, so we need not test for that case. The 
definition is: 

(defun find-all (item sequence &rest keyword-args 

&key (test #*eql) test-not &aHow-other-keys) 
"Find all those elements of sequence that match item, 
according to the keywords. Doesn't alter sequence." 
(if test-not 

(apply #*remove item sequence 
:test-not (complement test-not) keyword-args) 
(apply #.remove item sequence 
:test (complement test) keyword-args))) 

The only hard part about this definition is understanding the parameter list. The 
&rest accumulates all the keyword/value pairs in the variable keyword-args. In 
addition to the &rest parameter, two specific keyword parameters, rtest and 
: test-not, are specified. Any time you put a &key in a parameter Ust, you need 
an &al 1 ow-other- keys if, in fact, other keywords are allowed. In this case we want 

to accept keywords like : sta rt and : key and pass them on to remove. 

All the keyword/value pairs will be accumulated in the Ust keyword - a rgs, including 
the rtest or rtest-not values. SowewiUhave: 


<a id='page-102'></a>
(find-all 1 nums ;test #'= :key #*abs) 
= (remove 1 nums :test (complement #*=) :test #'= :key #*abs) 
^ (1 1) 
Note that the call to remove will contain two : tes t keywords. This is not an error; 
Common Lisp declares that the leftmost value is the one that counts. 

&#9635; Exercise 3.7 [s] Why do you think the leftmost of two keys is the one that counts, 
rather than the rightmost? 

&#9635; Exercise 3.8 [m] Some versions of Kyoto Common Lisp (KCL) have a bug wherein 
they use the rightmost value when more than one keyword/value pair is specified 
for the same keyword. Change the definition of f i nd -a 11 so that it works in KCL. 
There are two more lambda-list keywords that are sometimes used by advanced 
programmers. First, within a macro definition (but not a function definition), the 
symbol &body can be used as a synonym for &rest. The difference is that &body 
instructs certain formatting programs to indent the rest as a body. Thus, if we 
defined the macro: 
(defmacro while2 (test &body body) 
"Repeat body while test is true." 
'(loop (if (not .test) (return nil)) 
. .body)) 
Then the automatic indentation of wh 11 e2 (on certain systems) is prettier than wh 11 e: 
(while (< i 10)
(print (* i D )
(setf i (+ i 1))) 
(while2 (< i 10) 
(print (* i i)) 
(setf i (+ i 1))) 
Finally, an &aux can be used to bind a new local variable or variables, as if bound 
with let*. Personally, I consider this an abomination, because &aux variables are 
not parameters at all and thus have no place in a parameter list. I think they should 
be clearly distinguished as local variables with a let. But some good programmers 
do use &aux, presumably to save space on the page or screen. Against my better 
judgement, I show an example: 
(defun length14 (list &aux (len 0)) 
(dolist (element lis t len) 
(incf len))) 


<a id='page-103'></a>
3.20 The Rest of Lisp 
There is a lot more to Common Lisp than what we have seen here, but this overview 
should be enough for the reader to comprehend the programs in the chapters to 
come. The serious Lisp programmer will further his or her education by continuing 
to consult reference books and online documentation. You may also find part V 
of this book to be helpful, particularly chapter 24, which covers advanced features 
of Common Lisp (such as packages and error handling) and chapter 25, which is a 
collection of troubleshooting hints for the perplexed Lisper. 

While it may be distracting for the beginner to be continually looking at some 
reference source, the alternative—to explain every new function in complete detail as 
it is introduced—would be even more distracting. It would interrupt the description 
of the AI programs, which is what this book is all about. 

3.21 Exercises 
&#9635; Exercise 3.9 [m] Write a version of length using the function reduce. 

&#9635; Exercise 3.10 [m] Use a reference manual or descri be to figure out what the functions 
1 cm and . reconc do. 

&#9635; Exercise 3.11 [m] There is a built-in Common Lisp function that, given a key, a 
value, and an association Hst, returns a new association list that is extended to 
include the key/value pair. What is the name of this function? 

&#9635; Exercise 3.12 [m] Write a single expression using format that will take a list of 
words and print them as a sentence, with the first word capitalized and a period after 
the last word. You will have to consult a reference to learn new format directives. 

3.22 Answers 
Answer 3.2 (consab) = (Mst*ab) 


<a id='page-104'></a>

Answer 3.3 

(defun dprint (x) 
"Print an expression in dotted pair notation.' 
(cond ((atom x) (princ x)) 

(t (princ "(") 
(dprint (first x)) 
(pr-rest (rest x)) 
(princ ")") 

X))) 

(defun pr-rest (x) 
(princ " . ") 
(dprint x)) 

Answer 3.4 Use the same dpri nt function defined in the last exercise, but change 
pr-rest. 

(defun pr-rest (x) 

(cond ((null x)) 
((atom x) (princ " . ") (princ x)) 
(t (princ " ") (dprint (first x)) (pr-rest (rest x))))) 

Answer 3.5 We will keep a data base called *db*. The data base is organized into 
a tree structure of nodes. Each node has three fields: the name of the object it 
represents, a node to go to if the answer is yes, and a node for when the answer is no. 
We traverse the nodes until we either get an "it" reply or have to give up. In the latter 
case, we destructively modify the data base to contain the new information. 

(defstruct node 
name 
(yes nil) 
(no nil)) 

(defvar *db* 

(make-node :name 'animal 
:yes (make-node :name 'mammal) 
:no (make-node 

:name 'vegetable 
:no (make-node :name 'mineral)))) 


<a id='page-105'></a>
(defun questions (&optional (node *db*)) 
(format t "~&Is it a ~a? " (node-name node)) 
(case (read) 

((y yes) (if (not (null (node-yes node))) 
(questions (node-yes node)) 
(setf (node-yes node) (give-up)))) 

((n no) (if (not (null (node-no node))) 
(questions (node-no node)) 
(setf (node-no node) (give-up)))) 

(it 'aha!) 
(t (format t "Reply with YES, NO, or IT if I have guessed it.") 
(questions node)))) 

(defun give-up () 
(format t "~&I give up - what is it? ") 
(make-node :name (read))) 

Here it is used: 

> (questions) 

Is it a ANIMAL? yes 

Is it a MAMMAL? yes 

I give up - what is it? bear 

#S(NODE :NAME BEAR) 

> (questions) 

Is it a ANIMAL? yes 
Is it a MAMMAL? no 

I give up - what is it? penguin 

#S(NODE :NAME PENGUIN) 

> (questions) 

Is it a ANIMAL? yes 
Is it a MAMMAL? yes 
Is it a BEAR? it 

AHA! 

Answer 3.6 The value is (LOCAL-A LOCAL-B LOCAL-B GLOBAL-A LOCAL-B). 

The let form binds a lexically and *b* dynamically, so the references to a and 
*b* (including the reference to *b* within f n) all get the local values. The function 
symbol - value always treats its argument as a special variable, so it ignores the lexical 
binding for a and returns the global binding instead. However, the symbol - va1 ue of 
*b* is the local dynamic value. 


<a id='page-106'></a>

Answer 3.7 There are two good reasons: First, it makes it faster to search through 
the argument list: just search until you find the key, not all the way to the end. 
Second, in the case where you want to override an existing keyword and pass the 
argument list on to another function, it is cheaper to cons the new keyword/value 
pair on the front of a list than to append it to the end of a list. 

Answer 3.9 

(defun length-r (list) 
(reduce #*+ (mapcar #*(lambda (x) 1) list))) 

or more efficiently: 

(defun length-r (list) 
(reduce #'(lambda (x y) (+ . D) list 
rinitial-value 0)) 

or, with an ANSI-compliant Common Lisp, you can specify a : key 

(defun length-r (list) 
(reduce #'+ list :key #'(lambda (x) 1))) 

Answer 3.12 (format t '^@r{'^a'^^ '(this is a test)) 


## Chapter 4
<a id='page-109'></a>

GPS: The Genera 
Problem Solver 

There are now in the world machines that think. 

—Herbert Simon 
Nobel Prize-winning Al researcher 

I I 1 he General Problem Solver, developed in 1957 by Alan Newell and Herbert Simon, em-
I bodied a grandiose vision: a single computer program that could solve any problem, 

JL given a suitable description of the problem. GPS caused quite a stir when it was introduced, 
and some people in AI felt it would sweep in a grand new era of intelligent machines. 
Simon went so far as to make this statement about his creation: 

It is not my aim to surprise or shock you. ... But the simplest way I can summarize is to say 
that there are now in the world machines that think, that learn and create. Moreover, their 
ability to do these things is going to increase rapidly until-in a visible future-the range of 
problems they can handle will be coextensive with the range to which the human mind has 
been applied. 


<a id='page-110'></a>

Although GPS never lived up to these exaggerated claims, it was still an important 
program for historical reasons. It was the first program to separate its problem-
solving strategy from its knowledge of particular problems, and it spurred much 
further research in problem solving. For all these reasons, it is a fitting object 
of study. 

The original GPS program had a number of minor features that made it quite 
complex. In addition, it was written in an obsolete low-level language, IPL, that added 
gratuitous complexity. In fact, the confusing nature of IPL was probably an important 
reason for the grand claims about GPS. If the program was that complicated, it must 
do something important. We will be ignoring some of the subtleties of the original 
program, and we will use Common Lisp, a much more perspicuous language than 
IPL. The result will be a version of GPS that is quite simple, yet illustrates some 
important points about AI. 

On one level, this chapter is about GPS. But on another level, it is about the process 
of developing an AI computer program. We distinguish five stages in the development 
of a program. First is the problem description, which is a rough idea—usually 
written in English prose~of what we want to do. Second is the program specification, 
where we redescribe the problem in terms that are closer to a computable procedure. 
The third stage is the implementation of the program in a programming language 
such as Common Lisp, the fourth is testing, and the fifth is debugging and analysis. 
The boundaries between these stages are fluid, and the stages need not be completed 
in the order stated. Problems at any stage can lead to a change in the previous stage, 
or even to complete redesign or abandonment of the project. A programmer may 
prefer to complete only a partial description or specification, proceed directly to 
implementation and testing, and then return to complete the specification based on 
a better understanding. 

We follow all five stages in the development of our versions of GPS, with the hope 
that the reader will understand GPS better and will also come to understand better 
how to write a program of his or her own. To summarize, the five stages of an AI 
programming project are: 

1. Describe the problem in vague terms 
2. Specify the problem in algorithmic terms 
3. Implement the problem in a programming language 
4. Test the program on representative examples 
5. Debug and analyze the resulting program, and repeat the process 

<a id='page-111'></a>

4.1 Stage 1: Description 
As our problem description, we will start with a quote from Newell and Simon's 1972 
book. Human Problem Solving: 

The main methods of GPS jointly embody the heunstic ofmeans-ends analysis. 
Means-ends analysis is typified by the following kind of common-sense 
argument: 

I want to take my son to nursery school. What's the difference 
between what I have and what I want? One of distance. What 
changes distance? My automobile. My automobile won't work. 
What is needed to make it work? A new battery. What has new 
battenes? An auto repair shop. I want the repair shop to put in a 
new battery; but the shop doesn't know I need one. What is the 
difficulty? One of communication. What allows communication? 
Atelephone... and so on. 

The kind of analysis-classifying things in terms of the functions they serve and 
oscillating among ends, functions required, andmeans thatperform them-forms 
the basic system of heuristic of GPS. 

Of course, this kind of analysis is not exactly new. The theory of means-ends 
analysis was laid down quite elegantly by Aristotle 2300 years earlier in the chapter 
entitled "The nature of deliberation and its objects" of the Nicomachean Ethics (Book 
III. 3,1112b): 

We deliberate not about ends, but about means. For a doctor does not deliberate 
whether he shall heal, nor an orator whether he shall persuade, nor a statesman 
whether he shall produce law and order, nor does any one else deliberate about 
his end. They assume the end and consider how and by what means it is attained; 
and if it seems to be produced by several means they consider by which it is 
most easily and best produced, while if it is achieved by one only they consider 
how it will be achieved by this and by what means this will be achieved, till 
they come to the first cause, which in the order of discovery is last... and what 
is last in the order of analysis seems to be first in the order of becoming. And if 
we come on an impossibility, we give up the search, e.g., if we need money and 
this cannot be got; but if a thing appears possible we try to do it. 

Given this description of a theory of problem solving, how should we go about 
writing a program? First, we try to understand more fully the procedure outlined in 
the quotes. The main idea is to solve a problem using a process called means-ends 
analysis, where the problem is stated in terms of what we want to happen. In Newell 
and Simon's example, the problem is to get the kid to school, but in general we would 


<a id='page-112'></a>

like the program to be able to solve a broad class of problems. We can solve a problem 
if we can find some way to eliminate "the difference between what I have and what 
I want." For example, if what I have is a child at home, and what I want is a child 
at school, then driving may be a solution, because we know that driving leads to a 
change in location. We should be aware that using means-ends analysis is a choice: 
it is also possible to start from the current situation and search forward to the goal, 
or to employ a mixture of different search strategies. 

Some actions require the solving of preconditions as subproblems. Before we can 
drive the car, we need to solve the subproblem of getting the car in working condition. 
It may be that the car is already working, in which case we need do nothing to solve 
the subproblem. So a problem is solved either by taking appropriate action directly, 
or by first solving for the preconditions of an appropriate action and then taking 
the action. It is clear we will need some description of allowable actions, along 
with their preconditions and effects. We will also need to develop a definition of 
appropriateness. However, if we can define these notions better, it seems we won't 
need any new notions. Thus, we will arbitrarily decide that the problem description 
is complete, and move on to the problem specification. 

4.2 Stage 2: Specification 
At this point we have an idea—admittedly vague—of what it means to solve a problem 
in GPS. We can refine these notions into representations that are closer to Lisp as 
follows: 

* We can represent the current state of the world—"what I have"—or the goal 
state—"what I want"—as sets of conditions. Common Lisp doesn't have a data 
type for sets, but it does have Usts, which can be used to implement sets. Each 
condition can be represented by a symbol. Thus, a typical goal might be the list 
of two conditions (rich famous), and a typical current state might be (unknown 
poor). 
* We need a list of allowable operators. This list will be constant over the course 
of a problem, or even a series of problems, but we want to be able to change it 
and tackle a new problem domain. 
* An operator can be represented as a structure composed of an action, a list 
of preconditions, and a list of effects. We can place limits on the kinds of 
possible effects by saying that an effect either adds or deletes a condition from 
the current state. Thus, the list of effects can be split into an add-list and 
a delete-list. This was the approach taken by the STRIPS^ implementation of 
^STRIPS is the Stanford Research Institute Problem Solver, designed by Richard Pikes and 
NilsNilsson (1971). 


<a id='page-113'></a>

GPS, which we will be in effect reconstructing in this chapter. The original GPS 
allowed more flexibility in the specification of effects, but flexibility leads to 
inefficiency. 

* A complete problem is described to GPS in terms of a starting state, a goal state, 
and a set of known operators. Thus, GPS will be a function of three arguments. 
For example, a sample call might be: 
(GPS '(unknown poor) '(rich famous) list-of-ops) 

In other words, starting from the state of being poor and unknown, achieve the 
state of being rich and famous, using any combination of the known operators. 
GPS should return a true value only if it solves the problem, and it should print 
a record of the actions taken. The simplest approach is to go through the 
conditions in the goal state one at a time and try to achieve each one. If they 
can all be achieved, then the problem is solved. 

* A single goal condition can be achieved in two ways. If it is already in the 
current state, the goal is trivially achieved with no effort. Otherwise, we have 
to find some appropriate operator and try to apply it. 
* An operator is appropriate if one of the effects of the operator is to add the goal 
in question to the current state; in other words, if the goal is in the operator's 
add-list. 
* We can apply an operator if we can achieve all the preconditions. But this is 
easy, because we just defined the notion of achieving a goal in the previous 
paragraph. Once the preconditions have been achieved, applying an operator 
means executing the action and updating the current state in term of the operator's 
add-list and delete-list. Since our program is just a simulation—it won't 
be actually driving a car or dialing a telephone—we must be content simply to 
print out the action, rather than taking any real action. 
4.3 Stage 3: Implementation 
The specification is complete enough to lead directly to a complete Common Lisp 
program. Figure 4.1 summarizes the variables, data types, and functions that make 
up the GPS program, along with some of the Common Lisp functions used to implement 
it. 


<a id='page-114'></a>

Top-Level Function 
GPS Solve a goal from a state using a list of operators. 
Special Variables 
*state* The current state: a list of conditions. 
*ops* A list of available operators. 
Data Types 
op An operation with preconds, add-list and del-list. 
Functions 
achieve Achieve an individual goal. 
appropriate-p Decide if an operator is appropriate for a goal. 
apply-op Apply operator to current state. 
Selected Common Lisp Functions 
member Test if an element is a member of a list. (p. 78) 
set-difference All elements in one set but not the other. 
union All elements in either of two sets. 
every Test if every element of a list passes a test. (p. 62) 
some Test if any element of a list passes a test. 
Previously Defined Functions 
find-all A list of all matching elements, (p. 101) 
Figure 4.1: Glossary for the GPS Program 

Here is the complete GPS program itself: 

(defvar *state* nil "The current state: a list of conditions.") 

(defvar *ops* nil "A list of available operators.") 

(defstruct op "An operation" 
(action nil) (preconds nil) (add-list nil) (del-list nil)) 

(defun GPS (*state* goals *ops*) 
"General Problem Solver: achieve all goals using *ops*." 
(if (every #'achieve goals) 'solved)) 

(defun achieve (goal) 
"A goal is achieved if it already holds, 
or if there is an appropriate op for it that is applicable." 
(or (member goal *state*) 

(some #'apply-op 
(find-all goal *ops* :test #'appropriate-p)))) 

(defun appropriate-p (goal op) 
"An op is appropriate to a goal if it is in its add list." 
(member goal (op-add-list op))) 


<a id='page-115'></a>

(defun apply-op (op) 
"Print a message and update *state* if op is applicable." 
(when (every #*achieve (op-preconds op)) 

(print (list 'executing (op-action op))) 
(setf *state* (set-difference *state* (op-del-list op))) 
(setf *state* (union *state* (op-add-list op))) 
t)) 

We can see the program is made up of seven definitions. These correspond to the 
seven items in the specification above. In general, you shouldn't expect such a 
perfect fit between specification and implementation. There are two def var forms, 
one def s t r uct, and four defun forms. These are the Common Lisp forms for defining 
variables, structures, and functions, respectively. They are the most common top-
level forms in Lisp, but there is nothing magic about them; they are just special forms 
that have the side effect of adding new definitions to the Lisp environment. 

The two def var forms, repeated below, declare special variables named *state* 
and *ops*, which can then be accessed from anywhere in the program. 

(defvar *state* nil "The current state: a list of conditions.") 

(defvar *ops* nil "A list of available operators.") 

The defstruct form defines a structure called an op, which has slots called acti on, 
preconds, add -1 i st, and del -1 i st. Structures in Common Lisp are similar to structures 
in C, or records in Pascal. The defstruct automatically defines a constructor 
function, which is called make-op, and an access function for each slot of the structure. 
The access functions are called op-action, op-preconds, op-add-list, and 
op-del -1 ist. The defstruct also defines a copier function, copy-op, a predicate, 
op-p, and setf definitions for changing each slot. None of those are used in the GPS 
program. Roughly speaking, it is as if the defstruct form 

(defstruct op "An operation" 
(action nil) (preconds nil) (add-list nil) (del-list nil)) 

expanded into the following definitions: 

(defun make-op (&key action precondsadd-1ist del-1 ist) 
(vector 'op action preconds add-list del-list)) 

(defun op-action (op) (elt op 1)) 
(defun op-preconds (op) (elt op 2)) 
(defun op-add-list (op) (elt op 3)) 
(defun op-del-list (op) (elt op 4)) 

(defun copy-op (op) (copy-seq op)) 


<a id='page-116'></a>

(defun op-p (op) 
(and (vectorp op) (eq (elt op 0) Op))) 

(setf (documentation 'op 'structure) "An operation") 

Next in tlie GPS program are four function definitions. The main function, GPS, is 
passed three arguments. The first is the current state of the world, the second the 
goal state, and the third a list of allowable operators. The body of the function says 
simply that if we can achieve every one of the goals we have been given, then the 
problem is solved. The unstated alternative is that otherwise, the problem is not 
solved. 

The function a chi eve is given as an argument a single goal. The function succeeds 
if that goal is already true in the current state (in which case we don't have to do 
anything) or if we can apply an appropriate operator. This is accomplished by first 
building the list of appropriate operators and then testing each in turn until one can 
be applied, achieve calls find-al 1, which we defined on [page 101](chapter3.md#page-101). In this use, 
find-al 1 returns a list of operators that match the current goal, according to the 
predicate appropriate-p. 

The function appropriate-p tests if an operator is appropriate for achieving a 
goal. (It follows the Lisp naming convention that predicates end in - p.) 

Finally, the function apply-op says that if we can achieve all the preconditions 
for an appropriate operator, then we can apply the operator. This involves printing 
a message to that effect and changing the state of the world by deleting what was in 
the delete-list and adding what was in the add-Hst. apply-op is also a predicate; it 
returns t only when the operator can be applied. 

4.4 Stage 4: Test 
This section will define a list of operators applicable to the "driving to nursery school" 
domain and will show how to pose and solve some problems in that domain. First, 
we need to construct the list of operators for the domain. The defstruct form for the 
type op automatically defines the function make - op, which can be used as follows: 

(make-op :action 'drive-son-to-school 
ipreconds *(son-at-home car-works) 
:add-list '(son-at-school) 
:del-list '(son-at-home)) 

This expression returns an operator whose action is the symbol drive-son-to-school 
and whose preconditions, add-list and delete-list are the specified lists. The intent 


<a id='page-117'></a>

of this operator is that whenever the son is at home and the car works, dri ve-sonto-
school can be appHed, changing the state by deleting the fact that the son is at 
home, and adding the fact that he is at school. 

It should be noted that using long hyphenated atoms like son - at - home is a useful 
approach only for very simple examples like this one. A better representation would 
break the atom into its components: perhaps (at son home). The problem with 
the atom-based approach is one of combinatorics. If there are 10 predicates (such 
as at) and 10 people or objects, then there will be 10 . 10 . 10 = 1000 possible 
hyphenated atoms, but only 20 components. Clearly, it would be easier to describe 
the components. In this chapter we stick with the hyphenated atoms because it is 
simpler, and we do not need to describe the whole world. Subsequent chapters take 
knowledge representation more seriously. 

With this operator as a model, we can define other operators corresponding to 
Newell and Simon's quote on [page 109](chapter4.md#page-109). There will be an operator for installing a 
battery, telling the repair shop the problem, and telephoning the shop. We can fill in 
the "and so on" by adding operators for looking up the shop's phone number and for 
giving the shop money: 

(defparameter *school-ops* 
(list 

(make-op taction 'drive-son-to-school 
:preconds '(son-at-home car-works) 
:add-list '(son-at-school) 
:del-list '(son-at-home)) 

(make-op taction 'shop-installs-battery 
ipreconds '(car-needs-battery shop-knows-problem shop-has-money) 
:add-list '(car-works)) 

(make-op taction 'tell-shop-problem 
:preconds '(in-communication-with-shop) 
:add-list '(shop-knows-problem)) 

(make-op raction 'telephone-shop 
rpreconds '(know-phone-number) 
:add-list '(in-communication-with-shop)) 

(make-op .-action 'look-up-number 
ipreconds '(have-phone-book) 
:add-list '(know-phone-number)) 

(make-op taction 'give-shop-money 
ipreconds '(have-money) 
:add-list '(shop-has-money) 
:del-list '(have-money)))) 

The next step is to pose some problems to GPS and examine the solutions. Following 
are three sample problems. In each case, the goal is the same: to achieve the single 
condition son-at-school. The Hst of available operators is also the same in each 


<a id='page-118'></a>

problem; the difference is in the initial state. Each of the three examples consists of 
the prompt, ">", which is printed by the Lisp system, followed by a call to GPS, " (gps 
...which is typed by the user, then the output from the program, "(EXECUTING 
...)", and finally the result of the function call, which can be either SOLVED or NI L. 

> (gps '(son-at-home car-needs-battery have-money have-phone-book) 
'(son-at-school) 
*school-ops*) 

(EXECUTING LOOK-UP-NUMBER) 
(EXECUTING TELEPHONE-SHOP) 
(EXECUTING TELL-SHOP-PROBLEM) 
(EXECUTING GIVE-SHOP-MONEY) 
(EXECUTING SHOP-INSTALLS-BATTERY) 
(EXECUTING DRIVE-SON-TO-SCHOOL) 
SOLVED 

> (gps '(son-at-home car-needs-battery have-money) 
'(son-at-schoo1) 
*school-ops*) 

NIL 

> (gps '(son-at-home car-works) 
'(son-at-school) 
*school-ops*) 

(EXECUTING DRIVE-SON-TO-SCHOOL) 
SOLVED 

In all three examples the goal is to have the son at school. The only operator that 
has son-at-school in its add-list is drive-son-to-school, so GPS selects that operator 
initially. Before it can execute the operator, GPS has to solve for the preconditions. 
In the first example, the program ends up working backward through 
the operators shop-instal 1 s-battery, give-shop-money, tel 1 -shop-problem, and 
telephone-shop to look-up-number, whichhasnooutstandingpreconditions. Thus, 
the 1 ook-up-number action can be executed, and the program moves on to the other 
actions. As Aristotle said, "What is the last in the order of analysis seems to be first 
in the order of becoming." 

The second example starts out exactly the same, but the 1 ook - up-.umber operator 
fails because its precondition, have-phone-book, cannot be achieved. Knowing the 
phone number is a precondition, directly or indirectly, of all the operators, so no 
action is taken and GPS returns NIL. 

Finally, the third example is much more direct; the initial state specifies that the 
car works, so the driving operator can be applied immediately. 


<a id='page-119'></a>
4.5 Stage 5: Analysis, or ''We Lied about the C 
In the sections that follow, we examine the question of just how general this General 
Problem Solver is. The next four sections point out limitations of our version of GPS, 
and we will show how to correct these limitations in a second version of the program. 

One might ask if "limitations" is just a euphemism for "bugs." Are we "enhancing" 
the program, or are we "correcting" it? There are no clear answers on this point, 
because we never insisted on an unambiguous problem description or specification. 
AI programming is largely exploratory programming; the aim is often to discover 
more about the problem area rather than to meet a clearly defined specification. This 
is in contrast to a more traditional notion of programming, where the problem is 
completely specified before the first line of code is written. 

4.6 The Running Around the Block Problem 
Representing the operator "driving from home to school" is easy: the precondition 
and delete-list includes being at home, and the add-list includes being at school. But 
suppose we wanted to represent "running around the block." There would be no 
net change of location, so does that mean there would be no add- or delete-list? If 
so, there would be no reason ever to apply the operator. Perhaps the add-list should 
contain something like "got some exercise" or "feel tired," or something more general 
like "experience running around the block." We will return to this question later. 

4.7 The Clobbered Sibling Goal Problem 
Consider the problem of not only getting the child to school but also having some 
money left over to use for the rest of the day. GPS can easily solve this problem from 
the following initial condition: 

> (gps *(son-at-home have-money car-works) 
'(have-money son-at-school) 
*school-ops*) 

(EXECUTING DRIVE-SON-TO-SCHOOL) 
SOLVED 

However, in the next example GPS incorrectly reports success, when in fact it has 
spent the money on the battery. 


<a id='page-120'></a>

> (gps '(son-at-home car-needs-battery have-money have-phone-book) 
'(have-money son-at-school) 
^school-ops*) 

(EXECUTING LOOK-UP-NUMBER) 
(EXECUTING TELEPHONE-SHOP) 
(EXECUTING TELL-SHOP-PROBLEM) 
(EXECUTING GIVE-SHOP-MONEY) 
(EXECUTING SHOP-INSTALLS-BATTERY) 
(EXECUTING DRIVE-SON-TO-SCHOOL) 
SOLVED 

The "bug" is that GPS uses the expression (every #'achieve goals) to achieve 
a set of goals. If this expression returns true, it means that every one of the 
goals has been achieved in sequence, but it doesn't mean they are all still true 
at the end. In other words, the goal (have-money son-at-school), which we intended 
to mean "end up in a state where both have-money and son-at-school are 
true," was interpreted by GPS to mean "first achieve have-money, and then achieve 
son-at-school." Sometimes achieving one goal can undo another, previously 
achieved goal. We will call this the "prerequisite clobbers sibling goal" problem.^ 
That is, have-money and son-at-school are sibling goals, one of the prerequisites 
for the plan for son-at-school is car-works, and achieving that goal clobbers the 
have-money goal. 

Modifying the program to recognize the "prerequisite clobbers sibling goal" problem 
is straightforward. First note that we call (every #'achieve something) twice 
within the program, so let's replace those two forms with (achi eve - al 1 something). 
We can then define achi eve-al 1 as follows: 

(defun achieve-all (goals) 
"Try to achieve each goal, then make sure they still hold." 
(and (every #'achieve goals) (subsetp goals *state*))) 

The Common Lisp function subsetp returns true if its first argument is a subset of its 
second. In achi eve-al 1, it returns true if every one of the goals is still in the current 
state after achieving all the goals. This is just what we wanted to test. 

The introduction of achi eve-al 1 prevents GPS from returning true when one of 
the goals gets clobbered, but it doesn't force GPS to replan and try to recover from a 
clobbered goal. We won't consider that possibility now, but we will take it up again 
in the section on the blocks world domain, which was Sussman's primary example. 

^Gerald Sussman, in his book A Computer Model of Skill Acquisition, uses the term "prerequisite 
clobbers brother goal" or PCBG. I prefer to be gender neutral, even at the risk of being 
labeled a historical revisionist. 


<a id='page-121'></a>
4 . 8 The Leaping before You Look Problem 

Another way to address the "prerequisite clobbers sibling goal" problem is just to be 
more careful about the order of goals in a goal list. If we want to get the kid to school 
and still have some money left, why not just specify the goal as (son-at-school 
have-money) rather than (have-money son-at-school)? Let's see what happens 
when we try that: 

> (gps '(son-at-home car-needs-battery have-money have-phone-book) 
'(son-at-school have-money) 
*school-ops*) 

(EXECUTING LOOK-UP-NUMBER) 
(EXECUTING TELEPHONE-SHOP) 
(EXECUTING TELL-SHOP-PROBLEM) 
(EXECUTING GIVE-SHOP-MONEY) 
(EXECUTING SHOP-INSTALLS-BATTERY) 
(EXECUTING DRIVE-SON-TO-SCHOOL) 
NIL 

GPS returns nil, reflecting the fact that the goal cannot be achieved, but only after 
executing all actions up to and including driving to school. I call this the "leaping 
before you look" problem, because if you asked the program to solve for the two goals 
(j ump - of f -c 1 i f f 1 a nd -sa f e1 y) it would happily jump first, only to discover that it 
had no operator to land safely. This is less than prudent behavior. 

The problem arises because planning and execution are interleaved. Once the 
preconditions for an operator are achieved, the action is taken—and *sta te* is irrevocably 
changed—even if this action may eventually lead to a dead end. An alternative 
would be to replace the single global *state* with distinct local state variables, such 
that a new variable is created for each new state. This alternative is a good one for 
another, independent reason, as we shall see in the next section. 

4.9 The Recursive Subgoal Problem 
In our simulated nursery school world there is only one way to find out a phone 
number: to look it up in the phone book. Suppose we want to add an operator for 
finding out a phone number by asking someone. Of course, in order to ask someone 
something, you need to be in communication with him or her. The asking-for-a-
phone-number operator could be implemented as follows: 


<a id='page-122'></a>

(push (make-op :action 'ask-phone-number 
:preconds '(in-communication-with-shop) 
;add-list '(know-phone-number)) 

*school-ops*) 

(The special form (push item list) puts the item on the front of the list; it is equivalent 
to (setf list (cons item /fsO) in the simple case.) Unfortunately, something 
unexpected happens when we attempt to solve seemingly simple problems with this 
new set of operators. Consider the following: 

> (gps *(son-at-home car-needs-battery have-money) 
'(son-at-school) 
*school-ops*) 

>TRAP 14877 (SYSTEM:PDL-OVERFLOW EH::REGULAR) 
The regular push-down list has overflown. 
While in the function ACHIEVE <- EVERY <- REMOVE 

The error message (which will vary from one implementation of Common Lisp to 
another) means that too many recursively nested function calls were made. This 
indicates either a very complex problem or, more commonly, a bug in the program 
leading to infinite recursion. One way to try to see the cause of the bug is to trace a 
relevant function, such as achi eve: 

> (trace achieve) => (ACHIEVE) 

> (gps '(son-at-home car-needs-battery have-money) 
'(son-at-school) 
*school-ops*) 

(1 ENTER ACHIEVE: SON-AT-SCHOOL) 
(2 ENTER ACHIEVE: SON-AT-HOME) 
(2 EXIT ACHIEVE: (SON-AT-HOME CAR-NEEDS-BATTERY HAVE-MONEY)) 
(2 ENTER ACHIEVE: CAR-WORKS) 

(3 ENTER ACHIEVE: CAR-NEEDS-BATTERY) 
(3 EXIT ACHIEVE: (CAR-NEEDS-BATTERY HAVE-MONEY)) 
(3 ENTER ACHIEVE: SHOP-KNOWS-PROBLEM) 

(4 ENTER ACHIEVE: IN-COMMUNICATION-WITH-SHOP) 
(5 ENTER ACHIEVE: KNOW-PHONE-NUMBER) 
(6 ENTER ACHIEVE: IN-COMMUNICATION-WITH-SHOP) 
(7 ENTER ACHIEVE: KNOW-PHONE-NUMBER) 
(8 ENTER ACHIEVE: IN-COMMUNICATION-WITH-SHOP) 
(9 ENTER ACHIEVE: KNOW-PHONE-NUMBER) 


<a id='page-123'></a>
The output from trace gives us the necessary clues. Newell and Simon talk of 
"oscillating among ends, functions required, and means that perform them." Here 
it seems we have an infinite oscillation between being in communication with the 
shop (levels 4, 6, 8,...) and knowing the shop's phone number (levels 5, 7, 9,...). 
The reasoning is as follows: we want the shop to know about the problem with the 
battery, and this requires being in communication with him or her. One way to get in 
communication is to phone, but we don't have a phone book to look up the number. 
We could ask them their phone number, but this requires being in communication 
with them. As Aristotle put it, "If we are to be always deliberating, we shall have to 
go on to infinity." We will call this the "recursive subgoal" problem: trying to solve 
a problem in terms of itself. One way to avoid the problem is to have achi eve keep 
track of all the goals that are being worked on and give up if it sees a loop in the 
goal stack. 

4.10 The Lack of Intermediate Information 
Problem 
When GPS fails to find a solution, it just returns nil. This is annoying in cases where 
the user expected a solution to be found, because it gives no information about the 
cause of failure. The user could always trace some function, as we traced achi eve 
above, but the output from trace is rarely exactly the information desired. It would 
be nice to have a general debugging output tool where the programmer could insert 
print statements into his code and have them selectively printed, depending on the 
information desired. 

The function dbg provides this capability, dbg prints output in the same way as 
format, but it will only print when debugging output is desired. Each call to dbg is 
accompanied by an identifer that is used to specify a class of debugging messages. 
The functions debug and undebug are used to add or remove message classes to the 
list of classes that should be printed. In this chapter, all the debugging output will 
use the identifier :gps. Other programs will use other identifiers, and a complex 
program will use many identifiers. 

A call to dbg will result in output if the first argument to dbg, the identifier, is one 
that was specified in a call to debug. The other arguments to dbg are a format string 
followed by a list of arguments to be printed according to the format string. In other 
words, we will write functions that include calls to dbg like: 

(dbg :gps "The current goal is: ~a" goal) 

If we have turned on debugging with (debug :gps), then calls to dbg with the 
identifier :gps will print output. The output is turned off with (undebug :gps). 


<a id='page-124'></a>

debug and undebug are designed to be similar to trace and untrace, in that they turn 
diagnostic output on and off. They also follow the convention that debug with no 
arguments returns the current list of identifiers, and that undebug with no arguments 
turns all debugging off. However, they differ from trace and untrace in that they 
are functions, not macros. If you use only keywords and integers for identifiers, then 
you won't notice the difference. 

Two new built-in features are introduced here. First, *debug-io* is the stream 
normally used for debugging input/output. In all previous calls to format we have 
used t as the stream argument, which causes output to go to the *standa rd - output* 
stream. Sending different types of output to different streams allows the user some 
flexibility. For example, debugging output could be directed to a separate window, 
or it could be copied to a file. Second, the function fresh -1i ne advances to the next 
line of output, unless the output stream is already at the start of the line. 

(defvar *dbg-ids* nil "Identifiers used by dbg") 

(defun dbg (id format-string &rest args) 
"Print debugging info if (DEBUG ID) has been specified." 
(when (member id *dbg-ids*) 

(fresh-line *debug-io*) 
(apply #'format *debug-io* format-string args))) 

(defun debug (&rest ids) 
"Start dbg output on the given ids. " 
(setf *dbg-ids* (union ids *dbg-ids*))) 

(defun undebug (&rest ids) 
"Stop dbg on the ids. With no ids. stop dbg altogether." 
(setf *dbg-ids* (if (null ids) nil 

(set-difference *dbg-ids* ids)))) 

Sometimes it is easier to view debugging output if it is indented according to some 
pattern, such as the depth of nested calls to a function. To generate indented output, 
the function dbg -1 ndent is defined: 

(defun dbg-indent (id indent format-string &rest args) 
"Print indented debugging info if (DEBUG ID) has been specified." 
(when (member id *dbg-ids*) 

(fresh-line *debug-io*) 
(dotimes (i indent) (princ " " *debug-io*)) 
(apply #*format *debug-io* format-string args))) 


<a id='page-125'></a>
4.11 GPS Version 2: A More General 
Problem Solver 
At this point we are ready to put together a new version of GPS with solutions for 
the "running around the block," "prerequisite clobbers sibling goal," "leaping before 
you look," and "recursive subgoal" problems. The glossary for the new version is in 
figure 4.2. 

Top-Level Function 
GPS Solve a goal from a state using a list of operators. 
Special Variables 
*ops* A list of available operators. 
Data Types 
op An operation with preconds, add-list and del-Hst. 
Major Functions 
achieve-all Achieve a list of goals. 
achieve Achieve an individual goal. 
appropriate-p Decide if an operator is appropriate for a goal. 
apply-op Apply operator to current state. 
Auxiliary Functions 
executing-p Is a condition an executi ng form? 
starts-with Is the argument a list that starts with a given atom? 
convert-op Convert an operator to use the executi ng convention. 
op Create an operator. 
use Use a list of operators. 
member-equal Test if an element is equal to a member of a list. 
Selected Common Lisp Functions 
member Test if an element is a member of a list. (p. 78) 
set -difference All elements in one set but not the other. 
subsetp Is one set wholly contained in another? 
union All elements in either of two sets. 
every Test if every element of a list passes a test. (p. 62) 
some Test if any element of a list passes a test. 
remove-if Remove all items satisfying a test. 
Previously Defined Functions 
find-all A list of all matching elements, (p. 101) 
find-all-if A list of all elements satisfying a predicate. 
Figure 4.2: Glossary for Version 2 of GPS 

The most important change is that, instead of printing a message when each 
operator is applied, we will instead have GPS return the resulting state. A list of 


<a id='page-126'></a>

"messages" in each state indicates what actions have been taken. Each message is 
actuallyacondition,aHstof the form (executing operator). This solves the "running 
around the block" problem: we could call GPS with an initial goal of ((executing 
run -a round - bl ock)), and it would execute the run -a round - bl ock operator, thereby 
satisfying the goal. The following code defines a new function, op, which builds 
operators that include the message in their add-list. 

(defun executing-p (x) 
"Is X of the form: (executing ...) ? " 
(starts-with . 'executing)) 

(defun starts-with (list x) 
"Is this a list whose first element is x?" 
(and (consp list) (eql (first list) x))) 

(defun convert-op (op) 
"Make op conform to the (EXECUTING op) convention." 
(unless (some #'executing-p (op-add-list op)) 

(push (list 'executing (op-action op)) (op-add-list op))) 
op) 

(defun op (action &key preconds add-list del-list) 
"Make a new operator that obeys the (EXECUTING op) convention." 
(convert-op 

(make-op :action action :preconds preconds 
:add-list add-list :del-list del-list))) 

Operators built by op will be correct, but we can convert existing operators using 
convert-op directly: 

(mapc #'convert-op ^school-ops*) 

This is an example of exploratory programming: instead of starting all over when 
we discover a limitation of the first version, we can use Lisp to alter existing data 
structures for the new version of the program. 

The definition of the variable *ops* and the structure op are exactly the same as 
before, and the rest of the program consists of five functions we have already seen: 
GPS, achieve -all, achieve, appropriate-p, and apply-op. At the top level, the 
function GPS calls achieve-al 1, which returns either nil or a valid state. From this 
we remove all the atoms, which leaves only the elements of the final state that are 
lists—in other words, the actions of the form (executi ng operator). Thus, the value 
of GPS itself is the Hst of actions taken to arrive at the final state. GPS no longer returns 
SOLVED when it finds a solution, but it still obeys the convention of returning nil for 
failure, and non-nil for success. In general, it is a good idea to have a program return 


<a id='page-127'></a>
a meaningful value rather than print that value, if there is the possibility that some 
other program might ever want to use the value. 

(defvar *ops* nil "A list of available operators.") 

(defstruct op "An operation" 
(action nil) (preconds nil) (add-list nil) (del-list nil)) 

(defun GPS (state goals &optional (*ops* *ops*)) 
"General Problem Solver: from state, achieve goals using *ops*." 
(remove-if #'atom (achieve-all (cons '(start) state) goals nil))) 

The first major change in version 2 is evident from the first line of the program: there 
is no *state* variable. Instead, the program keeps track of local state variables. 
This is to solve the "leaping before you look" problem, as outlined before. The 
functions achieve, achieve-al 1, and apply-op all take an extra argument which is 
the current state, and all return a new state as their value. They also must still obey 
the convention of returning nil when they fail. 

Thus we have a potential ambiguity: does nil represent failure, or does it represent 
a valid state that happens to have no conditions? We resolve the ambiguity 
by adopting the convention that all states must have at least one condition. This 
convention is enforced by the function GPS. Instead of calling (achieve-al 1 state 
goals nil), GPS calls (achieve-all (cons '(start) state) goals nil). Soeven 
if the user passes GPS a null initial state, it will pass on a state containing (start ) 
to achieve-al 1. From then on, we are guaranteed that no state will ever become 
nil, because the only function that builds a new state is apply - op, and we can see by 
looking at the last line of appl y - op that it always appends something onto the state it 
is returning. (An add-list can never be nil, because if it were, the operator would not 
be appropriate. Besides, every operator includes the (executi ng ... ) condition.) 

Note that the final value we return from GPS has all the atoms removed, so we end 
up reporting only the actions performed, since they are represented by conditions 
of the form (executi ng action). Adding the (start ) condition at the beginning also 
serves to differentiate between a problem that cannot be solved and one that is solved 
without executing any actions. Failure returns nil, while a solution with no steps will 
at least include the (sta rt) condition, if nothing else. 

Functions that return nil as an indication of failure and return some useful value 
otherwise are known as semipredicates. They are error prone in just these cases 
where nil might be construed as a useful value. Be careful when defining and using 
semipredicates: (1) Decide if nil could ever be a meaningful value. (2) Insure that 
the user can't corrupt the program by supplying nil as a value. In this program, GPS 
is the only function the user should call, so once we have accounted for it, we're 
covered. (3) Insure that the program can't supply nil as a value. We did this by seeing 
that there was only one place in the program where new states were constructed, 
and that this new state was formed by appending a one-element list onto another 


<a id='page-128'></a>

state. By following this three-step procedure, we have an informal proof that the 
semipredicates involving states will function properly. This kind of informal proof 
procedure is a common element of good program design. 

The other big change in version 2 is the introduction of a goal stack to solve the 
recursive subgoal problem. The program keeps track of the goals it is working on 
and immediately fails if a goal appears as a subgoal of itself. This test is made in the 
second clause of achi eve. 

The function a chi eve -a 11 tries to achieve each one of the goals in turn, setting the 
variable state2 to be the value returned from each successive call to achi eve. If all 
goals are achieved in turn, and if all the goals still hold at the end (as subsetp checks 
for), then the final state is returned; otherwise the function fails, returning nil. 

Most of the work is done by achieve, which gets passed a state, a single goal 
condition, and the stack of goals worked on so far. If the condition is already in the 
state, then achieve succeeds and returns the state. On the other hand, if the goal 
condition is already in the goal stack, then there is no sense continuing—we will be 
stuck in an endless loop—so achi eve returns nil. Otherwise, achi eve looks through 
the list of operators, trying to find one appropriate to apply. 

(defun achieve-all (state goals goal-stack) 
"Achieve each goal, and make sure they still hold at the end." 
(let ((current-state state)) 

(if (and (every #'(lambda (g) 
(setf current-state 
(achieve current-state g goal-stack))) 
goals) 
(subsetp goals current-state rtest #'equal)) 
current-state))) 

(defun achieve (state goal goal-stack) 
"A goal is achieved if it already holds, 
or if there is an appropriate op for it that is applicable." 
(dbg-indent :gps (length goal-stack) "Goal: "a" goal) 
(cond ((member-equal goal state) state) 

((member-equal goal goal-stack) nil) 
(t (some #'(lambda (op) (apply-op state goal op goal-stack)) 
(find-all goal *ops* :test #*appropriate-p))))) 

The goal ((executing run-around-block)) is a list of one condition, where the 
condition happens to be a two-element list. Allowing lists as conditions gives us 
more flexibility, but we also have to be careful. The problem is that not all Usts that 
look alike actually are the same. The predicate equal essentially tests to see if its two 
arguments look alike, while the predicate eql tests to see if its two arguments actually 
are identical. Since functions like member use eql by default, we have to specify with 
a :test keyword that we want equal instead. Since this is done several times, we 


<a id='page-129'></a>
introduce the function member-equal. In fact, we could have carried the abstraction 
one step further and defined member-situation, a function to test if a condition is 
true in a situation. This would allow the user to change the matching function from 
eql to equal, and to anything else that might be useful. 

(defun member-equal (item list) 
(member item list :test #*equal)) 

The function apply-op, which used to change the state irrevocably and print a message 
reflecting this, now returns the new state instead of printing anything. It first 
computes the state that would result from achieving all the preconditions of the 
operator. If it is possible to arrive at such a state, then apply-op returns a new state 
derived from this state by adding what's in the add-list and removing everything in 
the delete-list. 

(defun apply-op (state goal op goal-stack) 
"Return a new, transformed state if op is applicable." 
(dbg-indent :gps (length goal-stack) "Consider: ~a" (op-action op)) 
(let ((state2 (achieve-all state (op-preconds op) 

(cons goal goal-stack)))) 

(unless (null state2) 
;; Return an updated state 
(dbg-indent :gps (length goal-stack) "Action: ~a" (op-action op)) 
(append (remove-if #*(lambda (x) 

(member-equal . (op-del-list op))) 
stateZ) 
(op-add-list op))))) 

(defun appropriate-p (goal op) 
"An op is appropriate to a goal if it is in its add-list." 
(member-equal goal (op-add-list op))) 

There is one last complication in the way we compute the new state. In version 
1 of GPS, states were (conceptually) unordered sets of conditions, so we could use 
uni on and set -di f f erence to operate on them. In version 2, states become ordered 
lists, because we need to preserve the ordering of actions. Thus, we have to use the 
functions append and remove-if, since these are defined to preserve order, while 
union and set -difference are not. 

Finally, the last difference in version 2 is that it introduces a new function: use. 
This function is intended to be used as a sort of declaration that a given list of operators 
is to be used for a series of problems. 


<a id='page-130'></a>

(defun use (oplist) 

"Use oplist as the default list of operators." 
Return something useful, but not too verbose: 
the number of operators, 

(length (setf *ops* oplist))) 

Calling use sets the parameter *ops*, so that it need not be specified on each call 
to GPS. Accordingly, in the definition of GPS itself the third argument, *ops*, is now 
optional; if it is not supplied, a default will be used. The default value for *ops* is 
given as *ops*. This may seem redundant or superfluous—how could a variable be 
its own default? The answer is that the two occurrences of *ops* look alike, but they 
actually refer to two completely separate bindings of the special variable *ops*. Most 
of the time, variables in parameter lists are local variables, but there is no rule against 
binding a special variable as a parameter. Remember that the effect of binding a 
special Vciriable is that all references to the special variable that occur anywhere in 
the program—even outside the lexical scope of the function—refer to the new binding 
of the special variable. So after a sequence of calls we eventually reach achieve, 
which references *ops*, and it will see the newly bound value of *ops*. 

The definition of GPS is repeated here, along with an alternate version that binds 
a local variable and explicitly sets and resets the special variable *ops*. Clearly, 
the idiom of binding a special variable is more concise, and while it can be initially 
confusing, it is useful once understood. 

(defun GPS (state goals &optional (*ops* *ops*)) 
"General Problem Solver: from state, achieve goals using *ops*." 
(remove-if #'atom (achieve-all (cons '(start) state) goals nil))) 

(defun GPS (state goals &optional (ops *ops*)) 
"General Problem Solver: from state, achieve goals using *ops*." 
(let ((old-ops *ops*)) 

(setf *ops* ops) 

(let ((result (remove-if #'atom (achieve-all 
(cons '(start) state) 
goalsnil)))) 

(setf *ops* old-ops) 
result))) 

Now let's see how version 2 performs. We use the list of operators that includes the 
"asking the shop their phone number" operator. First we make sure it will still do the 
examples version 1 did: 

> (use *school-ops*) 7 


<a id='page-131'></a>
> (gps '(son-at-home car-needs-battery have-money have-phone-book) 
'(son-at-school)) 

((START) 
(EXECUTING LOOK-UP-NUMBER) 
(EXECUTING TELEPHONE-SHOP) 
(EXECUTING TELL-SHOP-PROBLEM) 
(EXECUTING GIVE-SHOP-MONEY) 
(EXECUTING SHOP-INSTALLS-BATTERY) 
(EXECUTING DRIVE-SON-TO-SCHOOL)) 

> (debug :gps) => (:GPS) 

> (gps '(son-at-home car-needs-battery have-money have-phone-book) 

'(son-at-school)) 
Goal: SON-AT-SCHOOL 
Consider: DRIVE-SON-TO-SCHOOL 

Goal: SON-AT-HOME 
Goal: CAR-WORKS 
Consider: SHOP-INSTALLS-BATTERY 

Goal: CAR-NEEDS-BATTERY 
Goal: SHOP-KNOWS-PROBLEM 
Consider: TELL-SHOP-PROBLEM 

Goal: IN-COMMUNICATION-WITH-SHOP 

Consider: TELEPHONE-SHOP 
Goal: KNOW-PHONE-NUMBER 
Consider: ASK-PHONE-NUMBER 

Goal: IN-COMMUNICATION-WITH-SHOP 
Consider: LOOK-UP-NUMBER 
Goal: HAVE-PHONE-BOOK 
Action: LOOK-UP-NUMBER 

Action: TELEPHONE-SHOP 
Action: TELL-SHOP-PROBLEM 
Goal: SHOP-HAS-MONEY 
Consider: GIVE-SHOP-MONEY 

Goal: HAVE-MONEY 
Action: GIVE-SHOP-MONEY 

Action: SHOP-INSTALLS-BATTERY 
Action: DRIVE-SON-TO-SCHOOL 
((START) 

(EXECUTING LOOK-UP-NUMBER) 
(EXECUTING TELEPHONE-SHOP) 
(EXECUTING TELL-SHOP-PROBLEM) 
(EXECUTING GIVE-SHOP-MONEY) 
(EXECUTING SHOP-INSTALLS-BATTERY) 
(EXECUTING DRIVE-SON-TO-SCHOOL)) 

> (undebug) NIL 


<a id='page-132'></a>

> (gps *(son-at-home car-works) 
'(son-at-school)) 
((START) 
(EXECUTING DRIVE-SON-TO-SCHOOL)) 

Now we see that version 2 can also handle the three cases that version 1 got wrong. 
In each case, the program avoids an infinite loop, and also avoids leaping before 
it looks. 

> (gps '(son-at-home car-needs-battery have-money have-phone-book) 
'(have-money son-at-school)) 
NIL 

> (gps '(son-at-home car-needs-battery have-money have-phone-book) 
'(son-at-school have-money)) 
NIL 

> (gps '(son-at-home car-needs-battery have-money) 
'(son-at-school)) 
NIL 

Finally, we see that this version of GPS also works on trivial problems requiring no 
action: 

> (gps '(son-at-home) '(son-at-home)) => ((START)) 

4.12 The New Domain Problem: Monkey 
and Bananas 
To show that GPS is at all general, we have to make it work in different domains. We 
will start with a "classic" AI problem.^ Imagine the following scenario: a hungry 
monkey is standing at the doorway to a room. In the middle of the room is a bunch 
of bananas suspended from the ceiling by a rope, well out of the monkey's reach. 
There is a chair near the door, which is light enough for the monkey to push and tall 
enough to reach almost to the bananas. Just to make things complicated, assume the 
monkey is holding a toy ball and can only hold one thing at a time. 

In trying to represent this scenario, we have some flexibility in choosing what to 
put in the current state and what to put in with the operators. For now, assume we 
define the operators as follows: 

^Originally posed by Saul Amarel (1968). 


<a id='page-133'></a>
(defparameter *banana-ops* 
(list 

(op 'climb-on-chair 
ipreconds '(chair-at-middle-room at-middle-room on-floor) 
:add-list '(at-bananas on-chair) 
:del-list '(at-middle-room on-floor)) 

(op 'push-chair-from-door-to-middle-room 
:preconds '(chair-at-door at-door) 
:add-list '(chair-at-middle-room at-middle-room) 
:del-list '(chair-at-door at-door)) 

(op 'walk-from-door-to-middle-room 
ipreconds '(at-door on-floor) 
;add-list '(at-middle-room) 
:del-list '(at-door)) 

(op 'grasp-bananas 
rpreconds '(at-bananas empty-handed) 
:add-list '(has-bananas) 
:del-list '(empty-handed)) 

(op 'drop-ball 
ipreconds '(has-ball) 
ladd-list '(empty-handed) 
idel-list '(has-balD) 

(op 'eat-bananas 
ipreconds '(has-bananas) 
ladd-list '(empty-handed not-hungry) 
idel-list '(has-bananas hungry)))) 

Using these operators, we could pose the problem of becoming not-hungry, given 
the initial state of being at the door, standing on the floor, holding the ball, hungry, 
and with the chair at the door. GPS can find a solution to this problem: 

> (use *banana-ops*) => 6 

> (GPS '(at-door on-floor has-ball hungry chair-at-door) 
'(not-hungry)) 

((START) 
(EXECUTING PUSH-CHAIR-FROM-DOOR-TO-MIDDLE-ROOM) 
(EXECUTING CLIMB-ON-CHAIR) 
(EXECUTING DROP-BALL) 
(EXECUTING GRASP-BANANAS) 
(EXECUTING EAT-BANANAS)) 

Notice we did not need to make any changes at all to the GPS program. We just used 
a different set of operators. 


<a id='page-134'></a>

4.13 The Maze Searching Domain 
Now we will consider another "classic" problem, maze searching. We will assume a 
particular maze, diagrammed here. 

1 2 3 4 5 
6 7 8 9 10 
11 12 13 14 15 
16 17 18 19 20 
21 22 23 24 25 

It is much easier to define some functions to help build the operators for this 
domain than it would be to type in all the operators directly. The following code 
defines a set of operators for mazes in general, and for this maze in particular: 

(defun make-maze-ops (pair) 
"Make maze ops in both directions" 
(list (make-maze-op (first pair) (second pair)) 

(make-maze-op (second pair) (first pair)))) 

(defun make-maze-op (here there) 
"Make an operator to move between two places" 
(op '(move from ,here to .there) 

ipreconds '((at .here)) 
:add-list '((at .there)) 
:del-list '((at .here)))) 

(defparameter *maze-ops* 
(mappend #'make-maze-ops 

'((1 2) (2 3) (3 4) (4 9) (9 14) (9 8) (8 7) (7 12) (12 13) 
(12 11) (11 6) (11 16) (16 17) (17 22) (21 22) (22 23) 
(23 18) (23 24) (24 19) (19 20) (20 15) (15 10) (10 5) (20 25)))) 

Note the backquote notation, (It is covered in section 3.2, [page 67](chapter3.md#page-67). 
We can now use this list of operators to solve several problems with this maze. 
And we could easily create another maze by giving another list of connections. Note 
that there is nothing that says the places in the maze are arranged in a five-by-five 
layout—that is just one way of visualizing the connectivity. 

> (use *maze-ops*) 48 


<a id='page-135'></a>
> (gps '((at D) '((at 25))) 

((START) 
(EXECUTING (MOVE FROM 1 TO 2)) 
(EXECUTING (MOVE FROM 2 TO 3)) 
(EXECUTING (MOVE FROM 3 TO 4)) 
(EXECUTING (MOVE FROM 4 TO 9)) 
(EXECUTING (MOVE FROM 9 TO 8)) 
(EXECUTING (MOVE FROM 8 TO 7)) 
(EXECUTING (MOVE FROM 7 TO 12)) 
(EXECUTING (MOVE FROM 12 TO ID ) 
(EXECUTING (MOVE FROM 11 TO 16)) 
(EXECUTING (MOVE FROM 16 TO 17)) 
(EXECUTING (MOVE FROM 17 TO 22)) 
(EXECUTING (MOVE FROM 22 TO 23)) 
(EXECUTING (MOVE FROM 23 TO 24)) 
(EXECUTING (MOVE FROM 24 TO 19)) 
(EXECUTING (MOVE FROM 19 TO 20)) 
(EXECUTING (MOVE FROM 20 TO 25)) 
(AT 25)) 

There is one subtle bug that the maze domain points out. We wanted GPS to return 
a list of the actions executed. However, in order to account for the case where the 
goal can be achieved with no action, I included (START) in the value returned by 
GPS. These examples include the START and EXECUTING forms but also a list of the 
form (AT n), for some n. This is the bug. If we go back and look at the function 
GPS, we find that it reports the result by removing all atoms from the state returned 
by achieve-al 1 . This is a "pun"—we said remove atoms, when we really meant 
to remove all conditions except the (START) and (EXECUTING action) forms. Up to 
now, all these conditions were atoms, so this approach worked. The maze domain 
introduced conditions of the form (AT n), so for the first time there was a problem. 
The moral is that when a programmer uses puns—saying what's convenient instead 
of what's really happening—there's bound to be trouble. What we really want to do 
is not to remove atoms but to find all elements that denote actions. The code below 
says what we mean: 

(defun GPS (state goals &optional (*ops* *ops*)) 
"General Problem Solver: from state, achieve goals using *ops*." 
(find-all-if #*action-p 

(achieve-all (cons '(start) state) goals nil))) 


<a id='page-136'></a>

(defun action-p (x) 
"Is . something that is (start) or (executing ...)? " 
(or (equal . '(start)) (executing-p x))) 

The domain of maze solving also points out an advantage of version 2: that it returns 
a representation of the actions taken rather than just printing them out. The reason 
this is an advantage is that we may want to use the results for something, rather than 
just look at them. Suppose we wanted a function that gives us a path through a maze 
as a list of locations to visit in turn. We could do this by calling GPS as a subfunction 
and then manipulating the results: 

(defun find-path (start end) 
"Search a maze for a path from start to end." 
(let ((results (GPS '((at .start)) '((at .end))))) 

(unless (null results) 
(cons start (mapcar #'destination 
(remove '(start) results 
:test #'equal)))))) 

(defun destination (action) 
"Find the Y in (executing (move from X to Y))" 
(fifth (second action))) 

The function f i nd - path calls GPS to get the resul ts. If this is ni 1, there is no answer, 
but if it is not, then take the rest of results (in other words, ignore the (START) part). 
Pick out the destination,!/, from each (EXECUTING (MOVE FROM . TO y)) form, and 
remember to include the starting point. 

> (use *maze-ops*) => 48 

> (find-path 1 25) ^ 
(1 2 3 4 9 8 7 12 11 16 17 22 23 24 19 20 25) 

> (find-path 1 1) (1) 

> (equal (find-path 1 25) (reverse (find-path 25 1))) => . 

4.14 The Blocks World Domain 

Another domain that has attracted more than its share of attention in AI circles is 
the blocks world domain. Imagine a child's set of building blocks on a table top. 
The problem is to move the blocks from their starting configuration into some goal 
configuration. We will assume that each block can have only one other block directly 


<a id='page-137'></a>
on top of it, although they can be stacked to arbitrary height. The only action that 
can be taken in this world is to move a single block that has nothing on top of it either 
to the top of another block or onto the table that represents the block world. We will 
create an operator for each possible block move. 

(defun make-block-ops (blocks) 
(let ((ops nil)) 
(dolist (a blocks) 
(dolist (b blocks) 
(unless (equal a b) 
(dolist (c blocks) 
(unless (or (equal c a) (equal c b)) 

(push (move-op abc) ops))) 
(push (move-op a 'table b) ops) 
(push (move-op a b 'table) ops)))) 

ops)) 

(defun move-op (a b c) 
"Make an operator to move A from . to C. " 
(op '(move .a from .b to ,c) 

ipreconds '((space on ,a) (space on ,c) (,a on .b)) 
ladd-list (move-ons abc) 
idel-list (move-ons a c b))) 

(defun move-ons (a b c) 

(if (eq b 'table) 
*((,a on ,c)) 
*((.a on ,c) (space on ,b)))) 

Now we try these operators out on some problems. The simplest possible problem 
is stacking one block on another: 

. 
start goal 

> (use (make-block-ops '(a b))) => 4 

> (gps '((a on table) (b on table) (space on a) (space on b) 
(space on table)) 
'((a on b) (b on table))) 
((START) 
(EXECUTING (MOVE A FROM TABLE TO B))) 


<a id='page-138'></a>

Here is a slightly more complex problem: inverting a stack of two blocks. This time 
we show the debugging output. 

start goa 

> (debug :gps) (:GPS) 

> (gps *((a on b) (b on table) (space on a) (space on table)) 

'((b on a))) 
Goal: (B ON A) 
Consider: (MOVE . FROM TABLE TO A) 

Goal: (SPACE ON B) 

Consider: (MOVE A FROM . TO TABLE) 
Goal: (SPACE ON A) 
Goal: (SPACE ON TABLE) 
Goal: (A ON B) 

Action: (MOVE A FROM . TO TABLE) 
Goal: (SPACE ON A) 
Goal: (B ON TABLE) 

Action: (MOVE . FROM TABLE TO A) 

((START) 
(EXECUTING (MOVE A FROM . TO TABLE)) 
(EXECUTING (MOVE . FROM TABLE TO A))) 

> (undebug) NIL 

Sometimes it matters what order you try the conjuncts in. For example, you can't 
have your cake and eat it too, but you can take a picture of your cake and eat it too, as 
long as you take the picture before eating it. In the blocks world, we have: 

A 
_B_ 
C 

start

> (use (make-block-ops '(a b c))) 18 

> (gps '((a on b) (b on c) (c on table)
'((b on a) (c on b))) 

((START) 
(EXECUTING (MOVE A FROM . TO TABLE)) 
(EXECUTING (MOVE . FROM C TO A)) 
(EXECUTING (MOVE C FROM TABLE TO B))) 

C 

_B_ 

A 

 goal 

 (space on a) (space on table)) 


<a id='page-139'></a>
> (gps '((a on b) (b on c) (c on table) (space on a) (space on table)) 
'((c on b) (b on a))) 
NIL 

In the first case, the tower was built by putting . on A first, and then C on B. In 
the second case, the program gets C on . first, but clobbers that goal while getting . 
on A. The "prerequisite clobbers sibling goal" situation is recognized, but the program 
doesn't do anything about it. One thing we could do is try to vary the order of the 
conjunct goals. That is, we could change achieve-al 1 as follows: 

(defun achieve-all (state goals goal-stack) 
"Achieve each goal, trying several orderings." 
(some #'(lambda (goals) (achieve-each state goals goal-stack)) 

(orderings goals))) 

(defun achieve-each (state goals goal-stack) 
"Achieve each goal, and make sure they still hold at the end." 
(let ((current-state state)) 

(if (and (every #'(lambda (g) 
(setf current-state 
(achieve current-state g goal-stack))) 
goals) 
(subsetp goals current-state :test #*equal)) 
current-state))) 

(defun orderings (1) 

(if (> (length 1) 1) 
(1 ist 1 (reverse 1)) 
(list 1))) 

Now we can represent the goal either way, and we'll still get an answer. Notice that 
we only consider two orderings: the order given and the reversed order. Obviously, 
for goal sets of one or two conjuncts this is all the orderings. In general, if there 
is only one interaction per goal set, then one of these two orders will work. Thus, 
we are assuming that "prerequisite clobbers sibling goal" interactions are rare, and 
that there will seldom be more than one interaction per goal set. Another possibility 
would be to consider all possible permutations of the goals, but that could take a long 
time with large goal sets. 

Another consideration is the efficiency of solutions. Consider the simple task of 
getting block C on the table in the following diagram: 

A] \B] [A] [B] 
start goal 

<a id='page-140'></a>

> (gps '((c on a) (a on table) (b on table) 
(space on c) (space on b) (space on table)) 
'((c on table))) 

((START) 
(EXECUTING (MOVE C FROM A TO B)) 
(EXECUTING (MOVE C FROM . TO TABLE))) 

The solution is correct, but there is an easier solution that moves C directly to the 
table. The simpler solution was not found because of an accident: it happens that 
make-bl ock-ops defines the operators so that moving C from . to the table comes 
before moving C from A to the table. So the first operator is tried, and it succeeds 
provided C is on B. Thus, the two-step solution is found before the one-step solution is 
ever considered. The following example takes four steps when it could be done in two: 

. 
start goal 

> (gps '((c on a) (a on table) (b on table) 
(space on c) (space on b) (space on table)) 
'((c on table) (a on b))) 

((START) 
(EXECUTING (MOVE C FROM A TO B)) 
(EXECUTING (MOVE C FROM . TO TABLE)) 
(EXECUTING (MOVE A FROM TABLE TO O ) 
(EXECUTING (MOVE A FROM C TO B))) 

How could we find shorter solutions? One way would be to do a full-fledged search: 
shorter solutions are tried first, temporarily abandoned when something else looks 
more promising, and then reconsidered later on. This approach is taken up in 
chapter 6, using a general searching function. A less drastic solution is to do a limited 
rearrangement of the order in which operators are searched: the ones with fewer 
unfulfilled preconditions are tried first. In particular, this means that operators with 
all preconditions filled would always be tried before other operators. To implement 
this approach, we change achi eve: 

(defun achieve (state goal goal-stack) 
"A goal is achieved if it already holds, 
or if there is an appropriate op for it that is applicable." 
(dbg-indent :gps (length goal-stack) "Goal:~a" goal) 
(cond ((member-equal goal state) state) 

((member-equal goal goal-stack) nil) 


<a id='page-141'></a>

(t (some #'(lambda (op) (apply-op state goal op goal-stack)) 
(appropriate-ops goal state))))) 

(defun appropriate-ops (goal state) 
"Return a list of appropriate operators, 
sorted by the number of unfulfilled preconditions." 
(sort (copy-list (find-all goal *ops* :test #'appropriate-p)) #'< 

:key #*(lambda (op) 
(count-if #'(lambda (precond) 
(not (member-equal precond state))) 
(op-preconds op))))) 

Now we get the solutions we wanted: 

start goal 

> (gps '((c on a) (a on table) (b on table) 
(space on c) (space on b) (space on table)) 
'((c on table) (a on b))) 

((START) 
(EXECUTING (MOVE C FROM A TO TABLE)) 
(EXECUTING (MOVE A FROM TABLE TO B))) 

start goal 

> (gps '((a on b) (b on c) (c on table) (space on a) (space on table)) 
'((b on a) (c on b))) 

((START) 
(EXECUTING (MOVE A FROM . TO TABLE)) 
(EXECUTING (MOVE . FROM C TO A)) 
(EXECUTING (MOVE C FROM TABLE TO B))) 

> (gps '((a on b) (b on c) (c on table) (space on a) (space on table)) 
'((c on b) (b on a))) 

((START) 
(EXECUTING (MOVE A FROM . TO TABLE)) 
(EXECUTING (MOVE . FROM C TO A)) 
(EXECUTING (MOVE C FROM TABLE TO B))) 


<a id='page-142'></a>

The Sussman Anomaly 

Surprisingly, there are problems that can't be solved by any reordering of goals. 
Consider: 

. A 
Start goal 

This doesn't look too hard, so let's see how our GPS handles it: 

> (setf start '((c on a) (a on table) (b on table) (space on c) 
(space on b) (space on table))) 
((C ON A) (A ON TABLE) (B ON TABLE) (SPACE ON C) 
(SPACE ON B) (SPACE ON TABLE)) 

> (gps start '((a on b) (b on c))) NIL 

> (gps start *((b on c) (a on b))) => NIL 

There is a "prerequisite clobbers sibling goal" problem regardless of which way we 
order the conjuncts! In other words, no combination of plans for the two individual 
goals can solve the conjunction of the two goals. This is a surprising fact, and the 
example has come to be known as "the Sussman anomaly."^ We will return to this 
problem in chapter 6. 

4.15 Stage 5 Repeated: Analysis of Version 2 
We have shown that GPS is extensible to multiple domains. The main point is that 
we didn't need to change the program itself to get the new domains to work; we 
just changed the list of operators passed to GPS. Experience in different domains 
did suggest changes that could be made, and we showed how to incorporate a few 
changes. Although version 2 is a big improvement over version 1, it still leaves much 
to be desired. Now we will discover a few of the most troubling problems. 

^ A footnote in Waldinger 1977 says, 'This problem was proposed by Allen Brown. Perhaps 
many children thought of it earlier but did not recognize that it was hard." The problem is 
named after Gerald Sussman because he popularized it in Sussman 1973. 


<a id='page-143'></a>
4.16 The Not Looking after You Don^t 
Leap Problem 
We solved the "leaping before you look" problem by introducing variables to hold a 
representation of possible future states, rather than just a single variable representing 
the current state. This prevents GPS from taking an ill-advised action, but we shall 
see that even with all the repair strategies introduced in the last section, it doesn't 
guarantee that a solution will be found whenever one is possible. 

To see the problem, add another operator to the front of the ^school - ops* Hst 
and turn the debugging output back on: 

(use(push (op 'taxi-son-to-school 
:preconds *(son-at-home have-money) 
:add-list '(son-at-school) 
:del-list '(son-at-home have-money)) 

*school-ops*)) 

(debug :gps) 

Now, consider the problem of getting the child to school without using any money: 

> (gps '(son-at-home have-money car-works) 

'(son-at-school have-money)) 
Goal: SON-AT-SCHOOL 
Consider: TAXI-SON-TO-SCHOOL 

Goal: SON-AT-HOME 

Goal: HAVE-MONEY 
Action: TAXI-SON-TO-SCHOOL 
Goal: HAVE-MONEY 
Goal: HAVE-MONEY 
Goal: SON-AT-SCHOOL 
Consider: TAXI-SON-TO-SCHOOL 

Goal: SON-AT-HOME 

Goal: HAVE-MONEY 
Action: TAXI-SON-TO-SCHOOL 
NIL 

The first five lines of output succesfully solve the son-at-school goal with the 
TAX I - SON - TO- SCHOO L action. The next line shows an unsuccesf ul attempt to solve the 
have - money goal. The next step is to try the other ordering. This time, the have - money 
goal is tried first, and succeeds. Then, the son-at-school goal is achieved again by 
the TAX I - SON - TO- SCHOO L action. But the check for consistency in achi eve-each fails, 
and there are no repairs available. The goal fails, even though there is a valid solution: 
driving to school. 


<a id='page-144'></a>

The problem is that achi eve uses some to look at the appropri ate-ops. Thus, if 
there is some appropriate operator, achi eve succeeds. If there is only one goal, this 
will yield a correct solution. However, if there are multiple goals, as in this case, 
achi eve will still only find one way to fulfill the first goal. If the first solution is a bad 
one, the only recourse is to try to repair it. In domains like the block world and maze 
world, repair often works, because all steps are reversible. But in the taxi example, no 
amount of plan repair can get the money back once it is spent, so the whole plan fails. 

There are two ways around this problem. The first approach is to examine all 
possible solutions, not just the first solution that achieves each subgoal. The language 
Prolog, to be discussed in chapter 11, does just that. The second approach is to have 
achi eve and achi eve-al 1 keep track of a list of goals that must be protected. In the 
taxi example, we would trivially achieve the have-money goal and then try to achieve 
son-at-school, while protecting the goal have-money. An operator would only 
be appropriate if it didn't delete any protected goals. This approach still requires 
some kind of repair or search through multiple solution paths. If we tried only 
one ordering-achieving son - at - school and then trying to protect it while achieving 
have - money—then we would not find the solution. David Warren's WARPLAN planner 
makes good use of the idea of protected goals. 

4.17 The Lack of Descriptive Power Problem 
It would be a lot more economical, in the maze domain, to have one operator that 
says we can move from here to there if we are at "here," and if there is a connection 
from "here" to "there." Then the input to a particular problem could list the valid 
connections, and we could solve any maze with this single operator. Similarly, we 
have defined an operator where the monkey pushes the chair from the door to the 
middle of the room, but it would be better to have an operator where the monkey 
can push the chair from wherever it is to any other nearby location, or better yet, an 
operator to push any "pushable" object from one location to a nearby one, as long 
as there is no intervening obstacle. The conclusion is that we would like to have 
variables in the operators, so we could say something like: 

(op '(push X from A to B) 

:preconds '((monkey at A) (X at A) (pushable X) (path A B)) 

:add-list '((monkey at B) (X at B)) 

:del-list '((monkey at A) (X at A))) 

Often we want to characterize a state in terms of something more abstract than a 
list of conditions. For example, in solving a chess problem, the goal is to have the 
opponent in checkmate, a situation that cannot be economically described in terms 
of primitives like (bl ack ki ng on A 4), so we need to be able to state some kind 


<a id='page-145'></a>
of constraint on the goal state, rather than just listing its components. We might 
want to be able to achieve a disjunction or negation of conditions, where the current 
formalism allows only a conjunction. 

It also is important, in many domains, to be able to state problems dealing with 
time: we want to achieve X before time To, and then achieve Y before time T2, but 
not before Ti. Scheduling work on a factory floor or building a house are examples 
of planning where time plays an important role. 

Often there are costs associated with actions, and we want to find a solution 
with minimal, or near-minimal costs. The cost might be as simple as the number of 
operators required for a solution—we saw in the blocks world domain that sometimes 
an operator that could be applied immediately was ignored, and an operator that 
needed several preconditions satisfied was chosen instead. Or we may be satisfied 
with a partial solution, if a complete solution is impossible or too expensive. We may 
also want to take the cost (and time) of computation into account. 

4.18 The Perfect Information Problem 
All the operators we have seen so far have unambiguous results; they add or delete 
certain things from the current state, and GPS always knows exactly what they are 
going to do. In the real world, things are rarely so cut and dried. Going back to the 
problem of becoming rich, one relevant operator would be playing the lottery. This 
operator has the effect of consuming a few dollars, and once in a while paying off a 
large sum. But we have no way to represent a payoff "once in a while." Similarly, 
we have no way to represent unexpected difficulties of any kind. In the nursery 
school problem, we could represent the problem with the car battery by having GPS 
explicitly check to see if the car was working, or if it needed a battery, every time 
the program considered the driving operator. In the real world, we are seldom this 
careful; we get in the car, and only when it doesn't start do we consider the possibility 
of a dead battery. 

4.19 The Interacting Goals Problem 
People tend to have multiple goals, rather than working on one at a time. Not only do 
I want to get the kid to nursery school, but I want to avoid getting hit by another car, 
get to my job on time, get my work done, meet my friends, have some fun, continue 
breathing, and so on. I also have to discover goals on my own, rather than work on 
a set of predefined goals passed to me by someone else. Some goals I can keep in 
the background for years, and then work on them when the opportunity presents 
itself. There is never a notion of satisfying all possible goals. Rather, there is a 


<a id='page-146'></a>

continual process of achieving some goals, partially achieving others, and deferring 
or abandoning still others. 

In addition to having active goals, people also are aware of undesirable situations 
that they are trying to avoid. For example, suppose I have a goal of visiting a friend 
in the hospital. This requires being at the hospital. One appHcable operator might 
be to walk to the hospital, while another would be to severly injure myself and wait 
for the ambulance to take me there. The second operator achieves the goal just as 
well (perhaps faster), but it has an undesirable side effect. This could be addressed 
either with a notion of solution cost, as outlined in the last section, or with a list of 
background goals that every solution attempts to protect. 

Herb Simon coined the term "satisficing" to describe the strategy of satisfying a 
reasonable number of goals to a reasonable degree, while abandoning or postponing 
other goals. GPS only knows success and failure, and thus has no way of maximizing 
partial success. 

4.20 The End of GPS 
These last four sections give a hint as to the scope of the limitations of GPS. In fact, it 
is not a very general problem solver at all. Itis general in the sense that the algorithm 
is not tied to a particular domain; we can change domain by changing the operators. 
But GPS fails to be general in that it can't solve many interesting problems. It is 
confined to small tricks and games. 

There is an important yet subtle reason why GPS was destined to fail, a reason 
that was not widely appreciated in 1957 but now is at the core of computer science. 
It is now recognized that there are problems that computers can't solve—not because 
a theoretically correct program can't be written, but because the execution of the 
program will take too long. A large number of problems can be shown to fall into 
the class of "NP-hard" problems. Computing a solution to these problems takes 
time that grows exponentially as the size of the problem grows. This is a property 
of the problems themselves, and holds no matter how clever the programmer is. 
Exponential growth means that problems that can be solved in seconds for, say, a 
five-input case may take trillions of years when there are 100 inputs. Buying a faster 
computer won't help much. After all, if a problem would take a trillion years to solve 
on your computer, it won't help much to buy 1000 computers each 1000 times faster 
than the one you have: you're still left with a million years wait. For a theoretical 
computer scientist, discovering that a problem is NP-hard is an end in itself. But for 
an AI worker, it means that the wrong question is being asked. Many problems are 
NP-hard when we insist on the optimal solution but are much easier when we accept 
a solution that might not be the best. 

The input to GPS is essentially a program, and the execution of GPS is the execution 
of that program. If GPS's input language is general enough to express any program. 


<a id='page-147'></a>
then there will be problems that can't be solved, either because they take too long 
to execute or because they have no solution. Modern problem-solving programs 
recognize this fundamental limitation, and either limit the class of problems they try 
to solve or consider ways of finding approximate or partial solutions. Some problem 
solvers also monitor their own execution time and know enough to give up when a 
problem is too hard. 

The following quote from Drew McDermott's article "Artificial Intelligence Meets 
Natural Stupidity" sums up the current feeling about GPS. Keep it in mind the next 
time you have to name a program. 

Remember GPS? By now, "GPS" is a colorless term denoting a particularly stupid 
program to solve puzzles. But it originally meant ''General Problem Solver," 
which caused everybody a lot of needless excitement and distraction. It should 
have been called LFGNS-"Loca/ Feature-Guided Network Searcher." 

Nonetheless, GPS has been a useful vehicle for exploring programming in general, 
and AI programming in particular. More importantly, it has been a useful vehicle 
for exploring "the nature of deliberation." Surely we'll admit that Aristotle was 
a smarter person than you or me, yet with the aid of the computational model of 
mind as a guiding metaphor, and the further aid of a working computer program 
to help explore the metaphor, we have been led to a more thorough appreciation of 
means-ends analysis—at least within the computational model. We must resist the 
temptation to believe that all thinking follows this model. 

The appeal of AI can be seen as a split between means and ends. The end of a 
successful AI project can be a program that accomplishes some useful task better, 
faster, or cheaper than it could be before. By that measure, GPS is a mostly a failure, 
as it doesn't solve many problems particularly well. But the means toward that end 
involved an investigation and formalization of the problem-solving process. By that 
measure, our reconstruction of GPS is a success to the degree in which it leads the 
reader to a better understanding of the issues. 

4.21 History and References 
The original GPS is documented in Newell and Simon's 1963 paper and in their 1972 
book. Human Problem Solving, as well as in Ernst and Newell 1969. The implementation 
in this chapter is based on the STRIPS program (Fikes and Nilsson 1971). 

There are other important planning programs. Earl Sacerdoti's ABSTRIPS program 
was a modification of STRIPS that allowed for hierarchical planning. The idea was to 
sketch out a skeletal plan that solved the entire program at an abstract level, and then 
fill in the details. David Warren's WARPLAN planner is covered in Warren 1974a,b 
and in a section of Coelho and Cotta 1988. Austin Tate's NONLIN system (Tate 1977) 


<a id='page-148'></a>

achieved greater efficiency by considering a plan as a partially ordered sequence of 
operations rather than as a strictly ordered sequence of situations. David Chapman's 
TWEAK synthesizes and formalizes the state of the art in planning as of 1987. 
All of these papers-an d quite a few other important planning papers-ar e 
reprinted in Allen, Hendler, and Tate 1990. 
4.22 Exercises 
&#9635; Exercise 4.1 [m] It is possible to implement dbg using a single call to format. Can 
you figure out the format directives to do this? 

&#9635; Exercise 4.2 [m] Write a function that generates all permutations of its input. 

&#9635; Exercise 4.3 [h] GPS does not recognize the situation where a goal is accidentally 
solved as part of achieving another goal. Consider the goal of eating dessert. Assume 
that there are two operators available: eating ice cream (which requires having the 
ice cream) and eating cake (which requires having the cake). Assume that we can 
buy a cake, and that the bakery has a deal where it gives out free ice cream to each 
customer who purchases and eats a cake. (1) Design a list of operators to represent 
this situation. (2) Give gps the goal of eating dessert. Show that, with the right list 
of operators, gps will decide to eat ice cream, then decide to buy and eat the cake in 
order to get the free ice cream, and then go ahead and eat the ice cream, even though 
the goal of eating dessert has already been achieved by eating the cake. (3) Fix gps so 
that it does not manifest this problem. 
The following exercises address the problems in version 2 of the program. 

&#9635; Exercise 4.4 [h] The Not Looking after You Don't Leap Problem. Write a program that 
keeps track of the remaining goals so that it does not get stuck considering only one 
possible operation when others will eventually lead to the goal. Hint: have achi eve 
take an extra argument indicating the goals that remain to be achieved after the 
current goal is achieved, achi eve should succeed only if it can achieve the current 
goal and also achi eve-all the remaining goals. 

&#9635; Exercise 4.5 [d] Write a planning program that, like Warren's WARPLAN, keeps 
track of the list of goals that remain to be done as well as the list of goals that have 
been achieved and should not be undone. The program should never undo a goal 
that has been achieved, but it should allow for the possibility of reordering steps that 


<a id='page-149'></a>

have already been taken. In this way, the program will solve the Sussman anomaly 
and similar problems. 

&#9635; Exercise 4.6 [d] The Lack of Descriptive Power Problem. Read chapters 5 and 6 to learn 
about pattern matching. Write a version of GPS that uses the pattern matching tools, 
and thus allows variables in the operators. Apply it to the maze and blocks world 
domains. Your program will be more efficient if, like Chapman's TWEAK program, 
you allow for the possibility of variables that remain unbound as long as possible. 

&#9635; Exercise 4.7 [d] Speculate on the design of a planner that can address the Perfect 
Information and Interacting Goals problems. 

4.23 Answers 
Answer 4.1 In this version, the format string " ~&~V@T~?" breaks down as follows: 

means go to a fresh line; "~V@T" means insert spaces (@T) but use the next 
argument (V) to get the number of spaces. The " ~?" is the indirection operator: use 
the next argument as a format string, and the argument following that as the list of 
arguments for the format string. 

(defun dbg-indent (id indent format-string &rest args) 
"Print indented debugging info if (DEBUG ID) has been specified." 
(when (member id *dbg-ids*) 

(format *debug-io* "~&~v@T~?" (* 2 indent) format-string args))) 


<a id='page-150'></a>

Answer 4.2 Here is one solution. The sophisticated Lisp programmer should also 
see the exercise on [page 680](chapter19.md#page-680). 

(defun permutations (bag) 

"Return a list of all the permutations of the input." 
If the input is nil, there is only one permutation: 
nil itself 

(if (null bag) 

'(()) 
Otherwise, take an element, e, out of the bag. 
Generate all permutations of the remaining elements. 
And add e to the front of each of these. 
Do this for all possible e to generate all permutations, 

(mapcan #'(lambda (e) 
(mapcar #*(lambda (p) (cons e p)) 
(permutations 
(remove e bag :count 1 :test #'eq)))) 
bag))) 


## Chapter 5
<a id='page-151'></a>

ELIZA: Dialog with a Machine 

It is said that to explain is to explain away. 

—Joseph Weizenbaum 
MIT computer scientist 

I I 1 his chapter and the rest of part I will examine three more well-known AI programs of 

I the 1960s. ELIZA held a conversation with the user in which it simulated a psychother


apist. STUDENT solved word problems of the kind found in high school algebra books, 
and MACSYMA solved a variety of symbolic mathematical problems, including differential and 
integral calculus. We will develop versions of the first two programs that duplicate most of 
the essential features, but for the third we will implement only a tiny fraction of the original 
program's capabilities. 

All three programs make heavy use of a technique called pattern matching. Part I serves to 
show the versatility—and also the limitations—of this technique. 

Of the three programs, the first two process input in plain English, and the last two solve nontrivial 
problems in mathematics, so there is some basis for describing them as being "intelligent." 
On the other hand, we shall see that this intelligence is largely an illusion, and that ELIZA in 
particular was actually designed to demonstrate this illusion, not to be a "serious" AI program. 


<a id='page-152'></a>

ELIZA was one of the first programs to feature English output as well as input. 
The program was named after the heroine of Pygmalion, who was taught to speak 
proper English by a dedicated teacher. ELIZA'S principal developer, MIT professor 
Joseph Weizenbaum, published a paper on ELIZA in the January 1966 issue of the 
Communications of the Association for Computing Machinery. The introduction to that 
paper is reproduced in its entirety here: 

It is said that to explain is to explain away. This maxim is nowhere so well 
fulfilled as in the area of computer programming, especially in what is called 
heuristic programming and artificial intelligence. For in those realms machines 
are made to behave in wondrous ways, often sufficient to dazzle even the most 
experienced observer. But once a particular program is unmasked, once its inner 
workings are explained in language sufficiently plain to induce understanding 
its magic crumbles away; it stands revealed as a mere collection of procedures, 
each quite comprehensible. The observer says to himself, "I could have written 
that." With that thought he moves the program in question from the shelf 
marked "intelligent," to that reserved for curios, fit to be discussed only with 
people less enlightened than he. 

The object of this paper is to cause just such a re-evaluation of the program about 
to be "explained." Few programs ever needed it more. 

Let me point out in passing that the main object of this book is to cause the reader 
to say to him or herself, "I could have written that." It is hoped that in some cases 
this will be because the reader has gained something, and not solely because the 
programs in question have lost their ability to dazzle. 

Let's start our investigation of ELIZA by looking at a sample dialog from the 
Weizenbaum article. ELIZA was designed to be instructed by a variety of scripts, or 
patterns of interaction. In fact it had several scripts, including ones in German and 
Welsh. But the only script that was used to any extent was in English, and it made 
ELIZA emulate a Rogerian psychoanalyst. Rogerians are "nondirective"—they try to 
let the patient reveal himself. This is an easy script for ELIZA to follow, because it 
involves being passive and reacting, rather than volunteering new information. In 
the listing that follows, the user's input is in mixed case, and ELIZA'S response is in 
capitals: 

Men are all alike. 
IN WHAT WAY 
They're always bugging us about something or another. 
CAN YOU BE MORE SPECIFIC 
Well, my boyfriend made me come here. 
YOUR BOYFRIEND MADE YOU COME HERE 
He says I'm depressed much of the time. 
I AM SORRY TO HEAR YOU ARE DEPRESSED 


<a id='page-153'></a>

It's true. I am unhappy. 
DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY 
I need some help, that much seems certain. 
WHAT WOULD IT MEAN TO YOU IF YOU GOT SOME HELP 
Perhaps I could learn to get along with my mother. 
TELL ME MORE ABOUT YOUR FAMILY 

This seems quite impressive; the program is responding reasonably to a variety of 
inputs and appears to be exhibiting true "understanding." But, as Weizenbaum 
explains, this appearance is an illusion, and the program has finessed the difficult 
task of understanding by carefully recognizing, transforming, and echoing pieces 
of the input. The procedure is to look for specific patterns, based on a key word 
or words in the input. For example, whenever the program sees the words "alike" 
or "same," it prints a message asking about similarity, in this case, "IN WHAT WAY." 
Other patterns are more complicated. In the next to last exchange, ELIZA first throws 
away everything after the comma, and then uses a pattern that looks for input of 
the form "I need X" and transforms it to the output "What would it mean to you if 
you got X," where X is the phrase "some help" in this case. The great advantage of 
this approach is that the response will make sense for a variety of inputs: "I need 
a vacation" will elicit "What would it mean to you if you got a vacation." This will 
work automatically, without having to tell the program the difference between "some 
help" and "a vacation." The disadvantage is that the program will sometimes make 
silly responses: "I need this like a hole in the head" will be answered with "What 
would it mean to you if you got this like a hole in the head." In fact, the program only 
makes any sense at all if it is receiving input from someone who makes sense—and 
someone who interprets its answers charitably. When given "I need gibble plix zzq," 
ELIZA would reply " What would it mean to you if you got gibble plix zzq," without any 
inkling that something is wrong. Another example of the original ELIZA program has 
it communicating with another program, PARRY, which was written by Dr. Kenneth 
Colby to mimic paranoid behavior. Part of the conversation follows, with ELIZA again 
in capitals and PARRY in mixed case: 

I don't understand your motives. 
WHY DON'T YOU UNDERSTAND MY MOTIVES? 
Shouldn't I be? 
WHY DO YOU SAY THAT JUST NOW? 
That's just the way it is . 
SUPPOSE THAT'S JUST THE WAY IT WERE NOT. 
So? 
I AM NOT SURE I UNDERSTAND YOU FULLY. 
You harp on the same questions too much. 
WHAT DOES THAT SIMILARITY SUGGEST TO YOU? 
I don't get you. 
DO YOU WISH THAT YOU DID GET I ? 


<a id='page-154'></a>

This suggests that neither ELIZA nor PARRY had a deep understanding of the dialog. 
When there is a human to take on most of the burden of carrying forth the conversation, 
these programs can be convincing, but when the human is taken out of the 
conversation, the weaknesses of the programs are revealed. 

5.1 Describing and Specifying ELIZA 
Now that we have an idea of what ELIZA is like, we can begin the description and specification 
of the program, and eventually move to the implementation and debugging. 

The ELIZA algorithm can be described simply as: (1) read an input, (2) find a 
pattern that matches the input, (3) transform the input into a response, and (4) print 
the response. These four steps are repeated for each input. 

The specification and implementation of steps (1) and (4) are trivial: for (1), use 
the built-in read function to read a list of words, and for (4) use print to print the list 
of words in the response. 

Of course, there are some drawbacks to this specification. The user will have 
to type a real list—using parentheses—and the user can't use characters that are 
special to read, like quotation marks, commas, and periods. So our input won't 
be as unconstrained as in the sample dialog, but that's a small price to pay for the 
convenience of having half of the problem neatly solved. 

5.2 Pattern Matching 
The hard part comes with steps (2) and (3)—this notion of pattern matching and 
transformation. There are four things to be concerned with: a general pattern and 
response, and a specific input and transformation of that input. Since we have agreed 
to represent the input as a list, it makes sense for the other components to be lists 
too. For example, we might have: 

Pattern: (i need a X) 

Response: (what would it mean to you if you got a X ?) 

Input: (i need a vacation) 
Transformation: (what would it mean to you if you got a vacation ?) 

The pattern matcher must match the literals i with i, need with need, and a with a, 
as well as match the variable X with va cat i on. This presupposes that there is some 
way of deciding that X is a variable and that need is not. We must then arrange to 
substitute vacation for X within the response, in order to get the final transformation. 


<a id='page-155'></a>
Ignoring for a moment the problem of transforming the pattern into the response, 
we can see that this notion of pattern matching is just a generalization of the Lisp 
function equa 1. Below we show the function s i mpl e - equa 1, which is like the built-in 
function equal,^ and the function pat-match, which is extended to handle pattern-
matching variables: 

(defun simple-equal (x y) 
"Are . and y equal? (Don't check inside strings.)" 
(if (or (atom x) (atom y)) 

(eql . y) 
(and (simple-equal (first x) (first y)) 
(simple-equal (rest x) (rest y))))) 

(defun pat-match (pattern input) 
"Does pattern match input? Any variable can match anything." 
(if (variable-p pattern) 

t 

(if (or (atom pattern) (atom input)) 
(eql pattern input) 
(and (pat-match (first pattern) (first input)) 

(pat-match (rest pattern) (rest input)))))) 

&#9635; Exercise 5.1 [s] Would it be a good idea to replace the complex and form in 
pat-match with the simpler (every #'pat-match pattern input)? 

Before we can go on, we need to decide on an implementation for pattern-
matching variables. We could, for instance, say that only a certain set of symbols, 
such as {.,.,.}, are variables. Alternately, we could define a structure of type 
vari abl e, but then we'd have to type something verbose like (make-vari abl e : name 

* X) every time we wanted one. Another choice would be to use symbols, but to distinguish 
variables from constants by the name of the symbol. For example, in Prolog, 
variables start with capital letters and constants with lowercase. But Common Lisp 
is case-insensitive, so that won't work. Instead, there is a tradition in Lisp-based AI 
programs to have variables be symbols that start with the question mark character. 
So far we have dealt with symbols as atoms—objects with no internal structure. 
But things are always more compHcated than they first appear and, as in Lisp as 
in physics, it turns out that even atoms have components. In particular, symbols 
have names, which are strings and are accessible through the symbol - name function. 
Strings in turn have elements that are characters, accessible through the function 
char. The character '?' is denoted by the self-evaluating escape sequence #\?. So 
the predicate variab1 e-p can be defined as follows, and we now have a complete 
pattern matcher: 

^The difference is that simpl e-equal does not handle strings. 


<a id='page-156'></a>

(defun variab1e-p (x) 
"Is X a variable (a symbol beginning with *?*)?" 
(and (symbolp x) (equal (char (symbol-name x) 0) #\?))) 

> (pat-match '(I need a ?X) '(I need a vacation)) 
. 

> (pat-match *(I need a ?X) '(I really need a vacation)) 
NIL 

In each case we get the right answer, but we don't get any indication of what ?X is, so 
we couldn't substitute it into the response. We need to modify pat-match to return 
some kind of table of variables and corresponding values. In making this choice, the 
experienced Common Lisp programmer can save some time by being opportunistic: 
recognizing when there is an existing function that will do a large part of the task at 
hand. What we want is to substitute values for variables throughout the response. 
The alert programmer could refer to the index of this book or the Common Lisp 
reference manual and find the functions substi tute, subst, and subl i s. All of these 
substitute some new expression for an old one within an expression. It turns out that 
subl i s is most appropriate because it is the only one that allows us to make several 
substitutions all at once, subl 1 s takes two arguments, the first a list of old-new pairs, 
and the second an expression in which to make the substitutions. For each one of 
the pairs, the car is replaced by the cdr. In other words, we would form each pair 
with something like (cons ol d new). (Such a list of pairs is known as an association 
Ust, or a-list, because it associates keys with values. See section 3.6.) In terms of the 
example above, we would use: 

> (sublis '((?X . vacation)) 
'(what would it mean to you if you got a ?X ?)) 
(WHAT WOULD IT MEAN TO YOU IF YOU GOT A VACATION ?) 

Now we need to arrange for pat-match to return an a-Iist, rather than just . for 
success. Here's a first attempt: 

(defun pat-match (pattern input) 
"Does pattern match input? WARNING: buggy version. " 
(if (variable-p pattern) 

(list (cons pattern input)) 

(if (or (atom pattern) (atom input)) 
(eql pattern input) 
(append (pat-match (first pattern) (first input)) 

(pat-match (rest pattern) (rest input)))))) 

This implementation looks reasonable: it returns an a-list of one element if the pattern 
is a variable, and it appends alists if the pattern and input are both lists. However, 


<a id='page-157'></a>
there are several problems. First, the test (eql pattern input) may return T, which 
is not a list, so append will complain. Second, the same test might return nil, which 
should indicate failure, but it will just be treated as a list, and will be appended to 
the rest of the answer. Third, we haven't distinguished between the case where the 
match fails—and returns nil—versus the case where everything matches, but there 
are no variables, so it returns the null a-list. (This is the semipredicate problem 
discussed on [page 127](chapter4.md#page-127).) Fourth, we want the bindings of variables to agree—if ?X is 
used twice in the pattern, we don't want it to match two different values in the input. 
Finally, it is inefficient for pat-match to check both the first and rest of Hsts, even 
when the corresponding first parts fail to match. (Isn't it amazing that there could 
be five bugs in a seven-line function?) 

We can resolve these problems by agreeing on two major conventions. First, it is 
very convenient to make pat-match a true predicate, so we will agree that it returns 
.i 1 only to indicate failure. That means that we will need a non-nil value to represent 
the empty binding list. Second, if we are going to be consistent about the values of 
variables, then the firstwillhavetoknow what the restisdoing. We can accomplish 
this by passing the binding list as a third argument to pat-match. We make it an 
optional argument, because we want to be able to say simply (pat-match ab). 

To abstract away from these implementation decisions, we define the constants 
fai 1 and no-bi ndi ngs to represent the two problematic return values. The special 
form defconstant is used to indicate that these values will not change. (It is customary 
to give special variables names beginning and ending with asterisks, but this 
convention usually is not followed for constants. The reasoning is that asterisks 
shout out, "Careful! I may be changed by something outside of this lexical scope." 
Constants, of course, will not be changed.) 

(defconstant fail nil "Indicates pat-match failure") 

(defconstant no-bindings '((t . t)) 
"Indicates pat-match success, with no variables.") 

Next, we abstract away from assoc by introducing the following four functions: 

(defun get-binding (var bindings) 
"Find a (variable . value) pair in a binding list. " 
(assoc var bindings)) 

(defun binding-val (binding) 
"Get the value part of a single binding." 
(cdr binding)) 

(defun lookup (var bindings) 
"Get the value part (for var) from a binding list. " 
(binding-val (get-binding var bindings))) 


<a id='page-158'></a>

(defun extend-bindings (var val bindings) 
"Add a (var . value) pair to a binding list." 
(cons (cons var val) bindings)) 

Now that variables and bindings are defined, pat-match is easy. It consists of five 
cases. First, if the binding list is f ai 1, then the match fails (because some previous 
match must have failed). If the pattern is a single variable, then the match returns 
whatever match- va r i abl e returns; either the existing binding Ust, an extended one, 
or f ai 1. Next, if both pattern and input are lists, we first call pat-match recursively 
on the first element of each list. This returns a binding list (or f ai 1), which we use 
to match the rest of the lists. This is the only case that invokes a nontrivial function, 
so it is a good idea to informally prove that the function will terminate: each of the 
two recursive calls reduces the size of both pattern and input, and pat -match checks 
the case of atomic patterns and inputs, so the function as a whole must eventually 
return an answer (unless both pattern and input are of infinite size). If none of these 
four cases succeeds, then the match fails. 

(defun pat-match (pattern input &optional (bindings no-bindings)) 
"Match pattern against input in the context of the bindings" 
(cond ((eq bindings fail) fail) 

((variable-p pattern) 

(match-variable pattern input bindings)) 
((eql pattern input) bindings) 
((and (consp pattern) (consp input)) 

(pat-match (rest pattern) (rest input) 
(pat-match (first pattern) (first input) 
bindings))) 
(t fail))) 

(defun match-variable (var input bindings) 
"Does VAR match input? Uses (or updates) and returns bindings." 
(let ((binding (get-binding var bindings))) 

(cond ((not binding) (extend-bindings var input bindings)) 
((equal input (binding-val binding)) bindings) 
(t fail)))) 

We can now test pat-match and see how it works: 

> (pat-match '(i need a ?X) '(i need a vacation)) 
((?X . VACATION) (T . T)) 

The answer is a list of variable bindings in dotted pair notation; each element of 
the list is a (vanable , value) pair. The (T . T) is a remnant from no-bindings. It 
does no real harm, but we can eliminate it by making extend - bi ndi ngs a little more 
complicated: 


<a id='page-159'></a>
(defun extend-bindings (var val bindings) 
"Add a (var . value) pair to a binding list." 
(cons (cons var val) 

Once we add a "real" binding, 
we can get rid of the dummy no-bindings 

(if (eq bindings no-bindings) 
nil 
bindings) 

> (sublis (pat-match '(i need a ?X) '(i need a vacation)) 
'(what would it mean to you if you got a ?X ?)) 
(WHAT WOULD IT MEAN TO YOU IF YOU GOT A VACATION ?) 

> (pat-match '(i need a ?X) '(i really need a vacation)) 
NIL 

> (pat-match '(this is easy) '(this is easy)) 
((T . T)) 

> (pat-match '(?X is ?X) '((2 + 2) is 4)) 
NIL 

> (pat-match '(?X is ?X) '((2 + 2) is (2 + 2))) 
((?X 2 + 2)) 

> (pat-match '(?P need . ?X) '(i need a long vacation)) 
((?X A LONG VACATION) (?P . I)) 

Notice the distinction between NIL and ((. . .)). The latter means that the match 
succeeded, but there were no bindings to return. Also, remember that (?X 2 + 2) 
means the same as (?X . (2 + 2)). 

A more powerful implementation of pat -match is given in chapter 6. Yet another 
implementation is given in section 10.4. It is more efficient but more cumbersome 
to use. 

5.3 Segment Pattern Matching 
In the pattern (?P need . ?X), the variable ?X matches the rest of the input Ust, 
regardless of its length. This is in contrast to ?P, which can only match a single 
element, namely, the first element of the input. For many applications of pattern 
matching, this is fine; we only want to match corresponding elements. However, 
ELIZA is somewhat different in that we need to account for variables in any position 
that match a sequence of items in the input. We will call such variables segment 
vanables. We will need a notation to differentiate segment variables from normal 


<a id='page-160'></a>

variables. The possibilities fall into two classes: either we use atoms to represent 
segment variables and distinguish them by some spelling convention (as we did to 
distinguish variables from constants) or we use a nonatomic construct. We will 
choose the latter, using a list of the form (?* variable) to denote segment variables. 
The symbol ?* is chosen because it combines the notion of variable with the Kleene-
star notation. So, the behavior we want from pat-match is now: 

> (pat-match '((?* ?p) need (?* ?x)) 
'(Mr Hulot and I need a vacation)) 
((?P MR HULOT AND I) (?X A VACATION)) 

In other words, when both pattern and input are lists and the first element of the 
pattern is a segment variable, then the variable will match some initial part of the 
input, and the rest of the pattern will attempt to match the rest. We can update 
pat-match to account for this by adding a single cond-clause. Defining the predicate 
to test for segment variables is also easy: 

(defun pat-match (pattern input &optional (bindings no-bindings)) 
"Match pattern against input in the context of the bindings" 

(cond ((eq bindings fail ) fail ) 
((variable-p pattern) 
(match-variable pattern input bindings)) 
((eql pattern input) bindings) 
((segment-pattern-p pattern) ; ** * 
(segment-match pattern input bindings)) ; ** * 
((and (consp pattern) (consp input)) 
(pat-match (rest pattern) (rest input) 

(pat-match (first pattern) (first input) 
bindings))) 
(t fail))) 

(defun segment-pattern-p (pattern) 

"Is this a segment matching pattern: ((?* var) . pat)" 

(and (consp pattern) 

(starts-with (first pattern) '?*))) 

In writing segment-match, the important question is how much of the input the 
segment variable should match. One answer is to look at the next element of the 
pattern (the one after the segment variable) and see at what position it occurs in the 
input. If it doesn't occur, the total pattern can never match, and we should f ai 1. If 
it does occur, call its position pos. We will want to match the variable against the 
initial part of the input, up to pos. But first we have to see if the rest of the pattern 
matches the rest of the input. This is done by a recursive call to pat-match. Let the 
result of this recursive call be named b2. If b2 succeeds, then we go ahead and match 
the segment variable against the initial subsequence. 


<a id='page-161'></a>
The tricky part is when bZ fails. We don't want to give up completely, because 
it may be that if the segment variable matched a longer subsequence of the input, 
then the rest of the pattern would match the rest of the input. So what we want is to 
try segment-match again, but forcing it to consider a longer match for the variable. 
This is done by introducing an optional parameter, start, which is initially 0 and is 
increased with each failure. Notice that this policy rules out the possibility of any 
kind of variable following a segment variable. (Later we will remove this constraint.) 

(defun segment-match (pattern input bindings &optional (start 0)) 
"Match the segment pattern ((?* var) . pat) against input." 
(let ((var (second (first pattern))) 

(pat (rest pattern))) 
(if (null pat) 

(match-variable var input bindings) 
We assume that pat starts with a constant 
In other words, a pattern can't have 2 consecutive vars 

(let ((pos (position (first pat) input 
:start start :test #'equal))) 

(if (null pos) 
fail 
(let ((b2 (pat-match pat (subseq input pos) bindings))) 

If this match failed, try another longer one 

If it worked, check that the variables match 

(if (eq b2 fail) 
(segment-match pattern input bindings (+ pos 1)) 
(match-variable var (subseq input 0 pos) b2)))))))) 

Some examples of segment matching follow: 

> (pat-match '((?* ?p) need (?* ?x)) 
'(Mr Hulot and I need a vacation)) 
((?P MR HULOT AND I) (?X A VACATION)) 

> (pat-match '((?* ?x) is a (?* ?y)) '(what he is is a fool)) 

((?X WHAT HE IS) (?Y FOOD) 

The first of these examples shows a fairly simple case: ?p matches everything up 
to need, and ?x matches the rest. The next example involves the more complicated 
backup case. First ?x matches everything up to the first i s (this is position 2, since 
counting starts at 0 in Common Lisp). But then the pattern a fails to match the input 
i s, so segment - match tries again with starting position 3. This time everything works; 
i s matches i s, a matches a, and (?* ?y) matches fool. 


<a id='page-162'></a>

Unfortunately, this version of s egment - mat ch does not match as much as it should. 
Consider the following example: 

> (pat-match *((?* ?x) a b (?* ?x)) '(1 2 a b a b 1 2 a b)) NIL 

This fails because ?x is matched against the subsequence (1 2), and then 
the remaining pattern succesfuUy matches the remaining input, but the final 
call to match-variabl e fails, because ?x has two different values. The fix is to call 
match-vari able before testing whether the b2 fails, so that we will be sure to try 
segment-match again with a longer match no matter what the cause of the failure. 

(defun segment-match (pattern input bindings &optional (start 0)) 
"Match the segment pattern ((?* var) . pat) against input." 
(let ((var (second (first pattern))) 

(pat (rest pattern))) 
(if (null pat) 

(match-variable var input bindings) 
We assume that pat starts with a constant 
In other words, a pattern can't have 2 consecutive vars 

(let ((pos (position (first pat) input 
istart start rtest #'equal))) 

(if (null pos) 
fail 
(let ((b2 (pat-match 

pat (subseq input pos) 
(match-variable var (subseq input 0 pos) 
bindings)))) 
If this match failed, try another longer one 

(if (eq b2 fail) 
(segment-match pattern input bindings (+ pos 1)) 
b2))))))) 

Now we see that the match goes through: 

> (pat-match '((?* ?x) a b (?* ?x)) '(1 2 a b a b 1 2 a b)) 
((?X 1 2 A B)) 

Note that this version of segment-match tries the shortest possible match first. It 
would also be possible to try the longest match first. 


<a id='page-163'></a>
5.4 The ELIZA Program: A Rule-Based 
Translator 
Now that we have a working pattern matcher, we need some patterns to match. 
What's more, we want the patterns to be associated with responses. We can do this 
by inventing a data structure called a rul e, which consists of a pattern and one or 
more associated responses. These are rules in the sense that they assert, "If you 
see A, then respond with . or C, chosen at random." We will choose the simplest 
possible implementation for rules: as lists, where the first element is the pattern and 
the rest is a list of responses: 

(defun rule-pattern (rule) (first rule)) 
(defun rule-responses (rule) (rest rule)) 

Here's an example of a rule: 

(((?* ?x) I want (?* ?y)) 
(What would it mean if you got ?y) 
(Why do you want ?y) 
(Suppose you got ?y soon)) 

When applied to the input (I want to test this program), this rule (when interpreted 
by the ELIZA program) would pick a response at random, substitute in the 
valueof ?y, and respond with, say, (why do you want to test this program). 

Now that we know what an individual rule will do, we need to decide how to 
handle a set of rules. If ELIZA is to be of any interest, it will have to have a variety of 
responses. So several rules may all be applicable to the same input. One possibility 
would be to choose a rule at random from among the rules having patterns that match 
the input. 

Another possibility is just to accept the first rule that matches. This implies that 
the rules form an ordered list, rather than an unordered set. The clever ELIZA rule 
writer can take advantage of this ordering and arrange for the most specific rules to 
come first, while more vague rules are near the end of the list. 

The original ELIZA had a system where each rule had a priority number associated 
with it. The matching rule with the highest priority was chosen. Note that putting the 
rules in order achieves the same effect as having a priority number on each rule: the 
first rule implicitly has the highest priority, the second rule is next highest, and so on. 

Here is a short list of rules, selected from Weizenbaum's original article, but with 
the form of the rules updated to the form we are using. The answer to exercise 5.19 
contains a longer list of rules. 


<a id='page-164'></a>

(defparameter *eliza-rules* 
'((((?* ?x) hello (?* ?y)) 
(How do you do. Please state your problem.)) 

(((?* ?x) I want (?* ?y)) 
(What would it mean if you got ?y) 
(Why do you want ?y) (Suppose you got ?y soon)) 

(((?* ?x) if (?* ?y)) 
(Do you really think its likely that ?y) (Do you wish that ?y) 
(What do you think about ?y) (Really-- if ?y)) 

(((?* ?x) no (?* ?y)) 
(Why not?) (You are being a bit negative) 
(Are you saying "NO" just to be negative?)) 

(((?* ?x) I was (?* ?y)) 
(Were you really?) (Perhaps I already knew you were ?y) 
(Why do you tell me you were ?y now?)) 

(((?* ?x) I feel (?* ?y)) 
(Do you often feel ?y ?)) 
(((?* ?x) I felt (?* ?y)) 
(What other feelings do you have?)))) 

Finally we are ready to define ELIZA proper. As we said earlier, the main program 
should be a loop that reads input, transforms it, and prints the result. Transformation 
is done primarily by finding some rule such that its pattern matches the input, and 
then substituting the variables into the rule's response. The program is summarized 
in figure 5.1. 

There are a few minor complications. We print a prompt to tell the user to 
input something. We use the function f 1 atten to insure that the output won't have 
imbedded lists after variable substitution. An important trick is to alter the input 
by swapping "you" for "me" and so on, since these terms are relative to the speaker. 
Here is the complete program: 

(defun el iza () 
"Respond to user input using pattern matching rules." 
(loop 

(print 'eliza>) 
(write (flatten (use-eliza-rules (read))) ipretty t))) 

(defun use-eliza-rules (input) 
"Find some rule with which to transform the input." 
(some #*(lambda (rule) 

(let ((result (pat-match (rule-pattern rule) input))) 
(if (not (eq result fail)) 
(sublis (switch-viewpoint result) 
(random-elt (rule-responses rule)))))) 
*eliza-rules*)) 


<a id='page-165'></a>
Top-Level Function 

el iza Respond to user input using pattern matching rules. 

Special Variables 

*eliza-rules* A list of transformation rules. 

Data Types 

rule An association of a pattern with a list of responses. 

Fimctions 

el iza Respond to user input using pattern matching rules. 
use-eliza-rules Find some rule with which to transform the input. 
switch-viewpoint Change I to you and vice versa, and so on. 
flatten Append together elements of a list. 

Selected Common Lisp Functions 

sublis Substitute elements into a tree. 

Previously Defined Functions 

random-elt Pick a random element from a list. (p. 36) 
pat-match Match a pattern against an input, (p. 160) 
mappend Append together the results of a mapcar. 

Figure 5.1: Glossary for the ELIZA Program 

(defun switch-viewpoint (words) 
"Change I to you and vice versa, and so on." 
(sublis '((I . you) (you . I) (me . you) (am are)) 

words)) 

Note the use of wri te with the : pretty keyword true. This will give better formatted 
output in some cases. The program makes use of the previously defined random- el t, 
and f 1 atten, which is defined here using mappend and mkl i st, a function that is 
defined in the InterLisp dialect but not in Common Lisp. 

(defun flatten (the-list) 
"Append together elements (or lists) in the list. " 
(mappend #'mklist the-list)) 

(defun mklist (.) 
"Return . if it is a list, otherwise (x)." 
(if distp X) 

X 
(list X))) 

(defun mappend (fn the-list) 
"Apply fn to each element of list and append the results.' 
(apply #*append (mapcar fn the-list))) 


<a id='page-166'></a>

(defun random-elt (choices) 
"Choose an element from a list at random." 
(elt choices (random (length choices)))) 

The actual ELIZA program had a few complications that don't show up in this version. 
First, there was an alias method for associating several words with the same pattern; 
both "mother" and "father" could be associated with the "family" pattern. There was 
also a synonym mechanism that would treat "don't" and "do not" or "everybody" and 
"everyone" the same. In the case of input with several comma-separated phrases, 
each phrase was processed separately, and the response with the highest priority 
was selected. In addition, the original ELIZA had a "memory" mechanism. When 
no pattern matched the input, it said something like "Tell me more about X," where 
X is some input given earlier. Finally, our version has fewer rules. Despite the 
shortcomings of our version, it can occasionally hold up its end of a conversation, as 
shown below: 

> (eliza) 
ELIZA> (hello there) 
(HOW DO YOU DO. PLEASE STATE YOUR PROBLEM.) 
ELIZA> (i want to test this program) 
(WHAT WOULD IT MEAN IF YOU GOT TO TEST THIS PROGRAM) 
ELIZA> (i could see if it works) 
(DO YOU REALLY THINK ITS LIKELY THAT IT WORKS) 
ELIZA> (no not really) 
(ARE YOU SAYING "NO" JUST TO BE NEGATIVE?) 
ELIZA> (no) 
(ARE YOU SAYING "NO" JUST TO BE NEGATIVE?) 
ELIZA> (forget it--i was wondering how general the program is) 
(WHY DO YOU TELL ME YOU WERE WONDERING HOW GENERAL THE PROGRAM IS NOW?) 
ELIZA> (i felt like it) 
(WHAT OTHER FEELINGS DO YOU HAVE?) 
ELIZA> (i feel this is enough) 
(DO YOU OFTEN FEEL THIS IS ENOUGH ?) 
ELIZA> [Abort] 

In the end, it is the technique that is important—not the program. ELIZA has been 
"explained away" and should rightfully be moved to the curio shelf. Pattern matching 
in general remains important technique, and we will see it again in subsequent 
chapters. The notion of a rule-based translator is also important. The problem 
of understanding English (and other languages) remains an important part of AI. 
Clearly, the problem of understanding English is not solved by ELIZA. In part V, we 
will address the problem again, using more sophisticated techniques. 


<a id='page-167'></a>
5.5 History and References 
As mentioned above, the original article describing ELIZA is Weizenbaum 1966. Another 
dialog system using similar pattern-matching techniques is Kenneth Colby's 
(1975) PARRY. This program simulated the conversation of a paranoid person well 
enough to fool several professional psychologists. Although the pattern matching 
techniques were simple, the model of belief maintained by the system was much 
more sophisticated than ELIZA. Colby has suggested that dialog programs like ELIZA, 
augmented with some sort of belief model like PARRY, could be useful tools in treating 
mentally disturbed people. According to Colby, it would be inexpensive and 
effective to have patients converse with a specially designed program, one that could 
handle simple cases and alert doctors to patients that needed more help. Weizenbaum's 
book Computer Power and Human Reason (1976) discusses ELIZA and PARRY 
and takes a very critical view toward Colby's suggestion. Other interesting early 
work on dialog systems that model belief is reported by Allan Collins (1978) and 
Jamie Carbonell (1981). 

5.6 Exercises 
&#9635; Exercise 5.2 [m] Experiment with this version of ELIZA. Show some exchanges 
where it performs well, and some where it fails. Try to characterize the difference. 
Which failures could be fixed by changing the rule set, which by changing the 
pa t - ma tch function (and the pattern language it defines), and which require a change 
to the el i za program itself? 

&#9635; Exercise 5.3 [h] Define a new set of rules that make ELIZA give stereotypical responses 
to some situation other than the doctor-patient relationship. Or, write a set 
of rules in a language other than English. Test and debug your new rule set. 

&#9635; Exercise 5.4 [s] We mentioned that our version of ELIZA cannot handle commas 
or double quote marks in the input. However, it seems to handle the apostrophe in 
both input and patterns. Explain. 

&#9635; Exercise 5.5 [h] Alter the input mechanism to handle commas and other punctuation 
characters. Also arrange so that the user doesn't have to type parentheses 
around the whole input expression. (Hint: this can only be done using some Lisp 
functions we have not seen yet. Look at read-lineand read-from-string.) 


<a id='page-168'></a>

&#9635; Exercise 5.6 [m] Modify ELIZA to have an explicit exit. Also arrange so that the 
output is not printed in parentheses either. 

&#9635; Exercise 5.7 [m] Add the "memory mechanism" discussed previously to ELIZA. 
Also add some way of definining synonyms like "everyone" and "everybody." 

&#9635; Exercise 5.8 [h] It turns out that none of the rules in the given script uses a variable 
more than once-ther e is no rule of the form (?x... ?x). Write a pattern matcher that 
only adds bindings, never checks variables against previous bindings. Use the time 
special form to compare your function against the current version. 

&#9635; Exercise 5.9 [h] Winston and Horn's book Lisp presents a good pattern-matching 
program. Compare their implementation with this one. One difference is that they 
handle the case where the first element of the pattern is a segment variable with the 
following code (translated into our notation): 
(or (pat-match (rest pattern) (rest input) bindings) 
(pat-match pattern (rest input) bindings)) 
This says that a segment variable matches either by matching the first element of 
the input, or by matching more than the first element. It is much simpler than our 
approach using posi ti on, partly because they don't update the binding list. Can 
you change their code to handle bindings, and incorporate it into our version of 
pat-match? Is it still simpler? Is it more or less efficient? 

&#9635; Exercise 5.10 What is wrong with the following definition of s i mpl e equa1 
? 
(defun simple-equal (x y) 
"Test if two list s or atoms are equal." 
Warning incorrect 
(or (eql . y) 
(and (listp x) (listp y) 
(simple-equal (firs t x) (firs t y)) 
(simple-equal (rest x) (rest y)))) ) 

&#9635; Exercise 5.11 [m] Weigh the advantages of changing no-bi ndi ngs to ni 1, and f ai 1 
to something else. 


<a id='page-169'></a>

&#9635; Exercise 5.12 [m] Weigh the advantages of making pat-match return multiple values: 
the first would be true for a match and false for failure, and the second would 
be the binding list. 

&#9635; Exercise 5.13 [m] Suppose that there is a call to segment-match where the variable 
already has a binding. The current definition will keep making recursive calls to 
segment-match, one for each possible matching position. But this is silly—if the 
variable is already bound, there is only one sequence that it can possibly match 
against. Change the definition so that it looks only for this one sequence. 

